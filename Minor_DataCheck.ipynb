{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "considerable-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-responsibility",
   "metadata": {},
   "source": [
    "# Version Notes: \n",
    "\n",
    "### v1: \n",
    "* add Data_HourMinute for all exported datasources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-diagnosis",
   "metadata": {},
   "source": [
    "# Tip for quick search\n",
    "\n",
    "* Needs attention: the place where needs update or better logic\n",
    "* question to be answered: the place where things are still not clear\n",
    "* Manual Check: Unit test where you can drill in to find the data that leads to the check results for a specific project and specific check\n",
    "* TODO: things needs to be done\n",
    "* bookmark: stop point from last visit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-excess",
   "metadata": {},
   "source": [
    "# Admin Notes:\n",
    "\n",
    "\n",
    "1. The AMTool dataset is archived daily as csv files and used for the project book check. \n",
    "The csv files are located at: \n",
    "r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\DataLake'\n",
    "\n",
    "2. The excel input files are checked daily and archived with datestamp whenever it is modified.\n",
    "The continuously updated excel input files are located at: r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\excel'\n",
    "The excel input file are archived at: r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\Data_MiscInput'\n",
    "To recover the archived excel file used in project book check for a target date, select the excel file with latest datestamp but is still earlier than the target date.\n",
    "\n",
    "3. The check summary export action is logged daily. It can be used for daily monitoring. \n",
    "The file export log is located at: \\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal\\log\n",
    "\n",
    "4. The published data are at:\n",
    "\n",
    "    * csv files for district asset manager: http://svgcshopp.dot.ca.gov/DataLake/ProjectBookCheck/\n",
    "    * csv files for HQ AM: \\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal\n",
    "    * tableau workbook with live data source: https://tableau.dot.ca.gov/#/site/AssetManagement/workbooks/1815/views\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-disaster",
   "metadata": {},
   "source": [
    "# General Approach\n",
    "\n",
    "use Minor raw data as basis for data checks. \n",
    "Each project only occupies one line\n",
    "\n",
    "can expand columns, only if it will not create duplicate rows in the SHOPP raw dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-celebrity",
   "metadata": {},
   "source": [
    "# Data clean process\n",
    "\n",
    "* funding amount: remove dollar sign, \n",
    "* fill missing value, string, numerical, \n",
    "* remove leading single quote for string value\n",
    "* strip off leading and trailing space \n",
    "\n",
    "* regulate column names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-mozambique",
   "metadata": {},
   "source": [
    "# Import common modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-cheat",
   "metadata": {},
   "source": [
    "<a id='TableOfContents'></a>\n",
    "\n",
    "# Table Of Contents\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "### [Global Constants](#GlobalConstants)\n",
    "\n",
    "\n",
    "### [Load and cleanup source data](#Read_Data)\n",
    "\n",
    "\n",
    "## Add fields to SHOPP raw data (calculate and join)\n",
    "* [Calculated Fields](#AddDataColumns)\n",
    "* [Join Tables](#DataJoining)\n",
    "\n",
    "\n",
    "\n",
    "## Data Check and Export\n",
    "\n",
    "\n",
    "## [Data Check List](#Issue_Table1)\n",
    "The main table of check issues, \n",
    "one issue per row, \n",
    "\n",
    "\n",
    "* [Will_this_project_be_included_in_the_Project_Book](#Will_this_project_be_included_in_the_Project_Book)\n",
    "* [Does_project_cost_exceed_Minor_Program_limits](#Does_project_cost_exceed_Minor_Program_limits)\n",
    "\n",
    "\n",
    "\n",
    "## [Export Internal Check Summary](#Export_internal_check_summary)\n",
    "* internal check summary (csv)\n",
    "\n",
    "\n",
    "## [Final Clean Up](#FinalCleanUp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "fundamental-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "\n",
    "# import requests\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "second-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "intellectual-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show dataframe without skip column\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "acquired-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from config_datasource import *\n",
    "import projectbookcheck_utilityfunction as uf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-theory",
   "metadata": {},
   "source": [
    "<a id='GlobalConstants'></a>\n",
    "## Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "million-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use 'csv' to read data from data lake, use 'live' to read data directly from AmTool Server\n",
    "# DATA_SOURCE_TYPE = 'csv'\n",
    "\n",
    "# # DATALAKE_FOLDER = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\DataLake'\n",
    "\n",
    "# #input data\n",
    "# DATALAKE_FOLDER = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\DataLake'\n",
    "# PROJECTBOOKCHECK_INPUT_FOLDER = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\excel'\n",
    "\n",
    "# #output data\n",
    "# DATALAKE_HTTPSEVER_FOLDER = 'C:\\inetpub\\wwwroot\\DataLake\\ProjectBookCheck'\n",
    "# PROJECTBOOKCHECK_OUTPUT_FOLDER = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal'\n",
    "\n",
    "# #log data\n",
    "# log_folder = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal\\log'\n",
    "\n",
    "# TARGET_FY = 2021\n",
    "\n",
    "\n",
    "# # CURRENT_FY\n",
    "\n",
    "# TARGETDATE = datetime.today().strftime(\"%m-%d-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "experienced-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "artistic-facial",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'TenYrShopp_RawData_'\n",
    "path_to_file = r'{}\\{}.csv'.format(DATALAKE_HTTPSERVER_FOLDER, filename)\n",
    "t = os.path.getmtime(path_to_file)\n",
    "\n",
    "# File_TimeStamp = datetime.fromtimestamp(t).strftime(\"%m-%d-%Y_%H-%M\")\n",
    "Data_TimeStamp = datetime.fromtimestamp(t).strftime(\"%m-%d-%Y %H:%M:%S\")\n",
    "\n",
    "TARGETDATE = datetime.fromtimestamp(t).strftime(\"%m-%d-%Y\")\n",
    "\n",
    "CURRENT_FY = uf.fiscalyear(datetime.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-healthcare",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-profile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "dense-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'Programming_Summary_'\n",
    "# df_Programming_Summary = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-ready",
   "metadata": {},
   "source": [
    "<a id='Read_Data'></a>\n",
    "\n",
    "# Read Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "artificial-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "File_TimeStamp = ''\n",
    "\n",
    "if DATA_SOURCE_TYPE == 'csv':\n",
    "    filename = 'Minor_Project_Details_Raw_Data_'\n",
    "    df_Minor_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, File_TimeStamp))\n",
    "\n",
    "    filename = 'Minor_Performance_Raw_Data_'\n",
    "    df_Minor_perf_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, File_TimeStamp))\n",
    "\n",
    "    filename = 'Programming_Summary_'\n",
    "    df_Programming_Summary = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, File_TimeStamp))\n",
    "\n",
    "    filename = 'Minor_Project_Postmile_Check_'\n",
    "    df_Minor_pm_check = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, File_TimeStamp), header = 0)\n",
    "\n",
    "else:\n",
    "    print('skip getting csv data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "binding-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Minor_Activity_Crosswork.xlsx'\n",
    "\n",
    "df_Activity_CrossWalk = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename))\n",
    "\n",
    "# df_Activity_CrossWalk['Activity Category'].unique()\n",
    "\n",
    "temp = df_Activity_CrossWalk.groupby('Main Activity Category')['ActID'].agg(list).reset_index()\n",
    "\n",
    "dict_Activity_CW = dict(zip(temp['Main Activity Category'], temp['ActID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-assembly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-collect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "approximate-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question answered: 2021 and 2022 approved list project id duplication will be resolved with later excel files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-oasis",
   "metadata": {},
   "source": [
    "# Data quality check and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-handling",
   "metadata": {},
   "source": [
    "<a id='Minor_Raw_Data'></a>\n",
    "## Minor Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "solid-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rename = {'Project ID':'EFIS',\n",
    "               'ID': 'AMT_ID', \n",
    "              'FY.1': 'FY_ALN',\n",
    "               'Prog Appr Date': 'Prog Appr Date_ALN',\n",
    "               'FY': 'FY_WP',\n",
    "               'Prog Approval Date': 'Prog Appr Date_WP',\n",
    "              }\n",
    "df_Minor_raw_data = df_Minor_raw_data.rename(dict_rename, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "adolescent-medicaid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1263, 78)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Minor_raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "reliable-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for programmed FY year of 9999, skip all the checks\n",
    "\n",
    "# No need to check, since the raw data is filtered before download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "amateur-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Minor_raw_data['District'] = df_Minor_raw_data['District'].apply(uf.remove_punction)\n",
    "df_Minor_raw_data['District'] = df_Minor_raw_data['District'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-belief",
   "metadata": {},
   "source": [
    "<a id='Minor_Perf_RawData'></a>\n",
    "## Minor_Perf_RawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "psychological-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "dict_rename_perf_rawdata = {\n",
    "                           'ID': 'AMT_ID',\n",
    "#                             'ProjectedRTL FY': 'Projected RTL FY',\n",
    "              }\n",
    "\n",
    "df_Minor_perf_raw_data = df_Minor_perf_raw_data.rename(dict_rename_perf_rawdata, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "neural-outside",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols_strip = ['EA','EFIS']\n",
    "for c in cols_strip :\n",
    "    df_Minor_perf_raw_data[c] = df_Minor_perf_raw_data[c].str.strip(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-economy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "sustainable-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data clean \n",
    "#data type regulation\n",
    "\n",
    "df_Minor_perf_raw_data['Quantity'] = df_Minor_perf_raw_data['Quantity'].fillna(0)\n",
    "df_Minor_perf_raw_data['Assets in Good Cond'] = df_Minor_perf_raw_data['Assets in Good Cond'].fillna(0)\n",
    "df_Minor_perf_raw_data['Assets in Fair Cond'] = df_Minor_perf_raw_data['Assets in Fair Cond'].fillna(0)\n",
    "df_Minor_perf_raw_data['Assets in Poor Cond'] = df_Minor_perf_raw_data['Assets in Poor Cond'].fillna(0)\n",
    "df_Minor_perf_raw_data['New Assets Added'] = df_Minor_perf_raw_data['New Assets Added'].fillna(0)\n",
    "\n",
    "# df_Minor_perf_raw_data['EFIS'] = df_Minor_perf_raw_data['EFIS'].apply(regulate_EFIS)\n",
    "df_Minor_perf_raw_data['EFIS'] = pd.to_numeric(df_Minor_perf_raw_data['EFIS'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "dedicated-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data trimming\n",
    "#row\n",
    "df_Minor_perf_raw_data= df_Minor_perf_raw_data[df_Minor_perf_raw_data['District'] != 56]\n",
    "#column\n",
    "df_Minor_perf_raw_data.drop(['PID Cycle', 'TYP','ProjectedSHOPP Cycle','RequestedRTL FY','DistrictPriority'],\n",
    "  axis='columns', inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "sapphire-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Minor_perf_raw_data.name = 'df_Minor_perf_raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-tampa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "heated-edition",
   "metadata": {},
   "source": [
    "<a id='Counties'></a>\n",
    "## Counties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "standing-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Counties.xlsx'\n",
    "\n",
    "df_counties = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "virtual-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counties['Co. Name Abbr.'] = df_counties['Co. Name Abbr.'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "bigger-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_counties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "informative-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counties.name = 'df_counties'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "spectacular-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_prog_county = df_perf_raw_prog_candidate.merge(df_counties, how = 'left', left_on = 'County', right_on = 'Co. Name Abbr.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "therapeutic-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no need for the following, already added to the df_Minor_perf_raw_data\n",
    "\n",
    "# #rename columns\n",
    "# dict_rename_4= {\n",
    "#                'Performance Objective':'Performance Objective Original', \n",
    "#               }\n",
    "\n",
    "# df_perf_raw_prog_county = df_perf_raw_prog_county.rename(dict_rename_4, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-toyota",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-liability",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "classified-boost",
   "metadata": {},
   "source": [
    "<a id='Postmile_Check'></a>\n",
    "## Postmile Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "adult-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_PM_ck_rename = {\n",
    " 'ID': 'AMT_ID',\n",
    " '№': 'No'                            }\n",
    "df_Minor_pm_check.rename(dict_PM_ck_rename, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "alike-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Minor_pm_check['District'] = df_Minor_pm_check['District'].str.strip(\"'\")\n",
    "df_Minor_pm_check['District'] =df_Minor_pm_check['District'].astype(int)\n",
    "df_Minor_pm_check = df_Minor_pm_check[df_Minor_pm_check['District']!= 56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "molecular-passenger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1623, 29)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Minor_pm_check.name = 'df_Minor_pm_check'\n",
    "df_Minor_pm_check.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-cookie",
   "metadata": {},
   "source": [
    "<a id='ProgrammingSummary'></a>\n",
    "## Programming Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "medium-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_renamee = {'ID': 'AMT_ID',\n",
    "                               }\n",
    "df_Programming_Summary.rename(dict_renamee, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "entertaining-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_strip = ['EA','EFIS']\n",
    "for c in cols_strip :\n",
    "    df_Programming_Summary[c] = df_Programming_Summary[c].str.strip(\"'\")\n",
    "    \n",
    "df_Programming_Summary['EFIS'] = df_Programming_Summary['EFIS'].apply(uf.regulate_EFIS)\n",
    "df_Programming_Summary['EFIS'] = pd.to_numeric(df_Programming_Summary['EFIS'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-brown",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-secretary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "amazing-siemens",
   "metadata": {},
   "source": [
    "# Approved Project List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "complete-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Minor Approved list.xlsx'\n",
    "\n",
    "df_approved = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename, sheet_name='Minor Approved'))\n",
    "\n",
    "dict_rename = {\n",
    "    'Project ID':'EFIS',\n",
    "              }\n",
    "df_approved = df_approved.rename(dict_rename, axis = 1)\n",
    "\n",
    "df_approved['EFIS'] = df_approved['EFIS'].apply(uf.regulate_EFIS)\n",
    "df_approved['EFIS'] = pd.to_numeric(df_approved['EFIS'], errors='coerce')\n",
    "\n",
    "df_approved['Approve Year'] = df_approved['FY'].str[-2:].astype(int)\n",
    "\n",
    "target_cols = ['EFIS','EA','Minor', 'Approve Year', 'Performance Value','Performance Measure','Program Code','Construction Capital Cost ($K)']\n",
    "\n",
    "df_approved = df_approved_2021[target_cols].append(df_approved_2022[target_cols])\n",
    "\n",
    "df_approved = df_approved.sort_values(by =['EFIS','Approve Year'], ascending = True)\n",
    "df_approved = df_approved.groupby('EFIS').first().reset_index()\n",
    "\n",
    "df_approved['In the Approved List?'] = 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-notion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-summary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "collective-drinking",
   "metadata": {},
   "source": [
    "<a id='AddDataColumns'></a>\n",
    "## Calculate and join additional fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "lovely-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this logic needs to consider the programming list\n",
    "df_Minor_raw_data['Section'] = df_Minor_raw_data['Section In Use']\n",
    "\n",
    "df_Minor_raw_data['Unique EA'] = df_Minor_raw_data.apply(uf.calc_unique_EA, axis = 1)\n",
    "\n",
    "df_Minor_raw_data['FY In Use'] = df_Minor_raw_data['FY.2'].str[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-tactics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "animated-water",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15245, 25)\n",
      "(1020, 25)\n"
     ]
    }
   ],
   "source": [
    "#filter data to keep Minor program and active section only.\n",
    "# df_Programming_Summary\n",
    "print(df_Programming_Summary.shape)\n",
    "df_Programming_Summary_filtered = pd.merge(df_Programming_Summary, df_Minor_raw_data[['AMT_ID','Section',]],\n",
    "               how= 'inner', left_on = ['AMT_ID','Section',], right_on = ['AMT_ID','Section',])\n",
    "print(df_Programming_Summary_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "accepted-village",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020, 25)\n",
      "(1020, 33)\n"
     ]
    }
   ],
   "source": [
    "print(df_Programming_Summary_filtered.shape)\n",
    "df_Programming_Summary_filtered = pd.merge(df_Programming_Summary_filtered, df_approved,\n",
    "               how= 'left', left_on = ['EFIS'], right_on = ['EFIS'],\n",
    "               suffixes=['','_ApprovedList'])\n",
    "print(df_Programming_Summary_filtered.shape)\n",
    "df_Programming_Summary_filtered['In the Approved List?'].fillna('No', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "miniature-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Matches Minor Approved List Performance Measure?'\n",
    "\n",
    "def ck_performance_measure(df):\n",
    "    if pd.isna(df['Performance Measure_ApprovedList']):\n",
    "        return 'Not in the Approved Lists'\n",
    "    else:\n",
    "        if df['Performance Measure_ApprovedList'] == df['Performance Measure']:\n",
    "            return 'Yes'\n",
    "        else:\n",
    "            return 'No'\n",
    "\n",
    "df_Programming_Summary_filtered[ck_col]= df_Programming_Summary_filtered.apply(ck_performance_measure, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "engaged-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ck_col = 'Matches Minor Approved List Performance Value?'\n",
    "def ck_performance_value(df):\n",
    "    if pd.isna(df['Performance Value_ApprovedList']):\n",
    "        return 'Not in the Approved Lists'\n",
    "    else:\n",
    "        if df['Performance Value_ApprovedList'] == df['Performance Value']:\n",
    "            return 'Yes'\n",
    "        else:\n",
    "            return 'No'\n",
    "\n",
    "df_Programming_Summary_filtered[ck_col]= df_Programming_Summary_filtered.apply(ck_performance_value, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "parallel-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Matches Minor Approved List Performance Value and Measure?'\n",
    "def ck_performance(df):\n",
    "    if df['Matches Minor Approved List Performance Value?'] == 'Not in the Approved Lists':\n",
    "        return 'Not in the Approved Lists'\n",
    "    elif (df['Matches Minor Approved List Performance Value?'] == 'Yes') and (df['Matches Minor Approved List Performance Measure?'] == 'Yes'):\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return 'No'\n",
    "    \n",
    "\n",
    "df_Programming_Summary_filtered[ck_col]= df_Programming_Summary_filtered.apply(ck_performance, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-truth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "responsible-nitrogen",
   "metadata": {},
   "source": [
    "# Check Minor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "hindu-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Minor_raw_data['Program Code in Use'] = df_Minor_raw_data.apply(lambda x: x['Program Code'] if x['Section In Use'] == 'WP' else x['Program Code.1'], axis = 1)\n",
    "\n",
    "df_Minor_raw_data['Const Capital in Use'] = df_Minor_raw_data.apply(lambda x: x['Construction Capital ($K)'] if x['Section In Use'] == 'WP' else x['Total Capital Project Cost ($K)'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "inner-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Minor_raw_data['FY In Use'] = pd.to_numeric(df_Minor_raw_data['FY In Use'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "innocent-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Minor_raw_data['Legacy Project?'] = df_Minor_raw_data.apply(lambda x: 'Yes' if float(x['FY In Use']) < 21 else 'No', axis = 1)\n",
    "#for legacy project, do not flag the project if the information is missing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "encouraging-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Minor_raw_data['FY In Use'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "convertible-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "geographic-panel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question answered: we focus on checking the data only in the Section in Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "attended-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Minor_raw_data_backup = df_Minor_raw_data.copy()\n",
    "\n",
    "# df_Minor_raw_data = df_Minor_raw_data_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "through-bristol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1263, 84)\n",
      "(1263, 90)\n"
     ]
    }
   ],
   "source": [
    "print(df_Minor_raw_data.shape)\n",
    "\n",
    "df_Minor_raw_data = pd.merge(df_Minor_raw_data, df_approved[['EFIS','Minor','EA','In the Approved List?','Approve Year','Program Code','Construction Capital Cost ($K)' ]],\n",
    "                            how = 'left', left_on = 'EFIS', right_on = 'EFIS', suffixes=['','_ApprovedList'])\n",
    "\n",
    "print(df_Minor_raw_data.shape)\n",
    "\n",
    "df_Minor_raw_data['In the Approved List?'].fillna('No', inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "extensive-wealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Minor_raw_data['Minor'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "paperback-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ck_match_2022_approved_list(df):\n",
    "    if df['In the Approved List?'] == 'Yes' and df['Approve Year'] == 22:\n",
    "        if df['FY In Use'] == 22:\n",
    "            return 'OK'\n",
    "        else:\n",
    "            return r'The FY {} does not match Approved year {}'.format(df['FY In Use'], df['Approve Year'])\n",
    "    else:\n",
    "        return 'Not in the 2022 Approved list'\n",
    "\n",
    "ck_col = 'FY Matches 2022 List?'\n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_match_2022_approved_list, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-begin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-active",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "binding-improvement",
   "metadata": {},
   "source": [
    "### is EFIS duplicate within Minor raw data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "complimentary-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = df_Minor_raw_data.groupby(['EFIS'])['AMT_ID'].nunique().reset_index(name = 'EFIS_Counts')\n",
    "# duplicated_EFIS= temp[temp['EFIS_Counts']> 1]\n",
    "\n",
    "# df_Minor_raw_data.drop(columns=['EFIS_Counts'],inplace=True , errors='ignore')\n",
    "# print(df_Minor_raw_data.shape)\n",
    "# df_Minor_raw_data = pd.merge(df_Minor_raw_data, duplicated_EFIS, \n",
    "#                              how = 'left', left_on = ['EFIS'], right_on=['EFIS'])\n",
    "# print(df_Minor_raw_data.shape)\n",
    "\n",
    "# def ck_EFIS_Uniqueness(df):\n",
    "#     if pd.isna(df['EFIS_Counts']):\n",
    "#         return 'OK'\n",
    "#     elif df['EFIS'] == 0: \n",
    "#         return 'Missing/Invalid EFIS'\n",
    "#     else:\n",
    "#         return 'Duplicate EFIS'\n",
    "    \n",
    "# df_Minor_raw_data['EFIS Uniqueness Check'] = df_Minor_raw_data.apply(ck_EFIS_Uniqueness, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "linear-afghanistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1263, 91)\n",
      "(1263, 94)\n"
     ]
    }
   ],
   "source": [
    "temp = df_Minor_raw_data.groupby(['EFIS'])['AMT_ID'].agg([pd.Series.nunique, list]).reset_index()\n",
    "temp['AMT_IDs'] = temp['list'].apply(lambda l: ','.join(l))\n",
    "duplicated_EFIS= temp[temp['nunique']> 1]\n",
    "\n",
    "df_Minor_raw_data.drop(columns=['nunique','AMT_IDs'],inplace=True , errors='ignore')\n",
    "print(df_Minor_raw_data.shape)\n",
    "df_Minor_raw_data = pd.merge(df_Minor_raw_data, duplicated_EFIS, \n",
    "                             how = 'left', left_on = ['EFIS'], right_on=['EFIS'])\n",
    "print(df_Minor_raw_data.shape)\n",
    "\n",
    "def ck_EFIS_Uniqueness(df):\n",
    "    if pd.isna(df['nunique']):\n",
    "        return 'OK'\n",
    "    elif df['EFIS'] == 0: \n",
    "        return 'Missing/Invalid EFIS'\n",
    "    else:\n",
    "        return 'Duplicate EFIS {} is found in the following projects: {}'.format(df['EFIS'], df['AMT_IDs'])\n",
    "    \n",
    "df_Minor_raw_data['EFIS Uniqueness Check'] = df_Minor_raw_data.apply(ck_EFIS_Uniqueness, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "exact-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Minor_raw_data['EFIS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "instructional-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Minor_raw_data['EFIS Uniqueness Check'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "collectible-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Minor_raw_data['EA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "improving-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #flag if EFIS is invalid\n",
    "# def ck_invalid_EFIS(df):\n",
    "#     if len(str(EFIS)) < 5: \n",
    "#         return 'Invalid EFIS'\n",
    "#     else:\n",
    "#         return 'OK'\n",
    "# df_Minor_raw_data['EFIS is valid?'] = df_Minor_raw_data['EFIS'].apply(ck_invalid_EFIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "concrete-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Minor_raw_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-worst",
   "metadata": {},
   "source": [
    "### flag if District + EA duplicate within Minor raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "recovered-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_Minor_raw_data.groupby(['Unique EA'])['AMT_ID'].nunique().reset_index(name = 'UnqiueEA_Counts')\n",
    "duplicated_EA= temp[temp['UnqiueEA_Counts']> 1]\n",
    "\n",
    "df_Minor_raw_data.drop(columns=['UnqiueEA_Counts'],inplace=True , errors='ignore')\n",
    "\n",
    "df_Minor_raw_data = pd.merge(df_Minor_raw_data, duplicated_EA[['Unique EA','UnqiueEA_Counts']].drop_duplicates(), \n",
    "                             how = 'left', left_on = ['Unique EA'], right_on=['Unique EA'])\n",
    "\n",
    "def ck_EA_Uniqueness(df):\n",
    "    if pd.isna(df['UnqiueEA_Counts']):\n",
    "        return 'OK'\n",
    "    else:\n",
    "        return 'Duplicate District+EA is found.'\n",
    "    \n",
    "df_Minor_raw_data['EA Uniqueness Check'] = df_Minor_raw_data.apply(ck_EA_Uniqueness, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-carter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "joint-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Does Project have a Repeated EA or Project ID repeated in Minor Profile?'\n",
    "\n",
    "def ck_ID_Uniqueness(df):\n",
    "    if df['EA Uniqueness Check'] == 'OK':\n",
    "        return 'OK'\n",
    "    else:\n",
    "        return 'Duplicate District+EA and/or Project ID(EFIS) is found.'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_ID_Uniqueness, axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "partial-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Minor_raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "western-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does FY Need Updates?\n",
    "\n",
    "def ck_FY_consistancy(df):\n",
    "    if df['In the Approved List?'] == 'Yes' and df['Legacy Project?'] != 'Yes':\n",
    "        if df['FY In Use'] == df['Approve Year']:\n",
    "            return 'OK'\n",
    "        else:\n",
    "            return 'Please update FY. It is in the {} Approved List'.format(df['Approve Year'])\n",
    "    else:\n",
    "        return 'OK'\n",
    "    \n",
    "df_Minor_raw_data['Does FY Need Updates?'] = df_Minor_raw_data.apply(ck_FY_consistancy, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "intelligent-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does EA Need Updates?\n",
    "\n",
    "def ck_EA_consistancy(df):\n",
    "    if df['Legacy Project?'] != 'Yes':\n",
    "        return 'OK'\n",
    "    else: \n",
    "        if df['EA'] == df['EA_ApprovedList']:\n",
    "            return 'OK'\n",
    "        else:\n",
    "            return 'Update EA. It does not match EA in Approved List of year {}'.format(df['Approve Year'])\n",
    "    \n",
    "df_Minor_raw_data['Does EA Need Updates?'] = df_Minor_raw_data.apply(ck_EA_consistancy, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "surgical-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does Program Code Need Updates?\n",
    "ck_col = 'Does Program Code Need Updates?'\n",
    "\n",
    "def ck_program_code_update(df):\n",
    "    if df['Legacy Project?'] != 'Yes':\n",
    "        return 'OK'\n",
    "    else: \n",
    "        if pd.isna(df['Program Code_ApprovedList']) or (df['Program Code in Use'] == df['Program Code_ApprovedList']):\n",
    "            return 'OK'\n",
    "        else:\n",
    "            return 'The program code for Section In Use does not match Approved project list.'\n",
    "\n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_program_code_update, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "fitting-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does Minor Category Match Approved Project List?\n",
    "\n",
    "ck_col = 'Does Minor Category Match Approved Project List?'\n",
    "\n",
    "def ck_minor_category(df):\n",
    "    if df['Legacy Project?'] != 'Yes':\n",
    "        return 'OK'\n",
    "    else: \n",
    "        if (df['Minor'] == df['Minor_ApprovedList']):\n",
    "            return 'OK'\n",
    "        else:\n",
    "            return 'The Minor Type for Section In Use does not match Approved project list. Please work with the Minor HQ to reconcile.'\n",
    "\n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_program_code_update, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "anonymous-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in df_Minor_raw_data.columns:\n",
    "#     print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "large-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Minor_raw_data.Minor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "smooth-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ck_col = 'Does Program Code Need Updates?'\n",
    "# df_Minor_raw_data[ck_col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "comfortable-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Activity_CrossWalk['Activity Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "specialized-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a in df_Activity_CrossWalk['Activity Category'].unique():\n",
    "#     if a not in df_Minor_perf_raw_data['Main Activity Category'].unique():\n",
    "#         print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "european-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a in df_Minor_perf_raw_data['Main Activity Category'].unique():\n",
    "#     if a not in df_Activity_CrossWalk['Activity Category'].unique():\n",
    "#         print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "subject-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Activity_CrossWalk['QualifiedActivity'] = 'Yes'\n",
    "\n",
    "temp = pd.merge(df_Minor_perf_raw_data, df_Activity_CrossWalk, \n",
    "         how='left', left_on=['Main Activity Category', 'ActID'], right_on=['Main Activity Category', 'ActID'])\n",
    "\n",
    "temp['QualifiedActivity'].fillna('No', inplace=True)\n",
    "\n",
    "temp = temp.groupby(['AMT_ID', 'Section'])['QualifiedActivity'].agg(list).reset_index()\n",
    "\n",
    "\n",
    "temp['Project Has Qualified Activity?'] = temp['QualifiedActivity'].apply(\n",
    "    lambda x: 'Yes' if 'Yes' in x else 'No'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-lesson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "overall-amazon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1263, 102)\n",
      "(1263, 103)\n"
     ]
    }
   ],
   "source": [
    "print(df_Minor_raw_data.shape)\n",
    "df_Minor_raw_data = pd.merge(df_Minor_raw_data, temp[['AMT_ID', 'Section', 'Project Has Qualified Activity?']], \n",
    "         how='left', left_on=['AMT_ID', 'Section'], right_on=['AMT_ID', 'Section'])\n",
    "print(df_Minor_raw_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-inventory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-impossible",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "boring-agriculture",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_name = 'Project has at least one qualified activity?'\n",
    "\n",
    "def ck_qualified_activity(df):\n",
    "    if pd.isna(df['Project Has Qualified Activity?']):\n",
    "        return 'The performance data is missing for this project.'\n",
    "    elif df['Project Has Qualified Activity?'] == 'No':\n",
    "        try: \n",
    "            act_list = ','.join(dict_Activity_CW[df['Activity Category']])\n",
    "        except:\n",
    "            act_list = 'please find out from HQ AM for the latest list.'\n",
    "        return 'Please update the performance to include at least one qualified activity. The qualified activity for {} are {}'.format(df['Activity Category'], act_list)\n",
    "    else:\n",
    "        return 'OK'\n",
    "\n",
    "df_Minor_raw_data[ck_name] = df_Minor_raw_data.apply(ck_qualified_activity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-marriage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "prepared-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Minor_raw_data[df_Minor_raw_data['Does Program Code Need Updates?'] != 'OK'][['AMT_ID','Program Code in Use','Program Code_ApprovedList']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "accessible-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO:\n",
    "\n",
    "# cols = ['EA','EFIS','SYSNO', 'INETNO',\n",
    "#        'OUTETNO',]\n",
    "\n",
    "# for c in cols:\n",
    "#     df_Minor_drain_raw_data[c] = df_Minor_drain_raw_data[c].apply(uf.remove_punction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "flexible-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO\n",
    "# #check for each Main Activity Category, at least on ActID within the cross walk list provided by mara\n",
    "# # \n",
    "# temp = df_Minor_drain_raw_data.groupby(['EFIS','Section'])['ActID'].agg(lambda l: ','.join(l)).reset_index(name = 'ActIDs')\n",
    "# temp['Drainage Activity Check'] = temp['ActIDs'].apply(lambda x: 'OK' if 'C' in x else 'This project needs to have at least one drainage activity starts with \"C\".')\n",
    "\n",
    "# df_Minor_brg_raw_data.head()\n",
    "\n",
    "# df_Minor_brg_raw_data.columns\n",
    "\n",
    "# #question to be answered: there is not ActID in the bridge worksheet raw data\n",
    "\n",
    "# cols = ['District.1','Route']\n",
    "\n",
    "# for c in cols:\n",
    "#     df_Minor_pav_raw_data[c] = df_Minor_pav_raw_data[c].apply(uf.remove_punction)\n",
    "\n",
    "# dict_rename = {\n",
    "#     'ID':'AMT_ID'\n",
    "# }\n",
    "\n",
    "# df_Minor_pav_raw_data.rename(dict_rename, axis = 1, inplace=True)\n",
    "\n",
    "# df_Minor_pav_raw_data.head()\n",
    "\n",
    "# #TODO\n",
    "# #check for each Main Activity Category, at least on ActID within the cross walk list provided by mara\n",
    "# # \n",
    "\n",
    "# # pavement: needs to have at least one B activity id\n",
    "# temp = df_Minor_pav_raw_data.groupby(['AMT_ID','Section'])['ActID'].agg(lambda l: ','.join(l)).reset_index(name = 'ActIDs')\n",
    "# temp['Pavement Activity Check'] = temp['ActIDs'].apply(lambda x: 'OK' if 'B' in x else 'This project needs to have at least one pavement activity starts with \"B\".')\n",
    "\n",
    "# temp['Pavement Activity Check'].unique()\n",
    "\n",
    "# # bridge,needs to have at least one A activity id\n",
    "# # temp = df_Minor_drain_raw_data.groupby(['EFIS','Section'])['ActID'].agg(lambda l: ','.join(l)).reset_index(name = 'ActIDs')\n",
    "# # temp['Drainage Activity Check'] = temp['ActIDs'].apply(lambda x: 'OK' if 'C' in x else 'This project needs to have at least one drainage activity starts with \"C\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "pleased-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question to be answered: \n",
    "# safety: needs to have at least one within the list []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "considered-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ck_shape(*args, **kwargs):\n",
    "#     def wrapper_func(original_func):\n",
    "#         print (kwargs['df'].shape)\n",
    "#         results = original_func(*args, **kwargs)\n",
    "#         print (kwargs['df']..shape)\n",
    "#         return results\n",
    "#     return wrapper_func\n",
    "\n",
    "# @ck_shape(df = df_Minor_raw_data)\n",
    "# def add(x,y):\n",
    "#     return (x+y) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-identifier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "hydraulic-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does Construction Capital Cost ($K) Need Updates?\n",
    "\n",
    "ck_col = 'Does Construction Capital Cost ($K) Need Updates?'\n",
    "\n",
    "def ck_construction_capital_cost(df):\n",
    "    if df['Legacy Project?'] != 'Yes':\n",
    "        return 'OK'\n",
    "    else:\n",
    "        if abs(df['Construction Capital Cost ($K)'] - df['Const Capital in Use']) < 0.01:\n",
    "            return 'OK'\n",
    "        else:\n",
    "            # question to be answered: for construct cost ck, for 22, only check WP band if Section in WP\n",
    "            if df['Section'] == 'ALN' or (df['Section'] == 'WP' and df['Approve Year'] == 22): \n",
    "                return 'Update Capital Cost. It does not match Approved List'\n",
    "            else:\n",
    "                return 'OK'\n",
    "        \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_construction_capital_cost, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-glass",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "australian-focus",
   "metadata": {},
   "source": [
    "### flag if no performance\n",
    " performance value can be zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "mobile-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# FY in Use needs to be the same as the pavement, TMS worksheet plan year\n",
    "\n",
    "# flag the invalid locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "amazing-efficiency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1263, 105)\n",
      "(1263, 106)\n"
     ]
    }
   ],
   "source": [
    "ck_col = 'Was Performance Tab Completed in Section in Use?'\n",
    "\n",
    "temp = df_Minor_perf_raw_data.groupby(['AMT_ID','Section']).first().reset_index()\n",
    "temp['Has performance raw data?'] = 'Yes'\n",
    "\n",
    "df_Minor_raw_data.drop(columns=['Has performance raw data?',],inplace=True , errors='ignore')\n",
    "print(df_Minor_raw_data.shape)\n",
    "\n",
    "df_Minor_raw_data = pd.merge(df_Minor_raw_data, temp[['AMT_ID','Section','Has performance raw data?']].drop_duplicates(), \n",
    "                             how = 'left', left_on = ['AMT_ID','Section'], right_on=['AMT_ID','Section'])\n",
    "\n",
    "df_Minor_raw_data['Has performance raw data?'].fillna('No', inplace=True)\n",
    "\n",
    "print(df_Minor_raw_data.shape)\n",
    "\n",
    "\n",
    "def ck_performance_availability(df):\n",
    "    if df['Has performance raw data?'] == 'No':\n",
    "        return '\"Please complete Performance Tab in Section {}'.format(df['Section'])\n",
    "    else:\n",
    "        return 'OK'\n",
    "\n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_performance_availability, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "finnish-writing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1263, 107)\n",
      "(1263, 108)\n"
     ]
    }
   ],
   "source": [
    "# Does Performance in Section in Use Match Approved List?\n",
    "# check shape\n",
    "print(df_Minor_raw_data.shape)\n",
    "#remove column\n",
    "\n",
    "col_name = 'Matches Minor Approved List Performance Value and Measure?'\n",
    "df_Minor_raw_data.drop(columns=[col_name],inplace=True , errors='ignore')\n",
    "\n",
    "#join\n",
    "df_Minor_raw_data = pd.merge(\n",
    "    df_Minor_raw_data, \n",
    "    df_Programming_Summary_filtered[['AMT_ID', 'Section',col_name]],\n",
    "    how='left', left_on=['AMT_ID', 'Section'], right_on=['AMT_ID', 'Section']\n",
    ")\n",
    "#fill na\n",
    "#question to be answered: for projects not in the programming summary list, we assigned the performance value and measure check to No\n",
    "\n",
    "df_Minor_raw_data[col_name].fillna('No', inplace=True)\n",
    "\n",
    "print(df_Minor_raw_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "alien-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Was project with FY Before 2021/22 Closed-Out?'\n",
    "\n",
    "def ck_project_closeout_status(df):\n",
    "    if pd.isna(df['FY In Use']):\n",
    "        return 'Please Identify FY'\n",
    "    elif int(df['FY In Use']) < 22 and df['Section'] == 'ALN':\n",
    "        return 'OK'\n",
    "    else:\n",
    "        return 'Please work with HQ Minor Program to Close-out Project'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_project_closeout_status, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "industrial-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ck_col = 'Data needs review other that Close-out?'\n",
    "\n",
    "input_cols = [\n",
    "    'Does Minor Category Match Approved Project List?',\n",
    "    'Does Project have a Repeated EA or Project ID repeated in Minor Profile?',\n",
    "    'Does FY Need Updates?', \n",
    "    'Does EA Need Updates?',\n",
    "    'Does Program Code Need Updates?',\n",
    "    'Does Construction Capital Cost ($K) Need Updates?',\n",
    "    'Has performance raw data?',\n",
    "    'Was Performance Tab Completed in Section in Use?',\n",
    "    'Matches Minor Approved List Performance Value and Measure?',\n",
    "    \n",
    "#          'Was project with FY Before 2021/22 Closed-Out?'     \n",
    "       ]\n",
    "\n",
    "def ck_review_needs_2(df, input_cols):\n",
    "    for col in input_cols:\n",
    "        if df[col] != 'OK:':\n",
    "            return 'District needs to review project data (Profile and/or RTL)'\n",
    "    return 'OK'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_review_needs_2, args = [input_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "elegant-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Data Needs Review?'\n",
    "\n",
    "input_cols = [\n",
    "    'Data needs review other that Close-out?',\n",
    "    'Was project with FY Before 2021/22 Closed-Out?'\n",
    "]\n",
    "\n",
    "def ck_review_needs(df, input_cols):\n",
    "    for col in input_cols:\n",
    "        if df[col] != 'OK:':\n",
    "            return 'District needs to review project data (Profile and/or RTL)'\n",
    "    return 'OK'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_review_needs, args = [input_cols], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "thorough-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question to be answered, can we convert the following checks into \"OK\" or others, to be used in filter out flagged items in the punchlist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "becoming-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Was information Entered in the Allocation Band?'\n",
    "\n",
    "def ck_ALN_band_info_completeness(df):\n",
    "    if pd.isna(df['FY_ALN']) or df['Has performance raw data?'] == 'No' or pd.isna(df['Total Capital Project Cost ($K)']):\n",
    "        return 'No'\n",
    "    else: \n",
    "        return 'Yes'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_ALN_band_info_completeness, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "banner-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Is Project ready to enter data in the Allocation Band?'\n",
    "\n",
    "def ck_readiness_to_enter_ALN_band(df):\n",
    "    if pd.notna(df['Prog Appr Date_WP']):  #has approval date in WP band\n",
    "        if df['Section'] == 'ALN':\n",
    "            return 'Project was closed-out'\n",
    "        elif df['Was information Entered in the Allocation Band?'] == 'Yes':\n",
    "            return 'Allocation Band needs review by HQ Minor Program. If all data Accurate HQ Minor will enter the approval date'\n",
    "        else:\n",
    "            return 'Project ready to enter data in the Allocation Band (Cost, Schedule, RTL, And/Or Performance Tab)'\n",
    "    else: \n",
    "        return 'Workplan Band needs review by HQ Minor Program. If all data Accurate HQ Minor will enter the approval date'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_readiness_to_enter_ALN_band, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-stock",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "blank-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ck_col = 'Is Project Project Ready for Review and Approval Date?'\n",
    "\n",
    "def ck_readiness_for_review(df):\n",
    "    if df['Data needs review other that Close-out?'] != 'OK':\n",
    "        return 'No'\n",
    "    elif df['FY In Use'] > 22: \n",
    "        return 'No'\n",
    "    elif pd.isna(df['Prog Appr Date_WP']):\n",
    "        return 'HQ Needs to review Workplan band and enter Approval Date if data is accurate'\n",
    "    \n",
    "    elif df['Was information Entered in the Allocation Band?'] == 'Yes':\n",
    "        if pd.notna(df['Prog Appr Date_ALN']):\n",
    "            return 'No, Project Already Closed-out'\n",
    "        else:\n",
    "            return 'HQ Needs to review Allocation band and enter Approval Date if data is accurate'\n",
    "    else:\n",
    "        return 'No'\n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_readiness_for_review, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "administrative-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Does Worplan Band needs Approval Removal?'\n",
    "\n",
    "def ck_WP_data_error(df):\n",
    "    if pd.isna(df['Prog Appr Date_WP']):  #has no approval data in WP band\n",
    "        return 'No'\n",
    "    elif (pd.isna(df['FY In Use'])\n",
    "        or int(df['FY In Use']) > 22 \n",
    "        or (df['FY In Use'] in ['21', '22'] and df['In the Approved List?'] == 'No')\n",
    "         ): \n",
    "        return 'HQ Minor Program needs to remove Approval date fromWorkplan Band, so District can updated the project FY. Project not in Approved lists or in the future'\n",
    "    else:\n",
    "        return 'No'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_WP_data_error, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "spread-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Does Allocation Band needs Approval Removal?'\n",
    "\n",
    "def ck_ALN_data_error(df):\n",
    "    if pd.isna(df['Prog Appr Date_ALN']):  #has no approval data in ALN band\n",
    "        return 'No'\n",
    "    elif df['Data needs review other that Close-out?'] == 'OK': \n",
    "        return 'No'\n",
    "    else:\n",
    "        return 'HQ Minor Program needs to remove Approval date from Allocation Band, so District can updated the project data'\n",
    "\n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_ALN_data_error, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "fitting-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'HQ Minor Program Needs Review?'\n",
    "\n",
    "def ck_review_needs_HQ_Minor(df):\n",
    "    if (df['Is Project Project Ready for Review and Approval Date?'] == \"No\"\n",
    "        and df['Does Worplan Band needs Approval Removal?'] == 'No'\n",
    "        and df['Does Allocation Band needs Approval Removal?'] == 'No'\n",
    "       ):\n",
    "        return 'No'\n",
    "    else: \n",
    "        return \"HQ Minor Needs Review\"\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_review_needs_HQ_Minor, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "elect-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question to be answered: \n",
    "# for every project in Minor raw data, the section-in-use performance needs to be filled. \n",
    "# the performance measure unit and value should match with approved project list performance meansure, if available in approved project list. \n",
    "# if the raw data has all the information needed, including FY and performance data, and it is not only the approved project list, Minor project HQ needs to review and approve the project. \n",
    "#if the project is on the approved list, the HQ needs reach out the district to get the project close out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-pakistan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-bunch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "centered-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question to be answered: \n",
    "# do we need the following checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-symphony",
   "metadata": {},
   "source": [
    "### flag if total project cost is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "infectious-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ck_total_project_cost(df):\n",
    "    if pd.isna(df['Total Project Cost ($K)']) or df['Total Project Cost ($K)'] == 0:\n",
    "        return 'Total project cost can not Empty or zero.'\n",
    "    else:\n",
    "        return 'OK'\n",
    "    \n",
    "df_Minor_raw_data['Total Project Cost Check'] = df_Minor_raw_data.apply(ck_total_project_cost, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-destination",
   "metadata": {},
   "source": [
    "### flag if project description is blank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "colonial-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ck_project_description(df):\n",
    "    if pd.isna(df['Project Location/Description']) or df['Project Location/Description'] == '':\n",
    "        return 'Project Location/Description can not empty.'\n",
    "    else:\n",
    "        return 'OK'\n",
    "    \n",
    "df_Minor_raw_data['Project Location/Description Check'] = df_Minor_raw_data.apply(ck_project_description, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-gateway",
   "metadata": {},
   "source": [
    "### check pm validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "pleasant-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Minor_pm_invalid = df_Minor_pm_check[df_Minor_pm_check['Valid PM'] != 'Yes']\n",
    "\n",
    "AMT_IDs_withInvalidPM = df_Minor_pm_invalid['AMT_ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "exposed-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ck_invalid_pm(df):\n",
    "    if df['AMT_ID'] in AMT_IDs_withInvalidPM:\n",
    "        return 'The PM is invalid.'\n",
    "    else:\n",
    "        return 'OK'\n",
    "    \n",
    "df_Minor_raw_data['PM Validity Check'] = df_Minor_raw_data.apply(ck_invalid_pm, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-auckland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "front-might",
   "metadata": {},
   "source": [
    "<a id='Export_Data'></a>\n",
    "# Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "color-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_export_log = open(LOG_FILE, \"a\")  # append mode\n",
    "file_export_log.write(\"#####Minor Data Check:{} \\n\".format(Data_TimeStamp))\n",
    "file_export_log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "powerful-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Minor_raw_data['Data_TimeStamp'] = Data_TimeStamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-catalog",
   "metadata": {},
   "source": [
    "## export check flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "requested-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_cols = [\n",
    "    'EFIS Uniqueness Check',\n",
    "    'EA Uniqueness Check',\n",
    "    'Does Project have a Repeated EA or Project ID repeated in Minor Profile?',\n",
    "    'Does FY Need Updates?', \n",
    "    'Does EA Need Updates?',\n",
    "    'Does Program Code Need Updates?',\n",
    "    'Does Construction Capital Cost ($K) Need Updates?',\n",
    "    'Has performance raw data?',\n",
    "    'Was Performance Tab Completed in Section in Use?',\n",
    "    'Matches Minor Approved List Performance Value and Measure?',\n",
    "    'Was project with FY Before 2021/22 Closed-Out?', \n",
    " \n",
    "    #additional checks\n",
    "    'PM Validity Check',\n",
    "    'Project has at least one qualified activity?',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "robust-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export all projects with all checks in matrix\n",
    "out_cols = [\n",
    "    \n",
    "    #project information\n",
    "    'AMT_ID', 'Minor', 'EFIS', 'EA', 'District', \n",
    "    'Data_TimeStamp',\n",
    "    'Data Needs Review?',\n",
    "    'Data needs review other that Close-out?',\n",
    "                    ]\n",
    "\n",
    "out_cols.extend(ck_cols)\n",
    "\n",
    "\n",
    "filename = 'Minor_Datacheck_Matrix'\n",
    "df_out = df_Minor_raw_data[out_cols]\n",
    "\n",
    "uf.export_csv(df_out, filename, PROJECTBOOKCHECK_HTTPSERVER_FOLDER, LOG_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "split-macedonia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 2539it [00:00, 25140.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'Extract' does not exist in extract Minor_Datacheck_Punchlist.hyper, creating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 4610it [00:00, 24520.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing Minor_Datacheck_Punchlist.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "#table 1\n",
    "\n",
    "df_melted = pd.melt(df_Minor_raw_data, \n",
    "                    id_vars=['AMT_ID'], \n",
    "                    value_vars=ck_cols, var_name = 'Check Description')\n",
    "\n",
    "df_melted.columns = ['AMT_ID','Check Description','Check Summary']\n",
    "df_melted_filtered = df_melted[df_melted['Check Summary']!= 'OK']\n",
    "\n",
    "\n",
    "out_cols = [\n",
    "    \n",
    "    #project information\n",
    "    'AMT_ID', 'Minor', 'EFIS', 'EA', 'District', 'Data_TimeStamp'\n",
    "                    ]\n",
    "\n",
    "df_out = pd.merge(df_melted_filtered, df_Minor_raw_data[out_cols],\n",
    "                  how = 'left', left_on = 'AMT_ID', right_on = 'AMT_ID')\n",
    "\n",
    "\n",
    "filename = 'Minor_Datacheck_Punchlist'\n",
    "uf.export_csv(df_out, filename, PROJECTBOOKCHECK_HTTPSERVER_FOLDER, LOG_FILE)\n",
    "\n",
    "uf.export_hyper(df_out, filename, LOG_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-mongolia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "altered-childhood",
   "metadata": {},
   "source": [
    "## Export action items for Minor District Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "swedish-monday",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 1263it [00:00, 28067.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'Extract' does not exist in extract Minor_District_Action.hyper, creating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing Minor_District_Action.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "filename = 'Minor_District_Action'\n",
    "\n",
    "out_cols = [\n",
    "    #project information\n",
    "    'AMT_ID', 'Minor', 'EFIS', 'EA', 'District', 'Data_TimeStamp',\n",
    "    'Is Project ready to enter data in the Allocation Band?'\n",
    "                    ]\n",
    "df_out = df_Minor_raw_data[out_cols]\n",
    "uf.export_csv(df_out, filename, PROJECTBOOKCHECK_HTTPSERVER_FOLDER, LOG_FILE)\n",
    "\n",
    "uf.export_hyper(df_out, filename, LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-stereo",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "underlying-timeline",
   "metadata": {},
   "source": [
    "## Export action items for Minor HQ Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "tough-needle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 1263it [00:00, 20705.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'Extract' does not exist in extract Minor_HQ_Action.hyper, creating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing Minor_HQ_Action.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "filename = 'Minor_HQ_Action'\n",
    "\n",
    "out_cols = [\n",
    "    #project information\n",
    "    'AMT_ID', 'Minor', 'EFIS', 'EA', 'District', 'Data_TimeStamp',\n",
    "    \n",
    "    'Is Project Project Ready for Review and Approval Date?',\n",
    "    'Does Worplan Band needs Approval Removal?',\n",
    "    'Does Allocation Band needs Approval Removal?',\n",
    "    'HQ Minor Program Needs Review?',\n",
    "                    ]\n",
    "df_out = df_Minor_raw_data[out_cols]\n",
    "\n",
    "uf.export_csv(df_out, filename, PROJECTBOOKCHECK_HTTPSERVER_FOLDER, LOG_FILE)\n",
    "\n",
    "uf.export_hyper(df_out, filename, LOG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-republican",
   "metadata": {},
   "source": [
    "<a id='Export_programming_summary'></a>\n",
    "\n",
    "### Export Programming Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "competitive-siemens",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 624it [00:00, 6239.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'Extract' does not exist in extract Minor_Programming_Summary.hyper, creating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 1020it [00:00, 6144.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing Minor_Programming_Summary.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "out_col =df_Programming_Summary_filtered.columns\n",
    "\n",
    "filename = 'Minor_Programming_Summary'\n",
    "df_out = df_Programming_Summary_filtered[out_col]\n",
    "df_out['Data_TimeStamp'] = Data_TimeStamp\n",
    "\n",
    "uf.export_csv(df_out, filename, PROJECTBOOKCHECK_HTTPSERVER_FOLDER, LOG_FILE)\n",
    "\n",
    "uf.export_hyper(df_out, filename, LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-vatican",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "resistant-isaac",
   "metadata": {},
   "source": [
    "\n",
    "<a id='FinalCleanUp'></a>\n",
    "## Final Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "understanding-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up tableau publishing log file\n",
    "\n",
    "import os\n",
    "import glob\n",
    "# get a recursive list of file paths that matches pattern\n",
    "fileList = glob.glob('./*.log')\n",
    "# Iterate over the list of filepaths & remove each file.\n",
    "for filePath in fileList:\n",
    "    try:\n",
    "        os.remove(filePath)\n",
    "    except OSError:\n",
    "        print(\"Error while deleting file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "durable-sponsorship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed : 16.092893600463867 seconds\n"
     ]
    }
   ],
   "source": [
    "end_time =  time.time()\n",
    "elapsed = end_time - start_time\n",
    "print('time elapsed : {} seconds'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-colony",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-exercise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-vampire",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
