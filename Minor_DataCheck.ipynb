{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "known-diagnosis",
   "metadata": {},
   "source": [
    "# Tip for quick search\n",
    "\n",
    "* Needs attention: the place where needs update or better logic\n",
    "* question to be answered: the place where things are still not clear\n",
    "* Manual Check: Unit test where you can drill in to find the data that leads to the check results for a specific project and specific check\n",
    "* TODO: things needs to be done\n",
    "* bookmark: stop point from last visit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-excess",
   "metadata": {},
   "source": [
    "# Admin Notes:\n",
    "\n",
    "\n",
    "1. The AMTool dataset is archived daily as csv files and used for the project book check. \n",
    "The csv files are located at: \n",
    "r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\DataLake'\n",
    "\n",
    "2. The excel input files are checked daily and archived with datestamp whenever it is modified.\n",
    "The continuously updated excel input files are located at: r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\excel'\n",
    "The excel input file are archived at: r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\Data_MiscInput'\n",
    "To recover the archived excel file used in project book check for a target date, select the excel file with latest datestamp but is still earlier than the target date.\n",
    "\n",
    "3. The check summary export action is logged daily. It can be used for daily monitoring. \n",
    "The file export log is located at: \\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal\\log\n",
    "\n",
    "4. The published data are at:\n",
    "\n",
    "    * csv files for district asset manager: http://svgcshopp.dot.ca.gov/DataLake/ProjectBookCheck/\n",
    "    * csv files for HQ AM: \\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal\n",
    "    * tableau workbook with live data source: https://tableau.dot.ca.gov/#/site/AssetManagement/workbooks/1815/views\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-disaster",
   "metadata": {},
   "source": [
    "# General Approach\n",
    "\n",
    "use Minor raw data as basis for data checks. \n",
    "Each project only occupies one line\n",
    "\n",
    "can expand columns, only if it will not create duplicate rows in the SHOPP raw dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-celebrity",
   "metadata": {},
   "source": [
    "# Data clean process\n",
    "\n",
    "* funding amount: remove dollar sign, \n",
    "* fill missing value, string, numerical, \n",
    "* remove leading single quote for string value\n",
    "* strip off leading and trailing space \n",
    "\n",
    "* regulate column names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-mozambique",
   "metadata": {},
   "source": [
    "# Import common modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-cheat",
   "metadata": {},
   "source": [
    "<a id='TableOfContents'></a>\n",
    "\n",
    "# Table Of Contents\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "### [Global Constants](#GlobalConstants)\n",
    "\n",
    "\n",
    "### [Load and cleanup source data](#Read_Data)\n",
    "\n",
    "\n",
    "## Add fields to SHOPP raw data (calculate and join)\n",
    "* [Calculated Fields](#AddDataColumns)\n",
    "* [Join Tables](#DataJoining)\n",
    "\n",
    "\n",
    "\n",
    "## Data Check and Export\n",
    "\n",
    "\n",
    "## [Data Check List](#Issue_Table1)\n",
    "The main table of check issues, \n",
    "one issue per row, \n",
    "\n",
    "\n",
    "* [Will_this_project_be_included_in_the_Project_Book](#Will_this_project_be_included_in_the_Project_Book)\n",
    "* [Does_project_cost_exceed_Minor_Program_limits](#Does_project_cost_exceed_Minor_Program_limits)\n",
    "\n",
    "\n",
    "\n",
    "## [Export Internal Check Summary](#Export_internal_check_summary)\n",
    "* internal check summary (csv)\n",
    "\n",
    "\n",
    "## [Final Clean Up](#FinalCleanUp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fundamental-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "\n",
    "# import requests\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "second-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "intellectual-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show dataframe without skip column\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acquired-istanbul",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using the Extract API 2.0, please save the output as .hyper format\n"
     ]
    }
   ],
   "source": [
    "# from config_datasource import *\n",
    "from projectbookcheck_utilityfunction import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-theory",
   "metadata": {},
   "source": [
    "<a id='GlobalConstants'></a>\n",
    "## Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "million-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use 'csv' to read data from data lake, use 'live' to read data directly from AmTool Server\n",
    "# DATA_SOURCE_TYPE = 'csv'\n",
    "\n",
    "# # DATALAKE_FOLDER = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\DataLake'\n",
    "\n",
    "# #input data\n",
    "# DATALAKE_FOLDER = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\DataLake'\n",
    "# PROJECTBOOKCHECK_INPUT_FOLDER = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\excel'\n",
    "\n",
    "# #output data\n",
    "# DATALAKE_HTTPSEVER_FOLDER = 'C:\\inetpub\\wwwroot\\DataLake\\ProjectBookCheck'\n",
    "# PROJECTBOOKCHECK_OUTPUT_FOLDER = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal'\n",
    "\n",
    "# #log data\n",
    "# log_folder = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal\\log'\n",
    "\n",
    "# TARGET_FY = 2021\n",
    "\n",
    "\n",
    "# # CURRENT_FY\n",
    "\n",
    "# TARGETDATE = datetime.today().strftime(\"%m-%d-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "experienced-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sorted-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETDATE = datetime.today().strftime(\"%m-%d-%Y\")\n",
    "CURRENT_FY = fiscalyear (datetime.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "quality-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regulate_EFIS(EFIS):\n",
    "    #check if is all numerical\n",
    "    #convert to 10-digit string\n",
    "    if isinstance(EFIS, str) and EFIS.strip()[0] == \"'\":\n",
    "        EFIS = EFIS[1:]\n",
    "    try: \n",
    "        return \"{:10.0f}\".format(float(EFIS))\n",
    "    except: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-profile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dense-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'Programming_Summary_'\n",
    "# df_Programming_Summary = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-ready",
   "metadata": {},
   "source": [
    "<a id='Read_Data'></a>\n",
    "\n",
    "# Read Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "artificial-handy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s151589\\Anaconda3\\envs\\dataprep\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (29,30,31,32,34) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "if DATA_SOURCE_TYPE == 'csv':\n",
    "    filename = 'Minor_Project_Details_Raw_Data_'\n",
    "    df_Minor_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE))\n",
    "\n",
    "    filename = 'Minor_Performance_Raw_Data_'\n",
    "    df_Minor_perf_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE))\n",
    "\n",
    "    filename = 'Programming_Summary_'\n",
    "    df_Programming_Summary = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE))\n",
    "\n",
    "    filename = 'Minor_Project_Postmile_Check_'\n",
    "    df_Minor_pm_check = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE), header = 0)\n",
    "\n",
    "    filename = 'Rawdata_Bridge_Worksheet_'\n",
    "    df_brg_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE), skiprows = [0], header = 0)\n",
    "\n",
    "    filename = 'Rawdata_Pavement_Worksheet_'\n",
    "    df_pav_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE), skiprows = [0], header = 1)\n",
    "\n",
    "\n",
    "    filename = 'Rawdata_Drainage_Worksheet_'\n",
    "    df_drain_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE), header = 0)\n",
    "\n",
    "\n",
    "    filename = 'Rawdata_TMS_Worksheet_'\n",
    "    df_tms_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE), header = 0)\n",
    "    \n",
    "\n",
    "else:\n",
    "    print('skip getting csv data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-cheese",
   "metadata": {},
   "source": [
    "Done with TenYrShopp_RawData_ in -13.425710678100586\n",
    "Done with TenYrShopp_PerfM_Raw_Data_ in -96.45661997795105\n",
    "Done with Rawdata_Pavement_Worksheet_ in -8.857773303985596\n",
    "Done with Rawdata_Drainage_Worksheet_ in -43.5689959526062\n",
    "Done with Rawdata_Bridge_Worksheet_ in -7.964364290237427\n",
    "Done with Rawdata_TMS_Worksheet_ in -9.304267168045044\n",
    "Done with Project_Postmile_Check_ in -12.754770517349243\n",
    "Done with Programming_Summary_ in -15.230461597442627\n",
    "Done with HM_Project_Details_Raw_Data_ in -7.1786627769470215\n",
    "Done with Minor_Project_Details_Raw_Data_ in -7.667008399963379\n",
    "total time: -222.40863466262817"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "approximate-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question answered: 2021 and 2022 approved list project id duplication will be resolved with later excel files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-oasis",
   "metadata": {},
   "source": [
    "# Data quality check and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-handling",
   "metadata": {},
   "source": [
    "<a id='Minor_Raw_Data'></a>\n",
    "\n",
    "## Minor Raw Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "solid-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rename = {'Project ID':'EFIS',\n",
    "               'ID': 'AMT_ID', \n",
    "              'FY.1': 'FY_ALN',\n",
    "               'Prog Appr Date': 'Prog Appr Date_ALN',\n",
    "               'FY': 'FY_WP',\n",
    "               'Prog Approval Date': 'Prog Appr Date_WP',\n",
    "              }\n",
    "df_Minor_raw_data = df_Minor_raw_data.rename(dict_rename, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adolescent-medicaid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1251, 78)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Minor_raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "reliable-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for programmed FY year of 9999, skip all the checks\n",
    "\n",
    "# No need to check, since the raw data is filtered before download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "amateur-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_Minor_raw_data['District'] = df_Minor_raw_data['District'].apply(remove_punction)\n",
    "df_Minor_raw_data['District'] = df_Minor_raw_data['District'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-belief",
   "metadata": {},
   "source": [
    "<a id='Minor_Perf_RawData'></a>\n",
    "## Minor_Perf_RawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "psychological-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "dict_rename_perf_rawdata = {\n",
    "                           'ID': 'AMT_ID',\n",
    "#                             'ProjectedRTL FY': 'Projected RTL FY',\n",
    "\n",
    "              }\n",
    "\n",
    "df_Minor_perf_raw_data = df_Minor_perf_raw_data.rename(dict_rename_perf_rawdata, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "neural-outside",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols_strip = ['EA','EFIS']\n",
    "for c in cols_strip :\n",
    "    df_Minor_perf_raw_data[c] = df_Minor_perf_raw_data[c].str.strip(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-economy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sustainable-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data clean \n",
    "#data type regulation\n",
    "\n",
    "df_Minor_perf_raw_data['Quantity'] = df_Minor_perf_raw_data['Quantity'].fillna(0)\n",
    "df_Minor_perf_raw_data['Assets in Good Cond'] = df_Minor_perf_raw_data['Assets in Good Cond'].fillna(0)\n",
    "df_Minor_perf_raw_data['Assets in Fair Cond'] = df_Minor_perf_raw_data['Assets in Fair Cond'].fillna(0)\n",
    "df_Minor_perf_raw_data['Assets in Poor Cond'] = df_Minor_perf_raw_data['Assets in Poor Cond'].fillna(0)\n",
    "df_Minor_perf_raw_data['New Assets Added'] = df_Minor_perf_raw_data['New Assets Added'].fillna(0)\n",
    "\n",
    "# df_Minor_perf_raw_data['EFIS'] = df_Minor_perf_raw_data['EFIS'].apply(regulate_EFIS)\n",
    "df_Minor_perf_raw_data['EFIS'] = pd.to_numeric(df_Minor_perf_raw_data['EFIS'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dedicated-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data trimming\n",
    "#row\n",
    "df_Minor_perf_raw_data= df_Minor_perf_raw_data[df_Minor_perf_raw_data['District'] != 56]\n",
    "#column\n",
    "df_Minor_perf_raw_data.drop(['PID Cycle', 'TYP','ProjectedSHOPP Cycle','RequestedRTL FY','DistrictPriority'],\n",
    "  axis='columns', inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sapphire-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Minor_perf_raw_data.name = 'df_Minor_perf_raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-tampa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "heated-edition",
   "metadata": {},
   "source": [
    "<a id='Counties'></a>\n",
    "## Counties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "standing-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Counties.xlsx'\n",
    "\n",
    "df_counties = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "virtual-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counties['Co. Name Abbr.'] = df_counties['Co. Name Abbr.'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bigger-termination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_counties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "informative-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counties.name = 'df_counties'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "spectacular-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_prog_county = df_perf_raw_prog_candidate.merge(df_counties, how = 'left', left_on = 'County', right_on = 'Co. Name Abbr.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "therapeutic-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no need for the following, already added to the df_Minor_perf_raw_data\n",
    "\n",
    "# #rename columns\n",
    "# dict_rename_4= {\n",
    "#                'Performance Objective':'Performance Objective Original', \n",
    "#               }\n",
    "\n",
    "# df_perf_raw_prog_county = df_perf_raw_prog_county.rename(dict_rename_4, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-toyota",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-liability",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "classified-boost",
   "metadata": {},
   "source": [
    "<a id='Postmile_Check'></a>\n",
    "## Postmile Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adult-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_PM_ck_rename = {\n",
    " 'ID': 'AMT_ID',\n",
    " 'â„–': 'No'                            }\n",
    "df_Minor_pm_check.rename(dict_PM_ck_rename, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "alike-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Minor_pm_check['District'] = df_Minor_pm_check['District'].str.strip(\"'\")\n",
    "df_Minor_pm_check['District'] =df_Minor_pm_check['District'].astype(int)\n",
    "df_Minor_pm_check = df_Minor_pm_check[df_Minor_pm_check['District']!= 56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "molecular-passenger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1610, 29)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Minor_pm_check.name = 'df_Minor_pm_check'\n",
    "df_Minor_pm_check.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-cookie",
   "metadata": {},
   "source": [
    "<a id='ProgrammingSummary'></a>\n",
    "## Programming Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "medium-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_renamee = {'ID': 'AMT_ID',\n",
    "                               }\n",
    "df_Programming_Summary.rename(dict_renamee, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "entertaining-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_strip = ['EA','EFIS']\n",
    "for c in cols_strip :\n",
    "    df_Programming_Summary[c] = df_Programming_Summary[c].str.strip(\"'\")\n",
    "    \n",
    "df_Programming_Summary['EFIS'] = df_Programming_Summary['EFIS'].apply(regulate_EFIS)\n",
    "df_Programming_Summary['EFIS'] = pd.to_numeric(df_Programming_Summary['EFIS'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "loved-brown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District</th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>EA</th>\n",
       "      <th>EFIS</th>\n",
       "      <th>Section</th>\n",
       "      <th>Program Code</th>\n",
       "      <th>Activity Category</th>\n",
       "      <th>Asset Class</th>\n",
       "      <th>Asset</th>\n",
       "      <th>Performance Value</th>\n",
       "      <th>Performance Measure</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Pre-Good</th>\n",
       "      <th>Pre-Fair</th>\n",
       "      <th>Pre-Poor</th>\n",
       "      <th>Pre-Total</th>\n",
       "      <th>Post Good</th>\n",
       "      <th>New</th>\n",
       "      <th>Post Good+New</th>\n",
       "      <th>Post-Fair</th>\n",
       "      <th>Post-Poor</th>\n",
       "      <th>Post-Total</th>\n",
       "      <th>Program</th>\n",
       "      <th>Type</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>9000</td>\n",
       "      <td>39610</td>\n",
       "      <td>500000514.0</td>\n",
       "      <td>PPC</td>\n",
       "      <td>'201.111</td>\n",
       "      <td>Bridge - Scour</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Bridge</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bridge(s)</td>\n",
       "      <td>Square Feet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SHOPP</td>\n",
       "      <td>Programmed</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>9000</td>\n",
       "      <td>39610</td>\n",
       "      <td>500000514.0</td>\n",
       "      <td>PRG</td>\n",
       "      <td>'201.111</td>\n",
       "      <td>Bridge - Scour</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Bridge</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bridge(s)</td>\n",
       "      <td>Square Feet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SHOPP</td>\n",
       "      <td>Programmed</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>9008</td>\n",
       "      <td>16030</td>\n",
       "      <td>400000429.0</td>\n",
       "      <td>PPC</td>\n",
       "      <td>'201.110</td>\n",
       "      <td>Bridge - Health</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Bridge</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bridge(s)</td>\n",
       "      <td>Square Feet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9515.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9515.0</td>\n",
       "      <td>9515.0</td>\n",
       "      <td>18545.0</td>\n",
       "      <td>28060.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28060.0</td>\n",
       "      <td>SHOPP</td>\n",
       "      <td>Programmed</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9008</td>\n",
       "      <td>16030</td>\n",
       "      <td>400000429.0</td>\n",
       "      <td>PRG</td>\n",
       "      <td>'201.110</td>\n",
       "      <td>Bridge - Health</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Bridge</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bridge(s)</td>\n",
       "      <td>Square Feet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9515.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9515.0</td>\n",
       "      <td>9515.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9515.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9515.0</td>\n",
       "      <td>SHOPP</td>\n",
       "      <td>Programmed</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>9014</td>\n",
       "      <td>43640</td>\n",
       "      <td>100000193.0</td>\n",
       "      <td>PPC</td>\n",
       "      <td>'201.110</td>\n",
       "      <td>Bridge - Health</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Bridge</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bridge(s)</td>\n",
       "      <td>Square Feet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33314.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33314.0</td>\n",
       "      <td>33314.0</td>\n",
       "      <td>18961.0</td>\n",
       "      <td>52275.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52275.0</td>\n",
       "      <td>SHOPP</td>\n",
       "      <td>Programmed</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   District AMT_ID     EA         EFIS Section Program Code Activity Category  \\\n",
       "0         5   9000  39610  500000514.0     PPC     '201.111    Bridge - Scour   \n",
       "1         5   9000  39610  500000514.0     PRG     '201.111    Bridge - Scour   \n",
       "2         4   9008  16030  400000429.0     PPC     '201.110   Bridge - Health   \n",
       "3         4   9008  16030  400000429.0     PRG     '201.110   Bridge - Health   \n",
       "4         1   9014  43640  100000193.0     PPC     '201.110   Bridge - Health   \n",
       "\n",
       "  Asset Class   Asset  Performance Value Performance Measure         Unit  \\\n",
       "0     Primary  Bridge                0.0           Bridge(s)  Square Feet   \n",
       "1     Primary  Bridge                1.0           Bridge(s)  Square Feet   \n",
       "2     Primary  Bridge                1.0           Bridge(s)  Square Feet   \n",
       "3     Primary  Bridge                1.0           Bridge(s)  Square Feet   \n",
       "4     Primary  Bridge                1.0           Bridge(s)  Square Feet   \n",
       "\n",
       "  Pre-Good Pre-Fair Pre-Poor  Pre-Total Post Good      New Post Good+New  \\\n",
       "0      0.0      0.0      0.0        0.0       0.0      0.0           0.0   \n",
       "1      0.0      0.0      0.0        0.0       0.0      0.0           0.0   \n",
       "2      0.0   9515.0      0.0     9515.0    9515.0  18545.0       28060.0   \n",
       "3      0.0   9515.0      0.0     9515.0    9515.0      0.0        9515.0   \n",
       "4      0.0  33314.0      0.0    33314.0   33314.0  18961.0       52275.0   \n",
       "\n",
       "  Post-Fair Post-Poor  Post-Total Program        Type  Status  \n",
       "0       0.0       0.0         0.0   SHOPP  Programmed  Active  \n",
       "1       0.0       0.0         0.0   SHOPP  Programmed  Active  \n",
       "2       0.0       0.0     28060.0   SHOPP  Programmed  Active  \n",
       "3       0.0       0.0      9515.0   SHOPP  Programmed  Active  \n",
       "4       0.0       0.0     52275.0   SHOPP  Programmed  Active  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Programming_Summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-secretary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "amazing-siemens",
   "metadata": {},
   "source": [
    "# Approved Project List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "amateur-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read xlsx files\n",
    "df_approved_2021 = pd.read_excel(r'{}\\{}'.format('H:\\Jupyter\\Dev\\data', 'FY2021_Minor Approved list.xlsx'))\n",
    "df_approved_2022 = pd.read_excel(r'{}\\{}'.format('H:\\Jupyter\\Dev\\data', 'FY2022_Minor Approved list.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "revolutionary-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approved_2021['In the 2021 Approved List?'] = 'Yes'\n",
    "df_approved_2022['In the 2022 Approved List?'] = 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "refined-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question answered: should 2021 and 2022 approved list be treated seperately?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "palestinian-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rename = {\n",
    "    'Project ID':'EFIS',\n",
    "    'Total Project Cost ($K)': 'Construction Capital Cost ($K)'\n",
    "}\n",
    "df_approved_2021 = df_approved_2021.rename(dict_rename, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "forty-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rename = {\n",
    "    'Project ID':'EFIS',\n",
    "    'Contruction': 'Construction Capital Cost ($K)'\n",
    "              }\n",
    "df_approved_2022 = df_approved_2022.rename(dict_rename, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "japanese-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approved_2021['EFIS'] = df_approved_2021['EFIS'].apply(regulate_EFIS)\n",
    "df_approved_2022['EFIS'] = df_approved_2022['EFIS'].apply(regulate_EFIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "wrapped-robinson",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approved_2021['EFIS'] = pd.to_numeric(df_approved_2021['EFIS'], errors='coerce')\n",
    "df_approved_2022['EFIS'] = pd.to_numeric(df_approved_2022['EFIS'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "french-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approved_2021['Approve Year'] = 21\n",
    "df_approved_2022['Approve Year'] = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "supposed-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['EFIS','EA','Performance Value','Performance Measure','Approve Year','Program Code','Construction Capital Cost ($K)']\n",
    "\n",
    "df_approved = df_approved_2021[target_cols].append(df_approved_2022[target_cols])\n",
    "# only use 21 to check if project is in both 21 and 22\n",
    "df_approved = df_approved.sort_values(by =['EFIS','Approve Year'], ascending = True)\n",
    "df_approved = df_approved.groupby('EFIS').first().reset_index()\n",
    "\n",
    "df_approved['In the Approved List?'] = 'Yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-drinking",
   "metadata": {},
   "source": [
    "<a id='AddDataColumns'></a>\n",
    "## Calculate and join additional fields\n",
    "\n",
    "- Section\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- County\n",
    "- Route\n",
    "- End Postmile\n",
    "- Begin Postmile\n",
    "\n",
    "\n",
    "* Advertised Year\n",
    "* Last Year FY POR\n",
    "* Last Year of Fiscal Year\n",
    "* Will this project be included in the Project Book?\n",
    "* AM Tool RTL (Section in Use)\n",
    "* FY\n",
    "* Activity (group)\n",
    "\n",
    "* Total Project Cost ($K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "lovely-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this logic needs to consider the programming list\n",
    "df_Minor_raw_data['Section'] = df_Minor_raw_data['Section In Use']\n",
    "\n",
    "df_Minor_raw_data['Unique EA'] = df_Minor_raw_data.apply(calc_unique_EA, axis = 1)\n",
    "\n",
    "df_Minor_raw_data['FY In Use'] = df_Minor_raw_data['FY.2'].str[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "animated-water",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15091, 25)\n",
      "(15091, 25)\n"
     ]
    }
   ],
   "source": [
    "#filter data to keep Minor program and active section only.\n",
    "# df_Programming_Summary\n",
    "print(df_Programming_Summary.shape)\n",
    "df_Programming_Summary_filtered = pd.merge(df_Programming_Summary, df_Minor_raw_data[['AMT_ID','Section',]],\n",
    "               how= 'inner', left_on = ['AMT_ID','Section',], right_on = ['AMT_ID','Section',])\n",
    "print(df_Programming_Summary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "accepted-village",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15091, 25)\n",
      "(15091, 25)\n"
     ]
    }
   ],
   "source": [
    "print(df_Programming_Summary.shape)\n",
    "df_Programming_Summary_filtered = pd.merge(df_Programming_Summary_filtered, df_approved,\n",
    "               how= 'left', left_on = ['EFIS'], right_on = ['EFIS'],\n",
    "               suffixes=['','_ApprovedList'])\n",
    "print(df_Programming_Summary.shape)\n",
    "df_Programming_Summary_filtered['In the Approved List?'].fillna('No', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "miniature-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Matches Minor Approved List Performance Measure?'\n",
    "\n",
    "def ck_performance_measure(df):\n",
    "    if pd.isna(df['Performance Measure_ApprovedList']):\n",
    "        return 'Not in the Approved Lists'\n",
    "    else:\n",
    "        if df['Performance Measure_ApprovedList'] == df['Performance Measure']:\n",
    "            return 'Yes'\n",
    "        else:\n",
    "            return 'No'\n",
    "\n",
    "df_Programming_Summary_filtered[ck_col]= df_Programming_Summary_filtered.apply(ck_performance_measure, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "engaged-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ck_col = 'Matches Minor Approved List Performance Value?'\n",
    "def ck_performance_value(df):\n",
    "    if pd.isna(df['Performance Value_ApprovedList']):\n",
    "        return 'Not in the Approved Lists'\n",
    "    else:\n",
    "        if df['Performance Value_ApprovedList'] == df['Performance Value']:\n",
    "            return 'Yes'\n",
    "        else:\n",
    "            return 'No'\n",
    "\n",
    "df_Programming_Summary_filtered[ck_col]= df_Programming_Summary_filtered.apply(ck_performance_value, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "parallel-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Matches Minor Approved List Performance Value and Measure?'\n",
    "def ck_performance(df):\n",
    "    if df['Matches Minor Approved List Performance Value?'] == 'Not in the Approved Lists':\n",
    "        return 'Not in the Approved Lists'\n",
    "    elif (df['Matches Minor Approved List Performance Value?'] == 'Yes') and (df['Matches Minor Approved List Performance Measure?'] == 'Yes'):\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return 'No'\n",
    "    \n",
    "\n",
    "df_Programming_Summary_filtered[ck_col]= df_Programming_Summary_filtered.apply(ck_performance, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-truth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "responsible-nitrogen",
   "metadata": {},
   "source": [
    "# Check Minor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "hindu-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Minor_raw_data['Program Code in Use'] = df_Minor_raw_data.apply(lambda x: x['Program Code'] if x['Section In Use'] == 'WP' else x['Program Code.1'], axis = 1)\n",
    "\n",
    "df_Minor_raw_data['Const Capital in Use'] = df_Minor_raw_data.apply(lambda x: x['Construction Capital ($K)'] if x['Section In Use'] == 'WP' else x['Total Capital Project Cost ($K)'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "geographic-panel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question answered: we focus on checking the data only in the Section in Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "attended-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Minor_raw_data_backup = df_Minor_raw_data.copy()\n",
    "\n",
    "# df_Minor_raw_data = df_Minor_raw_data_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "through-bristol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1251, 83)\n",
      "(1251, 88)\n"
     ]
    }
   ],
   "source": [
    "print(df_Minor_raw_data.shape)\n",
    "\n",
    "df_Minor_raw_data = pd.merge(df_Minor_raw_data, df_approved[['EFIS','EA','In the Approved List?','Approve Year','Program Code','Construction Capital Cost ($K)' ]],\n",
    "                            how = 'left', left_on = 'EFIS', right_on = 'EFIS', suffixes=['','_ApprovedList'])\n",
    "\n",
    "print(df_Minor_raw_data.shape)\n",
    "\n",
    "df_Minor_raw_data['In the Approved List?'].fillna('No', inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "extensive-wealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Minor_raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "paperback-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ck_match_2022_approved_list(df):\n",
    "    if df['In the Approved List?'] == 'Yes' and df['Approve Year'] == 22:\n",
    "        if df['FY In Use'] == 22:\n",
    "            return 'OK'\n",
    "        else:\n",
    "            return r'The FY {} does not match Approved year {}'.format(df['FY In Use'], df['Approve Year'])\n",
    "    else:\n",
    "        return 'Not in the 2022 Approved list'\n",
    "\n",
    "ck_col = 'FY Matches 2022 List?'\n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_match_2022_approved_list, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-begin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-active",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "binding-improvement",
   "metadata": {},
   "source": [
    "### is EFIS duplicate within Minor raw data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "complimentary-platinum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1251, 89)\n",
      "(1251, 90)\n"
     ]
    }
   ],
   "source": [
    "temp = df_Minor_raw_data.groupby(['EFIS'])['AMT_ID'].nunique().reset_index(name = 'EFIS_Counts')\n",
    "duplicated_EFIS= temp[temp['EFIS_Counts']> 1]\n",
    "\n",
    "df_Minor_raw_data.drop(columns=['EFIS_Counts'],inplace=True , errors='ignore')\n",
    "print(df_Minor_raw_data.shape)\n",
    "df_Minor_raw_data = pd.merge(df_Minor_raw_data, duplicated_EFIS[['EFIS','EFIS_Counts']].drop_duplicates(), \n",
    "                             how = 'left', left_on = ['EFIS'], right_on=['EFIS'])\n",
    "print(df_Minor_raw_data.shape)\n",
    "\n",
    "\n",
    "def ck_EFIS_Uniqueness(df):\n",
    "    if pd.isna(df['EFIS_Counts']):\n",
    "        return 'OK'\n",
    "    else:\n",
    "        return 'Duplicate EFIS is found.'\n",
    "    \n",
    "df_Minor_raw_data['EFIS Uniqueness Check'] = df_Minor_raw_data.apply(ck_EFIS_Uniqueness, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "instructional-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Minor_raw_data['EFIS Uniqueness Check'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "improving-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #flag if EFIS is invalid\n",
    "# def ck_invalid_EFIS(df):\n",
    "#     if len(str(EFIS)) < 5: \n",
    "#         return 'Invalid EFIS'\n",
    "#     else:\n",
    "#         return 'OK'\n",
    "# df_Minor_raw_data['EFIS is valid?'] = df_Minor_raw_data['EFIS'].apply(ck_invalid_EFIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "concrete-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Minor_raw_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-worst",
   "metadata": {},
   "source": [
    "### flag if District + EA duplicate within Minor raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "recovered-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_Minor_raw_data.groupby(['Unique EA'])['AMT_ID'].nunique().reset_index(name = 'UnqiueEA_Counts')\n",
    "duplicated_EA= temp[temp['UnqiueEA_Counts']> 1]\n",
    "\n",
    "df_Minor_raw_data.drop(columns=['UnqiueEA_Counts'],inplace=True , errors='ignore')\n",
    "\n",
    "df_Minor_raw_data = pd.merge(df_Minor_raw_data, duplicated_EA[['Unique EA','UnqiueEA_Counts']].drop_duplicates(), \n",
    "                             how = 'left', left_on = ['Unique EA'], right_on=['Unique EA'])\n",
    "\n",
    "def ck_EA_Uniqueness(df):\n",
    "    if pd.isna(df['UnqiueEA_Counts']):\n",
    "        return 'OK'\n",
    "    else:\n",
    "        return 'Duplicate District+EA is found.'\n",
    "    \n",
    "df_Minor_raw_data['EA Uniqueness Check'] = df_Minor_raw_data.apply(ck_EA_Uniqueness, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-carter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "joint-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Does Project have a Repeated EA or Project ID repeated in Minor Profile?'\n",
    "\n",
    "def ck_ID_Uniqueness(df):\n",
    "    if df['EA Uniqueness Check'] == 'OK' and df['EA Uniqueness Check'] == 'OK':\n",
    "        return 'OK'\n",
    "    else:\n",
    "        return 'Duplicate District+EA and/or Project ID(EFIS) is found.'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_ID_Uniqueness, axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-pound",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "western-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does FY Need Updates?\n",
    "\n",
    "\n",
    "def ck_FY_consistancy(df):\n",
    "    if df['In the Approved List?'] == 'Yes':\n",
    "        if df['FY In Use'] == df['Approve Year']:\n",
    "            return 'OK'\n",
    "        else:\n",
    "            return 'Please update FY. It is in the {} Approved List'.format(df['Approve Year'])\n",
    "    else:\n",
    "        return 'OK'\n",
    "    \n",
    "df_Minor_raw_data['Does FY Need Updates?'] = df_Minor_raw_data.apply(ck_FY_consistancy, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "intelligent-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does EA Need Updates?\n",
    "\n",
    "def ck_EA_consistancy(df):\n",
    "    \n",
    "    if df['EA'] == df['EA_ApprovedList']:\n",
    "        return 'OK'\n",
    "    else:\n",
    "        return 'Update EA. It does not match EA in Approved List of year {}'.format(df['Approve Year'])\n",
    "    \n",
    "df_Minor_raw_data['Does EA Need Updates?'] = df_Minor_raw_data.apply(ck_EA_consistancy, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "surgical-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does Program Code Need Updates?\n",
    "\n",
    "ck_col = 'Does Program Code Need Updates?'\n",
    "\n",
    "def ck_program_code_update(df):\n",
    "    if pd.isna(df['Program Code_ApprovedList']) or (df['Program Code in Use'] == df['Program Code_ApprovedList']):\n",
    "        return 'OK'\n",
    "    else:\n",
    "        return 'The program code for Section In Use does not match Approved project list.'\n",
    "\n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_program_code_update, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "smooth-jaguar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OK                                                                           1217\n",
       "The program code for Section In Use does not match Approved project list.      34\n",
       "Name: Does Program Code Need Updates?, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ck_col = 'Does Program Code Need Updates?'\n",
    "df_Minor_raw_data[ck_col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "prepared-pasta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Program Code in Use</th>\n",
       "      <th>Program Code_ApprovedList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>MB000076</td>\n",
       "      <td>201.354</td>\n",
       "      <td>201.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>MB000215</td>\n",
       "      <td>201.150</td>\n",
       "      <td>201.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>MB000220</td>\n",
       "      <td>201.015</td>\n",
       "      <td>201.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>MB000234</td>\n",
       "      <td>201.121</td>\n",
       "      <td>201.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>MB000256</td>\n",
       "      <td>201.170</td>\n",
       "      <td>201.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>MB000286</td>\n",
       "      <td>201.351</td>\n",
       "      <td>201.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>MB000294</td>\n",
       "      <td>201.151</td>\n",
       "      <td>201.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>MA000299</td>\n",
       "      <td>201.351</td>\n",
       "      <td>201.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>MB000371</td>\n",
       "      <td>201.999</td>\n",
       "      <td>201.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>MB000448</td>\n",
       "      <td>201.151</td>\n",
       "      <td>201.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>MB000491</td>\n",
       "      <td>201.130</td>\n",
       "      <td>201.131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>MB000599</td>\n",
       "      <td>201.121</td>\n",
       "      <td>201.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>MB000638</td>\n",
       "      <td>201.010</td>\n",
       "      <td>201.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>MB000649</td>\n",
       "      <td>201.210</td>\n",
       "      <td>201.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>MB000650</td>\n",
       "      <td>201.235</td>\n",
       "      <td>201.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>MB000657</td>\n",
       "      <td>201.010</td>\n",
       "      <td>201.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>MB000658</td>\n",
       "      <td>201.010</td>\n",
       "      <td>201.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>MB000662</td>\n",
       "      <td>201.122</td>\n",
       "      <td>201.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>MB000668</td>\n",
       "      <td>201.122</td>\n",
       "      <td>201.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>MB000675</td>\n",
       "      <td>201.235</td>\n",
       "      <td>201.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>MB000683</td>\n",
       "      <td>201.240</td>\n",
       "      <td>201.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>MB000752</td>\n",
       "      <td>201.250</td>\n",
       "      <td>201.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>MB000754</td>\n",
       "      <td>201.151</td>\n",
       "      <td>201.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>MB000758</td>\n",
       "      <td>201.151</td>\n",
       "      <td>201.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>MB000957</td>\n",
       "      <td>201.130</td>\n",
       "      <td>201.131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>MB001108</td>\n",
       "      <td>201.235</td>\n",
       "      <td>201.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>MB001109</td>\n",
       "      <td>201.235</td>\n",
       "      <td>201.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>MB001131</td>\n",
       "      <td>201.010</td>\n",
       "      <td>201.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>MB001149</td>\n",
       "      <td>201.235</td>\n",
       "      <td>201.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>MB001175</td>\n",
       "      <td>201.010</td>\n",
       "      <td>201.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>MB001186</td>\n",
       "      <td>201.015</td>\n",
       "      <td>201.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>MB001237</td>\n",
       "      <td>201.310</td>\n",
       "      <td>201.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>MB001322</td>\n",
       "      <td>201.352</td>\n",
       "      <td>201.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>MB001359</td>\n",
       "      <td>201.015</td>\n",
       "      <td>201.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AMT_ID  Program Code in Use  Program Code_ApprovedList\n",
       "65    MB000076              201.354                    201.015\n",
       "186   MB000215              201.150                    201.310\n",
       "191   MB000220              201.015                    201.151\n",
       "201   MB000234              201.121                    201.010\n",
       "220   MB000256              201.170                    201.010\n",
       "246   MB000286              201.351                    201.352\n",
       "252   MB000294              201.151                    201.010\n",
       "256   MA000299              201.351                    201.352\n",
       "320   MB000371              201.999                    201.015\n",
       "381   MB000448              201.151                    201.130\n",
       "412   MB000491              201.130                    201.131\n",
       "491   MB000599              201.121                    201.120\n",
       "526   MB000638              201.010                    201.235\n",
       "537   MB000649              201.210                    201.122\n",
       "538   MB000650              201.235                    201.310\n",
       "544   MB000657              201.010                    201.235\n",
       "545   MB000658              201.010                    201.235\n",
       "549   MB000662              201.122                    201.120\n",
       "555   MB000668              201.122                    201.010\n",
       "561   MB000675              201.235                    201.010\n",
       "569   MB000683              201.240                    201.235\n",
       "627   MB000752              201.250                    201.130\n",
       "629   MB000754              201.151                    201.130\n",
       "633   MB000758              201.151                    201.130\n",
       "805   MB000957              201.130                    201.131\n",
       "940   MB001108              201.235                    201.352\n",
       "941   MB001109              201.235                    201.150\n",
       "961   MB001131              201.010                    201.170\n",
       "979   MB001149              201.235                    201.015\n",
       "1004  MB001175              201.010                    201.120\n",
       "1014  MB001186              201.015                    201.010\n",
       "1061  MB001237              201.310                    201.315\n",
       "1143  MB001322              201.352                    201.010\n",
       "1175  MB001359              201.015                    201.010"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Minor_raw_data[df_Minor_raw_data['Does Program Code Need Updates?'] != 'OK'][['AMT_ID','Program Code in Use','Program Code_ApprovedList']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-criticism",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "pleased-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drainage, needs to have at least one C activity id\n",
    "# bridge,needs to have at least one A activity id\n",
    "# pavement: needs to have at least one B activity id\n",
    "# safety: needs to have at least one within the list []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "considered-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ck_shape(*args, **kwargs):\n",
    "#     def wrapper_func(original_func):\n",
    "#         print (kwargs['df'].shape)\n",
    "#         results = original_func(*args, **kwargs)\n",
    "#         print (kwargs['df']..shape)\n",
    "#         return results\n",
    "#     return wrapper_func\n",
    "\n",
    "# @ck_shape(df = df_Minor_raw_data)\n",
    "# def add(x,y):\n",
    "#     return (x+y) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "physical-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "hydraulic-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does Construction Capital Cost ($K) Need Updates?\n",
    "\n",
    "ck_col = 'Does Construction Capital Cost ($K) Need Updates?'\n",
    "\n",
    "def ck_construction_capital_cost(df):\n",
    "       \n",
    "    if abs(df['Construction Capital Cost ($K)'] - df['Const Capital in Use']) < 0.01:\n",
    "        return 'OK'\n",
    "    else:\n",
    "        # question to be answered: for construct cost ck, for 22, only check WP band if Section in WP\n",
    "        if df['Section'] == 'ALN' or (df['Section'] == 'WP' and df['Approve Year'] == 22): \n",
    "            return 'Update Capital Cost. It does not match Approved List'\n",
    "        else:\n",
    "            return 'OK'\n",
    "        \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_construction_capital_cost, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-glass",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "australian-focus",
   "metadata": {},
   "source": [
    "### flag if no performance\n",
    " performance value can be zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "mobile-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# FY in Use needs to be the same as the pavement, TMS worksheet plan year\n",
    "\n",
    "# flag the invalid locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "amazing-efficiency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1251, 98)\n",
      "(1251, 99)\n"
     ]
    }
   ],
   "source": [
    "ck_col = 'Was Performance Tab Completed in Section in Use?'\n",
    "\n",
    "temp = df_Minor_perf_raw_data.groupby(['AMT_ID','Section']).first().reset_index()\n",
    "temp['Has performance raw data?'] = 'Yes'\n",
    "\n",
    "df_Minor_raw_data.drop(columns=['Has performance raw data?',],inplace=True , errors='ignore')\n",
    "print(df_Minor_raw_data.shape)\n",
    "\n",
    "df_Minor_raw_data = pd.merge(df_Minor_raw_data, temp[['AMT_ID','Section','Has performance raw data?']].drop_duplicates(), \n",
    "                             how = 'left', left_on = ['AMT_ID','Section'], right_on=['AMT_ID','Section'])\n",
    "\n",
    "df_Minor_raw_data['Has performance raw data?'].fillna('No', inplace=True)\n",
    "\n",
    "print(df_Minor_raw_data.shape)\n",
    "\n",
    "\n",
    "def ck_performance_availability(df):\n",
    "    if df['Has performance raw data?'] == 'No':\n",
    "        return '\"Please complete Performance Tab in Section {}'.format(df['Section'])\n",
    "    else:\n",
    "        return 'OK'\n",
    "\n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_performance_availability, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "finnish-writing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1251, 100)\n",
      "(1251, 101)\n"
     ]
    }
   ],
   "source": [
    "# Does Performance in Section in Use Match Approved List?\n",
    "# check shape\n",
    "print(df_Minor_raw_data.shape)\n",
    "#remove column\n",
    "\n",
    "col_name = 'Matches Minor Approved List Performance Value and Measure?'\n",
    "df_Minor_raw_data.drop(columns=[col_name],inplace=True , errors='ignore')\n",
    "\n",
    "#join\n",
    "df_Minor_raw_data = pd.merge(\n",
    "    df_Minor_raw_data, \n",
    "    df_Programming_Summary_filtered[['AMT_ID', 'Section',col_name]],\n",
    "    how='left', left_on=['AMT_ID', 'Section'], right_on=['AMT_ID', 'Section']\n",
    ")\n",
    "#fill na\n",
    "#question to be answered: for projects not in the programming summary list, we assigned the performance value and measure check to No\n",
    "\n",
    "df_Minor_raw_data[col_name].fillna('No', inplace=True)\n",
    "\n",
    "print(df_Minor_raw_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "alien-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Was project with FY Before 2021/22 Closed-Out?'\n",
    "\n",
    "def ck_project_closeout_status(df):\n",
    "    if pd.isna(df['FY In Use']):\n",
    "        return 'Please Identify FY'\n",
    "    elif int(df['FY In Use']) < 22 and df['Section'] == 'ALN':\n",
    "        return 'OK'\n",
    "    else:\n",
    "        return 'Please work with HQ Minor Program to Close-out Project'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_project_closeout_status, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "elegant-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Data Needs Review?'\n",
    "\n",
    "input_cols = ['Does Project have a Repeated EA or Project ID repeated in Minor Profile?',\n",
    "       'Does FY Need Updates?', 'Does EA Need Updates?',\n",
    "       'Does Program Code Need Updates?',\n",
    "       'Does Construction Capital Cost ($K) Need Updates?',\n",
    "       'Has performance raw data?',\n",
    "       'Was Performance Tab Completed in Section in Use?',\n",
    "       'Matches Minor Approved List Performance Value and Measure?',\n",
    "       'Was project with FY Before 2021/22 Closed-Out?']\n",
    "\n",
    "def ck_review_needs(df, input_cols):\n",
    "    for col in input_cols:\n",
    "        if df[col] != 'OK:':\n",
    "            return 'District needs to review project data (Profile and/or RTL)'\n",
    "    return 'OK'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_review_needs, args = [input_cols], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "industrial-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ck_col = 'Data needs review other that Close-out?'\n",
    "\n",
    "input_cols = ['Does Project have a Repeated EA or Project ID repeated in Minor Profile?',\n",
    "       'Does FY Need Updates?', 'Does EA Need Updates?',\n",
    "       'Does Program Code Need Updates?',\n",
    "       'Does Construction Capital Cost ($K) Need Updates?',\n",
    "       'Has performance raw data?',\n",
    "       'Was Performance Tab Completed in Section in Use?',\n",
    "       'Matches Minor Approved List Performance Value and Measure?',\n",
    "#          'Was project with FY Before 2021/22 Closed-Out?'     \n",
    "       ]\n",
    "\n",
    "def ck_review_needs_2(df, input_cols):\n",
    "    for col in input_cols:\n",
    "        if df[col] != 'OK:':\n",
    "            return 'District needs to review project data (Profile and/or RTL)'\n",
    "    return 'OK'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_review_needs_2, args = [input_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "thorough-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question to be answered, can we convert the following checks into \"OK\" or others, to be used in filter out flagged items in the punchlist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "becoming-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Was information Entered in the Allocation Band?'\n",
    "\n",
    "def ck_ALN_band_info_completeness(df):\n",
    "    if pd.isna(df['FY_ALN']) or df['Has performance raw data?'] == 'No' or pd.isna(df['Total Capital Project Cost ($K)']):\n",
    "        return 'No'\n",
    "    else: \n",
    "        return 'Yes'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_ALN_band_info_completeness, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "banner-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Is Project ready to enter data in the Allocation Band?'\n",
    "\n",
    "def ck_readiness_to_enter_ALN_band(df):\n",
    "    if pd.notna(df['Prog Appr Date_WP']):  #has approval date in WP band\n",
    "        if df['Section'] == 'ALN':\n",
    "            return 'Project was closed-out'\n",
    "        elif df['Was information Entered in the Allocation Band?'] == 'Yes':\n",
    "            return 'Allocation Band needs review by HQ Minor Program. If all data Accurate HQ Minor will enter the approval date'\n",
    "        else:\n",
    "            return 'Project ready to enter data in the Allocation Band (Cost, Schedule, RTL, And/Or Performance Tab)'\n",
    "    else: \n",
    "        return 'Workplan Band needs review by HQ Minor Program. If all data Accurate HQ Minor will enter the approval date'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_readiness_to_enter_ALN_band, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-stock",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "blank-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ck_col = 'Is Project Project Ready for Review and Approval Date?'\n",
    "\n",
    "def ck_readiness_for_review(df):\n",
    "    if df['Data needs review other that Close-out?'] != 'OK':\n",
    "        return 'No'\n",
    "    elif df['FY In Use'] > 22: \n",
    "        return 'No'\n",
    "    elif pd.isna(df['Prog Appr Date_WP']):\n",
    "        return 'HQ Needs to review Workplan band and enter Approval Date if data is accurate'\n",
    "    \n",
    "    elif df['Was information Entered in the Allocation Band?'] == 'Yes':\n",
    "        if pd.notna(df['Prog Appr Date_ALN']):\n",
    "            return 'No, Project Already Closed-out'\n",
    "        else:\n",
    "            return 'HQ Needs to review Allocation band and enter Approval Date if data is accurate'\n",
    "    else:\n",
    "        return 'No'\n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_readiness_for_review, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "administrative-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Does Worplan Band needs Approval Removal?'\n",
    "\n",
    "def ck_WP_data_error(df):\n",
    "    if pd.isna(df['Prog Appr Date_WP']):  #has no approval data in WP band\n",
    "        return 'No'\n",
    "    elif (pd.isna(df['FY In Use'])\n",
    "        or int(df['FY In Use']) > 22 \n",
    "        or (df['FY In Use'] in ['21', '22'] and df['In the Approved List?'] == 'No')\n",
    "         ): \n",
    "        return 'HQ Minor Program needs to remove Approval date fromWorkplan Band, so District can updated the project FY. Project not in Approved lists or in the future'\n",
    "    else:\n",
    "        return 'No'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_WP_data_error, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "spread-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Does Allocation Band needs Approval Removal?'\n",
    "\n",
    "def ck_ALN_data_error(df):\n",
    "    if pd.isna(df['Prog Appr Date_ALN']):  #has no approval data in ALN band\n",
    "        return 'No'\n",
    "    elif df['Data needs review other that Close-out?'] == 'OK': \n",
    "        return 'No'\n",
    "    else:\n",
    "        return 'HQ Minor Program needs to remove Approval date from Allocation Band, so District can updated the project data'\n",
    "\n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_ALN_data_error, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fitting-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'HQ Minor Program Needs Review?'\n",
    "\n",
    "def ck_review_needs_HQ_Minor(df):\n",
    "    if (df['Is Project Project Ready for Review and Approval Date?'] == \"No\"\n",
    "        and df['Does Worplan Band needs Approval Removal?'] == 'No'\n",
    "        and df['Does Allocation Band needs Approval Removal?'] == 'No'\n",
    "       ):\n",
    "        return 'No'\n",
    "    else: \n",
    "        return \"HQ Minor Needs Review\"\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_review_needs_HQ_Minor, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "elect-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question to be answered: \n",
    "# for every project in Minor raw data, the section-in-use performance needs to be filled. \n",
    "# the performance measure unit and value should match with approved project list performance meansure, if available in approved project list. \n",
    "# if the raw data has all the information needed, including FY and performance data, and it is not only the approved project list, Minor project HQ needs to review and approve the project. \n",
    "#if the project is on the approved list, the HQ needs reach out the district to get the project close out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-pakistan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-bunch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "centered-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question to be answered: \n",
    "# do we need the following checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-symphony",
   "metadata": {},
   "source": [
    "### flag if total project cost is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "infectious-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ck_total_project_cost(df):\n",
    "    if pd.isna(df['Total Project Cost ($K)']) or df['Total Project Cost ($K)'] == 0:\n",
    "        return 'Total project cost can not Empty or zero.'\n",
    "    else:\n",
    "        return 'OK'\n",
    "    \n",
    "df_Minor_raw_data['Total Project Cost Check'] = df_Minor_raw_data.apply(ck_total_project_cost, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-destination",
   "metadata": {},
   "source": [
    "### flag if project description is blank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "colonial-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ck_project_description(df):\n",
    "    if pd.isna(df['Project Location/Description']) or df['Project Location/Description'] == '':\n",
    "        return 'Project Location/Description can not empty.'\n",
    "    else:\n",
    "        return 'OK'\n",
    "    \n",
    "df_Minor_raw_data['Project Location/Description Check'] = df_Minor_raw_data.apply(ck_project_description, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-gateway",
   "metadata": {},
   "source": [
    "### check pm validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "pleasant-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Minor_pm_invalid = df_Minor_pm_check[df_Minor_pm_check['Valid PM'] != 'Yes']\n",
    "\n",
    "AMT_IDs_withInvalidPM = df_Minor_pm_invalid['AMT_ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "exposed-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ck_invalid_pm(df):\n",
    "    if df['AMT_ID'] in AMT_IDs_withInvalidPM:\n",
    "        return 'The PM is invalid.'\n",
    "    else:\n",
    "        return 'OK'\n",
    "    \n",
    "df_Minor_raw_data['PM Validity Check'] = df_Minor_raw_data.apply(ck_invalid_pm, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "asian-auckland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed : 6.211516857147217 seconds\n"
     ]
    }
   ],
   "source": [
    "end_time =  time.time()\n",
    "elapsed = end_time - start_time\n",
    "print('time elapsed : {} seconds'.format(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-might",
   "metadata": {},
   "source": [
    "<a id='Export_Data'></a>\n",
    "# Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "color-container",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_HHMM = datetime.now().strftime(\"%H%M\")\n",
    "\n",
    "file_export_log = open(LOG_FILE, \"a\")  # append mode\n",
    "file_export_log.write(\"#####{}, time(HHMM):{} \\n\".format(TARGETDATE, DATA_HHMM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "powerful-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Minor_raw_data['Data_HourMinute'] = DATA_HHMM\n",
    "df_Minor_raw_data['Data_Date'] = TARGETDATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-catalog",
   "metadata": {},
   "source": [
    "## export check flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "requested-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_cols = [\n",
    "    'EFIS Uniqueness Check',\n",
    "    'EA Uniqueness Check',\n",
    "    'Does Project have a Repeated EA or Project ID repeated in Minor Profile?',\n",
    "    'Does FY Need Updates?', \n",
    "    'Does EA Need Updates?',\n",
    "    'Does Program Code Need Updates?',\n",
    "    'Does Construction Capital Cost ($K) Need Updates?',\n",
    "    'Has performance raw data?',\n",
    "    'Was Performance Tab Completed in Section in Use?',\n",
    "    'Matches Minor Approved List Performance Value and Measure?',\n",
    "    'Was project with FY Before 2021/22 Closed-Out?', \n",
    "    'Data Needs Review?',\n",
    "    'Data needs review other that Close-out?',\n",
    "           \n",
    "    #additional checks\n",
    "    'PM Validity Check',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "robust-selection",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#export all projects with all checks in matrix\n",
    "out_cols = [\n",
    "    \n",
    "    #project information\n",
    "    'AMT_ID', 'Minor', 'EFIS', 'EA', 'District', \n",
    "    'Data_Date',\n",
    "    'Data_HourMinute',\n",
    "                    ]\n",
    "\n",
    "out_cols.extend(ck_cols)\n",
    "\n",
    "\n",
    "filename = 'minor_datachecks_matrix'\n",
    "\n",
    "try: \n",
    "    df_Minor_raw_data[out_cols].to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "    shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename))\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "split-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#table 1\n",
    "\n",
    "df_melted = pd.melt(df_Minor_raw_data, \n",
    "                    id_vars=['AMT_ID'], \n",
    "                    value_vars=ck_cols, var_name = 'Check Description')\n",
    "\n",
    "df_melted.columns = ['AMT_ID','Check Description','Check Summary']\n",
    "df_melted_filtered = df_melted[df_melted['Check Summary']!= 'OK']\n",
    "\n",
    "\n",
    "out_cols = [\n",
    "    \n",
    "    #project information\n",
    "    'AMT_ID', 'Minor', 'EFIS', 'EA', 'District', \n",
    "    'Data_Date',\n",
    "    'Data_HourMinute',\n",
    "                    ]\n",
    "\n",
    "df_out = pd.merge(df_melted_filtered, df_Minor_raw_data[out_cols],\n",
    "                  how = 'left', left_on = 'AMT_ID', right_on = 'AMT_ID')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "exterior-catering",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 8185it [00:00, 22119.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing Minor_Datachecks_Punchlist.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "filename = 'Minor_Datachecks_Punchlist'\n",
    "try: \n",
    "    df_out.to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "    shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename))\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "\n",
    "hyper_name = '{}.hyper'.format(filename)\n",
    "\n",
    "try: \n",
    "    publish_datasource(df_out, hyper_name)\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}'.format(hyper_name)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}'.format(hyper_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-utility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-mongolia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "altered-childhood",
   "metadata": {},
   "source": [
    "## export action items for Minor District Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "swedish-monday",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 1251it [00:00, 25527.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing Minor_District_ActionItem.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "filename = 'Minor_District_ActionItem'\n",
    "\n",
    "out_cols = [\n",
    "    #project information\n",
    "    'AMT_ID', 'Minor', 'EFIS', 'EA', 'District', \n",
    "    'Data_Date',\n",
    "    'Data_HourMinute',\n",
    "    \n",
    "    'Is Project ready to enter data in the Allocation Band?'\n",
    "                    ]\n",
    "df_out = df_Minor_raw_data[out_cols]\n",
    "\n",
    "\n",
    "\n",
    "try: \n",
    "    df_out.to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "    shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename))\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "\n",
    "hyper_name = '{}.hyper'.format(filename)\n",
    "\n",
    "try: \n",
    "    publish_datasource(df_out, hyper_name)\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}'.format(hyper_name)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}'.format(hyper_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-stereo",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "underlying-timeline",
   "metadata": {},
   "source": [
    "## export action items for Minor HQ Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "tough-needle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 1251it [00:00, 18951.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing Minor_HQ_ActionItem.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "filename = 'Minor_HQ_ActionItem'\n",
    "\n",
    "out_cols = [\n",
    "    #project information\n",
    "    'AMT_ID', 'Minor', 'EFIS', 'EA', 'District', \n",
    "    'Data_Date',\n",
    "    'Data_HourMinute',\n",
    "    \n",
    "    'Is Project Project Ready for Review and Approval Date?',\n",
    "    'Does Worplan Band needs Approval Removal?',\n",
    "    'Does Allocation Band needs Approval Removal?',\n",
    "    'HQ Minor Program Needs Review?',\n",
    "                    ]\n",
    "df_out = df_Minor_raw_data[out_cols]\n",
    "\n",
    "try: \n",
    "    df_out.to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "    shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename))\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "\n",
    "hyper_name = '{}.hyper'.format(filename)\n",
    "\n",
    "try: \n",
    "    publish_datasource(df_out, hyper_name)\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}'.format(hyper_name)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}'.format(hyper_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-republican",
   "metadata": {},
   "source": [
    "<a id='Export_programming_summary'></a>\n",
    "\n",
    "### Export Programming Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "competitive-siemens",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 1002it [00:00, 5191.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing Minor_Programming_Summary.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "out_col =df_Programming_Summary_filtered.columns\n",
    "\n",
    "filename = 'Minor_Programming_Summary'\n",
    "df_out = df_Programming_Summary_filtered[out_col]\n",
    "df_out['Data_Date'] = TARGETDATE\n",
    "df_out['Data_HourMinute'] = DATA_HHMM\n",
    "\n",
    "try: \n",
    "    df_out.to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "    shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename))\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "\n",
    "\n",
    "hyper_name = '{}.hyper'.format(filename)\n",
    "\n",
    "try: \n",
    "    publish_datasource(df_out, hyper_name)\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}'.format(hyper_name)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}'.format(hyper_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "interested-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_export_log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-contents",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-vatican",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "resistant-isaac",
   "metadata": {},
   "source": [
    "\n",
    "<a id='FinalCleanUp'></a>\n",
    "## Final Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "understanding-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#clean up tableau publishing log file\n",
    "\n",
    "import os\n",
    "import glob\n",
    "# get a recursive list of file paths that matches pattern\n",
    "fileList = glob.glob('./*.log')\n",
    "# Iterate over the list of filepaths & remove each file.\n",
    "for filePath in fileList:\n",
    "    try:\n",
    "        os.remove(filePath)\n",
    "    except OSError:\n",
    "        print(\"Error while deleting file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "durable-sponsorship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed : 18.732501745224 seconds\n"
     ]
    }
   ],
   "source": [
    "end_time =  time.time()\n",
    "elapsed = end_time - start_time\n",
    "print('time elapsed : {} seconds'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-colony",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-exercise",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
