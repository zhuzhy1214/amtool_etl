{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "established-trailer",
   "metadata": {},
   "source": [
    "# Version Notes: \n",
    "\n",
    "### v1: \n",
    "* add Data_HourMinute for all exported datasources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-diagnosis",
   "metadata": {},
   "source": [
    "# Tip for quick search\n",
    "\n",
    "* Needs attention: the place where needs update or better logic\n",
    "* question to be answered: the place where things are still not clear\n",
    "* Manual Check: Unit test where you can drill in to find the data that leads to the check results for a specific project and specific check\n",
    "* TODO: things needs to be done\n",
    "* bookmark: stop point from last visit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-excess",
   "metadata": {},
   "source": [
    "# Admin Notes:\n",
    "\n",
    "\n",
    "1. The AMTool dataset is archived daily as csv files and used for the project book check. \n",
    "The csv files are located at: \n",
    "r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\DataLake'\n",
    "\n",
    "2. The excel input files are checked daily and archived with datestamp whenever it is modified.\n",
    "The continuously updated excel input files are located at: r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\excel'\n",
    "The excel input file are archived at: r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\Data_MiscInput'\n",
    "To recover the archived excel file used in project book check for a target date, select the excel file with latest datestamp but is still earlier than the target date.\n",
    "\n",
    "3. The check summary export action is logged daily. It can be used for daily monitoring. \n",
    "The file export log is located at: \\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal\\log\n",
    "\n",
    "4. The published data are at:\n",
    "\n",
    "    * csv files for district asset manager: http://svgcshopp.dot.ca.gov/DataLake/ProjectBookCheck/\n",
    "    * csv files for HQ AM: \\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal\n",
    "    * tableau workbook with live data source: https://tableau.dot.ca.gov/#/site/AssetManagement/workbooks/1815/views\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-disaster",
   "metadata": {},
   "source": [
    "# General Approach\n",
    "\n",
    "use Minor raw data as basis for data checks. \n",
    "Each project only occupies one line\n",
    "\n",
    "can expand columns, only if it will not create duplicate rows in the SHOPP raw dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-celebrity",
   "metadata": {},
   "source": [
    "# Data clean process\n",
    "\n",
    "* funding amount: remove dollar sign, \n",
    "* fill missing value, string, numerical, \n",
    "* remove leading single quote for string value\n",
    "* strip off leading and trailing space \n",
    "\n",
    "* regulate column names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-mozambique",
   "metadata": {},
   "source": [
    "# Import common modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-cheat",
   "metadata": {},
   "source": [
    "<a id='TableOfContents'></a>\n",
    "\n",
    "# Table Of Contents\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "### [Global Constants](#GlobalConstants)\n",
    "\n",
    "\n",
    "### [Load and cleanup source data](#Read_Data)\n",
    "\n",
    "\n",
    "## Add fields to SHOPP raw data (calculate and join)\n",
    "* [Calculated Fields](#AddDataColumns)\n",
    "* [Join Tables](#DataJoining)\n",
    "\n",
    "\n",
    "\n",
    "## Data Check and Export\n",
    "\n",
    "\n",
    "## [Data Check List](#Issue_Table1)\n",
    "The main table of check issues, \n",
    "one issue per row, \n",
    "\n",
    "\n",
    "* [Will_this_project_be_included_in_the_Project_Book](#Will_this_project_be_included_in_the_Project_Book)\n",
    "* [Does_project_cost_exceed_Minor_Program_limits](#Does_project_cost_exceed_Minor_Program_limits)\n",
    "\n",
    "\n",
    "\n",
    "## [Export Internal Check Summary](#Export_internal_check_summary)\n",
    "* internal check summary (csv)\n",
    "\n",
    "\n",
    "## [Final Clean Up](#FinalCleanUp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aggressive-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fundamental-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "\n",
    "# import requests\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "second-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "intellectual-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show dataframe without skip column\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "acquired-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from config_datasource import *\n",
    "from projectbookcheck_utilityfunction import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-theory",
   "metadata": {},
   "source": [
    "<a id='GlobalConstants'></a>\n",
    "## Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "million-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use 'csv' to read data from data lake, use 'live' to read data directly from AmTool Server\n",
    "# DATA_SOURCE_TYPE = 'csv'\n",
    "\n",
    "# # DATALAKE_FOLDER = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\DataLake'\n",
    "\n",
    "# #input data\n",
    "# DATALAKE_FOLDER = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\DataLake'\n",
    "# PROJECTBOOKCHECK_INPUT_FOLDER = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\excel'\n",
    "\n",
    "# #output data\n",
    "# DATALAKE_HTTPSEVER_FOLDER = 'C:\\inetpub\\wwwroot\\DataLake\\ProjectBookCheck'\n",
    "# PROJECTBOOKCHECK_OUTPUT_FOLDER = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal'\n",
    "\n",
    "# #log data\n",
    "# log_folder = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal\\log'\n",
    "\n",
    "# TARGET_FY = 2021\n",
    "\n",
    "\n",
    "# # CURRENT_FY\n",
    "\n",
    "# TARGETDATE = datetime.today().strftime(\"%m-%d-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "experienced-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "sorted-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETDATE = datetime.today().strftime(\"%m-%d-%Y\")\n",
    "CURRENT_FY = fiscalyear (datetime.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "quality-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regulate_EFIS(EFIS):\n",
    "    #check if is all numerical\n",
    "    #convert to 10-digit string\n",
    "    if isinstance(EFIS, str) and EFIS.strip()[0] == \"'\":\n",
    "        EFIS = EFIS[1:]\n",
    "    try: \n",
    "        return \"{:10.0f}\".format(float(EFIS))\n",
    "    except: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-profile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dense-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'Programming_Summary_'\n",
    "# df_Programming_Summary = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-ready",
   "metadata": {},
   "source": [
    "<a id='Read_Data'></a>\n",
    "\n",
    "# Read Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "artificial-handy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s151589\\Anaconda3\\envs\\dataprep\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (29,30,31,32,34) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "if DATA_SOURCE_TYPE == 'csv':\n",
    "    filename = 'Minor_Project_Details_Raw_Data_'\n",
    "    df_Minor_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE))\n",
    "\n",
    "    filename = 'Minor_Performance_Raw_Data_'\n",
    "    df_Minor_perf_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE))\n",
    "\n",
    "    filename = 'Programming_Summary_'\n",
    "    df_Programming_Summary = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE))\n",
    "\n",
    "    filename = 'Minor_Project_Postmile_Check_'\n",
    "    df_Minor_pm_check = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE), header = 0)\n",
    "\n",
    "    filename = 'Rawdata_Bridge_Worksheet_'\n",
    "    df_brg_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE), skiprows = [0], header = 0)\n",
    "\n",
    "    filename = 'Rawdata_Pavement_Worksheet_'\n",
    "    df_pav_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE), skiprows = [0], header = 1)\n",
    "\n",
    "\n",
    "    filename = 'Rawdata_Drainage_Worksheet_'\n",
    "    df_drain_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE), header = 0)\n",
    "\n",
    "\n",
    "    filename = 'Rawdata_TMS_Worksheet_'\n",
    "    df_tms_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE), header = 0)\n",
    "    \n",
    "\n",
    "else:\n",
    "    print('skip getting csv data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-cheese",
   "metadata": {},
   "source": [
    "Done with TenYrShopp_RawData_ in -13.425710678100586\n",
    "Done with TenYrShopp_PerfM_Raw_Data_ in -96.45661997795105\n",
    "Done with Rawdata_Pavement_Worksheet_ in -8.857773303985596\n",
    "Done with Rawdata_Drainage_Worksheet_ in -43.5689959526062\n",
    "Done with Rawdata_Bridge_Worksheet_ in -7.964364290237427\n",
    "Done with Rawdata_TMS_Worksheet_ in -9.304267168045044\n",
    "Done with Project_Postmile_Check_ in -12.754770517349243\n",
    "Done with Programming_Summary_ in -15.230461597442627\n",
    "Done with HM_Project_Details_Raw_Data_ in -7.1786627769470215\n",
    "Done with Minor_Project_Details_Raw_Data_ in -7.667008399963379\n",
    "total time: -222.40863466262817"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "approximate-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question answered: 2021 and 2022 approved list project id duplication will be resolved with later excel files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-oasis",
   "metadata": {},
   "source": [
    "# Data quality check and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-handling",
   "metadata": {},
   "source": [
    "<a id='Minor_Raw_Data'></a>\n",
    "\n",
    "## Minor Raw Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "solid-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rename = {'Project ID':'EFIS',\n",
    "               'ID': 'AMT_ID', \n",
    "              'FY.1': 'FY_ALN',\n",
    "               'Prog Appr Date': 'Prog Appr Date_ALN',\n",
    "               'FY': 'FY_WP',\n",
    "               'Prog Approval Date': 'Prog Appr Date_WP',\n",
    "              }\n",
    "df_Minor_raw_data = df_Minor_raw_data.rename(dict_rename, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "adolescent-medicaid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1251, 78)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Minor_raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "reliable-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for programmed FY year of 9999, skip all the checks\n",
    "\n",
    "# No need to check, since the raw data is filtered before download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "amateur-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_Minor_raw_data['District'] = df_Minor_raw_data['District'].apply(remove_punction)\n",
    "df_Minor_raw_data['District'] = df_Minor_raw_data['District'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-belief",
   "metadata": {},
   "source": [
    "<a id='Minor_Perf_RawData'></a>\n",
    "## Minor_Perf_RawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "psychological-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "dict_rename_perf_rawdata = {\n",
    "                           'ID': 'AMT_ID',\n",
    "#                             'ProjectedRTL FY': 'Projected RTL FY',\n",
    "\n",
    "              }\n",
    "\n",
    "df_Minor_perf_raw_data = df_Minor_perf_raw_data.rename(dict_rename_perf_rawdata, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "neural-outside",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols_strip = ['EA','EFIS']\n",
    "for c in cols_strip :\n",
    "    df_Minor_perf_raw_data[c] = df_Minor_perf_raw_data[c].str.strip(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-economy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "sustainable-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data clean \n",
    "#data type regulation\n",
    "\n",
    "df_Minor_perf_raw_data['Quantity'] = df_Minor_perf_raw_data['Quantity'].fillna(0)\n",
    "df_Minor_perf_raw_data['Assets in Good Cond'] = df_Minor_perf_raw_data['Assets in Good Cond'].fillna(0)\n",
    "df_Minor_perf_raw_data['Assets in Fair Cond'] = df_Minor_perf_raw_data['Assets in Fair Cond'].fillna(0)\n",
    "df_Minor_perf_raw_data['Assets in Poor Cond'] = df_Minor_perf_raw_data['Assets in Poor Cond'].fillna(0)\n",
    "df_Minor_perf_raw_data['New Assets Added'] = df_Minor_perf_raw_data['New Assets Added'].fillna(0)\n",
    "\n",
    "# df_Minor_perf_raw_data['EFIS'] = df_Minor_perf_raw_data['EFIS'].apply(regulate_EFIS)\n",
    "df_Minor_perf_raw_data['EFIS'] = pd.to_numeric(df_Minor_perf_raw_data['EFIS'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dedicated-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data trimming\n",
    "#row\n",
    "df_Minor_perf_raw_data= df_Minor_perf_raw_data[df_Minor_perf_raw_data['District'] != 56]\n",
    "#column\n",
    "df_Minor_perf_raw_data.drop(['PID Cycle', 'TYP','ProjectedSHOPP Cycle','RequestedRTL FY','DistrictPriority'],\n",
    "  axis='columns', inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "sapphire-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Minor_perf_raw_data.name = 'df_Minor_perf_raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-tampa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "heated-edition",
   "metadata": {},
   "source": [
    "<a id='Counties'></a>\n",
    "## Counties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "standing-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Counties.xlsx'\n",
    "\n",
    "df_counties = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "virtual-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counties['Co. Name Abbr.'] = df_counties['Co. Name Abbr.'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bigger-termination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 6)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_counties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "informative-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counties.name = 'df_counties'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "spectacular-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_prog_county = df_perf_raw_prog_candidate.merge(df_counties, how = 'left', left_on = 'County', right_on = 'Co. Name Abbr.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "therapeutic-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no need for the following, already added to the df_Minor_perf_raw_data\n",
    "\n",
    "# #rename columns\n",
    "# dict_rename_4= {\n",
    "#                'Performance Objective':'Performance Objective Original', \n",
    "#               }\n",
    "\n",
    "# df_perf_raw_prog_county = df_perf_raw_prog_county.rename(dict_rename_4, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-toyota",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-liability",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "classified-boost",
   "metadata": {},
   "source": [
    "<a id='Postmile_Check'></a>\n",
    "## Postmile Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "adult-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_PM_ck_rename = {\n",
    " 'ID': 'AMT_ID',\n",
    " 'â„–': 'No'                            }\n",
    "df_Minor_pm_check.rename(dict_PM_ck_rename, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "alike-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Minor_pm_check['District'] = df_Minor_pm_check['District'].str.strip(\"'\")\n",
    "df_Minor_pm_check['District'] =df_Minor_pm_check['District'].astype(int)\n",
    "df_Minor_pm_check = df_Minor_pm_check[df_Minor_pm_check['District']!= 56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "molecular-passenger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1610, 29)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Minor_pm_check.name = 'df_Minor_pm_check'\n",
    "df_Minor_pm_check.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-cookie",
   "metadata": {},
   "source": [
    "<a id='ProgrammingSummary'></a>\n",
    "## Programming Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "medium-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_renamee = {'ID': 'AMT_ID',\n",
    "                               }\n",
    "df_Programming_Summary.rename(dict_renamee, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "entertaining-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_strip = ['EA','EFIS']\n",
    "for c in cols_strip :\n",
    "    df_Programming_Summary[c] = df_Programming_Summary[c].str.strip(\"'\")\n",
    "    \n",
    "df_Programming_Summary['EFIS'] = df_Programming_Summary['EFIS'].apply(regulate_EFIS)\n",
    "df_Programming_Summary['EFIS'] = pd.to_numeric(df_Programming_Summary['EFIS'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "loved-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Programming_Summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-secretary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "amazing-siemens",
   "metadata": {},
   "source": [
    "# Approved Project List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "amateur-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read xlsx files\n",
    "df_approved_2021 = pd.read_excel(r'{}\\{}'.format('H:\\Jupyter\\Dev\\data', 'FY2021_Minor Approved list.xlsx'))\n",
    "df_approved_2022 = pd.read_excel(r'{}\\{}'.format('H:\\Jupyter\\Dev\\data', 'FY2022_Minor Approved list.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "revolutionary-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approved_2021['In the 2021 Approved List?'] = 'Yes'\n",
    "df_approved_2022['In the 2022 Approved List?'] = 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "refined-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question answered: should 2021 and 2022 approved list be treated seperately?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "palestinian-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rename = {\n",
    "    'Project ID':'EFIS',\n",
    "    'Total Project Cost ($K)': 'Construction Capital Cost ($K)'\n",
    "}\n",
    "df_approved_2021 = df_approved_2021.rename(dict_rename, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "forty-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rename = {\n",
    "    'Project ID':'EFIS',\n",
    "    'Contruction': 'Construction Capital Cost ($K)'\n",
    "              }\n",
    "df_approved_2022 = df_approved_2022.rename(dict_rename, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "japanese-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approved_2021['EFIS'] = df_approved_2021['EFIS'].apply(regulate_EFIS)\n",
    "df_approved_2022['EFIS'] = df_approved_2022['EFIS'].apply(regulate_EFIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "wrapped-robinson",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approved_2021['EFIS'] = pd.to_numeric(df_approved_2021['EFIS'], errors='coerce')\n",
    "df_approved_2022['EFIS'] = pd.to_numeric(df_approved_2022['EFIS'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "french-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approved_2021['Approve Year'] = 21\n",
    "df_approved_2022['Approve Year'] = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "supposed-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['EFIS','EA','Performance Value','Performance Measure','Approve Year','Program Code','Construction Capital Cost ($K)']\n",
    "\n",
    "df_approved = df_approved_2021[target_cols].append(df_approved_2022[target_cols])\n",
    "# only use 21 to check if project is in both 21 and 22\n",
    "df_approved = df_approved.sort_values(by =['EFIS','Approve Year'], ascending = True)\n",
    "df_approved = df_approved.groupby('EFIS').first().reset_index()\n",
    "\n",
    "df_approved['In the Approved List?'] = 'Yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-drinking",
   "metadata": {},
   "source": [
    "<a id='AddDataColumns'></a>\n",
    "## Calculate and join additional fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "lovely-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this logic needs to consider the programming list\n",
    "df_Minor_raw_data['Section'] = df_Minor_raw_data['Section In Use']\n",
    "\n",
    "df_Minor_raw_data['Unique EA'] = df_Minor_raw_data.apply(calc_unique_EA, axis = 1)\n",
    "\n",
    "df_Minor_raw_data['FY In Use'] = df_Minor_raw_data['FY.2'].str[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-hungary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "animated-water",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15091, 25)\n",
      "(1002, 25)\n"
     ]
    }
   ],
   "source": [
    "#filter data to keep Minor program and active section only.\n",
    "# df_Programming_Summary\n",
    "print(df_Programming_Summary.shape)\n",
    "df_Programming_Summary_filtered = pd.merge(df_Programming_Summary, df_Minor_raw_data[['AMT_ID','Section',]],\n",
    "               how= 'inner', left_on = ['AMT_ID','Section',], right_on = ['AMT_ID','Section',])\n",
    "print(df_Programming_Summary_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "accepted-village",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1002, 25)\n",
      "(1002, 32)\n"
     ]
    }
   ],
   "source": [
    "print(df_Programming_Summary_filtered.shape)\n",
    "df_Programming_Summary_filtered = pd.merge(df_Programming_Summary_filtered, df_approved,\n",
    "               how= 'left', left_on = ['EFIS'], right_on = ['EFIS'],\n",
    "               suffixes=['','_ApprovedList'])\n",
    "print(df_Programming_Summary_filtered.shape)\n",
    "df_Programming_Summary_filtered['In the Approved List?'].fillna('No', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "miniature-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Matches Minor Approved List Performance Measure?'\n",
    "\n",
    "def ck_performance_measure(df):\n",
    "    if pd.isna(df['Performance Measure_ApprovedList']):\n",
    "        return 'Not in the Approved Lists'\n",
    "    else:\n",
    "        if df['Performance Measure_ApprovedList'] == df['Performance Measure']:\n",
    "            return 'Yes'\n",
    "        else:\n",
    "            return 'No'\n",
    "\n",
    "df_Programming_Summary_filtered[ck_col]= df_Programming_Summary_filtered.apply(ck_performance_measure, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "engaged-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ck_col = 'Matches Minor Approved List Performance Value?'\n",
    "def ck_performance_value(df):\n",
    "    if pd.isna(df['Performance Value_ApprovedList']):\n",
    "        return 'Not in the Approved Lists'\n",
    "    else:\n",
    "        if df['Performance Value_ApprovedList'] == df['Performance Value']:\n",
    "            return 'Yes'\n",
    "        else:\n",
    "            return 'No'\n",
    "\n",
    "df_Programming_Summary_filtered[ck_col]= df_Programming_Summary_filtered.apply(ck_performance_value, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "parallel-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Matches Minor Approved List Performance Value and Measure?'\n",
    "def ck_performance(df):\n",
    "    if df['Matches Minor Approved List Performance Value?'] == 'Not in the Approved Lists':\n",
    "        return 'Not in the Approved Lists'\n",
    "    elif (df['Matches Minor Approved List Performance Value?'] == 'Yes') and (df['Matches Minor Approved List Performance Measure?'] == 'Yes'):\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return 'No'\n",
    "    \n",
    "\n",
    "df_Programming_Summary_filtered[ck_col]= df_Programming_Summary_filtered.apply(ck_performance, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-truth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "responsible-nitrogen",
   "metadata": {},
   "source": [
    "# Check Minor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "hindu-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Minor_raw_data['Program Code in Use'] = df_Minor_raw_data.apply(lambda x: x['Program Code'] if x['Section In Use'] == 'WP' else x['Program Code.1'], axis = 1)\n",
    "\n",
    "df_Minor_raw_data['Const Capital in Use'] = df_Minor_raw_data.apply(lambda x: x['Construction Capital ($K)'] if x['Section In Use'] == 'WP' else x['Total Capital Project Cost ($K)'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "geographic-panel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question answered: we focus on checking the data only in the Section in Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "attended-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Minor_raw_data_backup = df_Minor_raw_data.copy()\n",
    "\n",
    "# df_Minor_raw_data = df_Minor_raw_data_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "through-bristol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1251, 83)\n",
      "(1251, 88)\n"
     ]
    }
   ],
   "source": [
    "print(df_Minor_raw_data.shape)\n",
    "\n",
    "df_Minor_raw_data = pd.merge(df_Minor_raw_data, df_approved[['EFIS','EA','In the Approved List?','Approve Year','Program Code','Construction Capital Cost ($K)' ]],\n",
    "                            how = 'left', left_on = 'EFIS', right_on = 'EFIS', suffixes=['','_ApprovedList'])\n",
    "\n",
    "print(df_Minor_raw_data.shape)\n",
    "\n",
    "df_Minor_raw_data['In the Approved List?'].fillna('No', inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "extensive-wealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Minor_raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "paperback-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ck_match_2022_approved_list(df):\n",
    "    if df['In the Approved List?'] == 'Yes' and df['Approve Year'] == 22:\n",
    "        if df['FY In Use'] == 22:\n",
    "            return 'OK'\n",
    "        else:\n",
    "            return r'The FY {} does not match Approved year {}'.format(df['FY In Use'], df['Approve Year'])\n",
    "    else:\n",
    "        return 'Not in the 2022 Approved list'\n",
    "\n",
    "ck_col = 'FY Matches 2022 List?'\n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_match_2022_approved_list, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-begin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-active",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "binding-improvement",
   "metadata": {},
   "source": [
    "### is EFIS duplicate within Minor raw data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "complimentary-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = df_Minor_raw_data.groupby(['EFIS'])['AMT_ID'].nunique().reset_index(name = 'EFIS_Counts')\n",
    "# duplicated_EFIS= temp[temp['EFIS_Counts']> 1]\n",
    "\n",
    "# df_Minor_raw_data.drop(columns=['EFIS_Counts'],inplace=True , errors='ignore')\n",
    "# print(df_Minor_raw_data.shape)\n",
    "# df_Minor_raw_data = pd.merge(df_Minor_raw_data, duplicated_EFIS, \n",
    "#                              how = 'left', left_on = ['EFIS'], right_on=['EFIS'])\n",
    "# print(df_Minor_raw_data.shape)\n",
    "\n",
    "# def ck_EFIS_Uniqueness(df):\n",
    "#     if pd.isna(df['EFIS_Counts']):\n",
    "#         return 'OK'\n",
    "#     elif df['EFIS'] == 0: \n",
    "#         return 'Missing/Invalid EFIS'\n",
    "#     else:\n",
    "#         return 'Duplicate EFIS'\n",
    "    \n",
    "# df_Minor_raw_data['EFIS Uniqueness Check'] = df_Minor_raw_data.apply(ck_EFIS_Uniqueness, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "marked-murder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1251, 93)\n",
      "(1251, 96)\n"
     ]
    }
   ],
   "source": [
    "temp = df_Minor_raw_data.groupby(['EFIS'])['AMT_ID'].agg([pd.Series.nunique, list]).reset_index()\n",
    "temp['AMT_IDs'] = temp['list'].apply(lambda l: ','.join(l))\n",
    "duplicated_EFIS= temp[temp['nunique']> 1]\n",
    "\n",
    "df_Minor_raw_data.drop(columns=['nunique','AMT_IDs'],inplace=True , errors='ignore')\n",
    "print(df_Minor_raw_data.shape)\n",
    "df_Minor_raw_data = pd.merge(df_Minor_raw_data, duplicated_EFIS, \n",
    "                             how = 'left', left_on = ['EFIS'], right_on=['EFIS'])\n",
    "print(df_Minor_raw_data.shape)\n",
    "\n",
    "def ck_EFIS_Uniqueness(df):\n",
    "    if pd.isna(df['nunique']):\n",
    "        return 'OK'\n",
    "    elif df['EFIS'] == 0: \n",
    "        return 'Missing/Invalid EFIS'\n",
    "    else:\n",
    "        return 'Duplicate EFIS {} is found in the following projects: {}'.format(df['EFIS'], df['AMT_IDs'])\n",
    "    \n",
    "df_Minor_raw_data['EFIS Uniqueness Check'] = df_Minor_raw_data.apply(ck_EFIS_Uniqueness, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "improving-glenn",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000e+00    46\n",
       "1.120000e+09     3\n",
       "1.120000e+09     3\n",
       "1.120000e+09     3\n",
       "1.118000e+09     2\n",
       "                ..\n",
       "1.121000e+09     1\n",
       "1.170002e+08     1\n",
       "4.200003e+08     1\n",
       "3.210002e+08     1\n",
       "1.119000e+09     1\n",
       "Name: EFIS, Length: 1135, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Minor_raw_data['EFIS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Minor_raw_data['EFIS Uniqueness Check'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "collectible-memorabilia",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0C930\n",
       "1       0F080\n",
       "2       0J010\n",
       "3       0H390\n",
       "4       2H140\n",
       "        ...  \n",
       "1246    0Y130\n",
       "1247    1N840\n",
       "1248    3A492\n",
       "1249    3A510\n",
       "1250    2J600\n",
       "Name: EA, Length: 1251, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_Minor_raw_data['EA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #flag if EFIS is invalid\n",
    "# def ck_invalid_EFIS(df):\n",
    "#     if len(str(EFIS)) < 5: \n",
    "#         return 'Invalid EFIS'\n",
    "#     else:\n",
    "#         return 'OK'\n",
    "# df_Minor_raw_data['EFIS is valid?'] = df_Minor_raw_data['EFIS'].apply(ck_invalid_EFIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Minor_raw_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-worst",
   "metadata": {},
   "source": [
    "### flag if District + EA duplicate within Minor raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_Minor_raw_data.groupby(['Unique EA'])['AMT_ID'].nunique().reset_index(name = 'UnqiueEA_Counts')\n",
    "duplicated_EA= temp[temp['UnqiueEA_Counts']> 1]\n",
    "\n",
    "df_Minor_raw_data.drop(columns=['UnqiueEA_Counts'],inplace=True , errors='ignore')\n",
    "\n",
    "df_Minor_raw_data = pd.merge(df_Minor_raw_data, duplicated_EA[['Unique EA','UnqiueEA_Counts']].drop_duplicates(), \n",
    "                             how = 'left', left_on = ['Unique EA'], right_on=['Unique EA'])\n",
    "\n",
    "def ck_EA_Uniqueness(df):\n",
    "    if pd.isna(df['UnqiueEA_Counts']):\n",
    "        return 'OK'\n",
    "    else:\n",
    "        return 'Duplicate District+EA is found.'\n",
    "    \n",
    "df_Minor_raw_data['EA Uniqueness Check'] = df_Minor_raw_data.apply(ck_EA_Uniqueness, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-carter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Does Project have a Repeated EA or Project ID repeated in Minor Profile?'\n",
    "\n",
    "def ck_ID_Uniqueness(df):\n",
    "    if df['EA Uniqueness Check'] == 'OK' and df['EA Uniqueness Check'] == 'OK':\n",
    "        return 'OK'\n",
    "    else:\n",
    "        return 'Duplicate District+EA and/or Project ID(EFIS) is found.'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_ID_Uniqueness, axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-pound",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does FY Need Updates?\n",
    "\n",
    "\n",
    "def ck_FY_consistancy(df):\n",
    "    if df['In the Approved List?'] == 'Yes':\n",
    "        if df['FY In Use'] == df['Approve Year']:\n",
    "            return 'OK'\n",
    "        else:\n",
    "            return 'Please update FY. It is in the {} Approved List'.format(df['Approve Year'])\n",
    "    else:\n",
    "        return 'OK'\n",
    "    \n",
    "df_Minor_raw_data['Does FY Need Updates?'] = df_Minor_raw_data.apply(ck_FY_consistancy, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does EA Need Updates?\n",
    "\n",
    "def ck_EA_consistancy(df):\n",
    "    \n",
    "    if df['EA'] == df['EA_ApprovedList']:\n",
    "        return 'OK'\n",
    "    else:\n",
    "        return 'Update EA. It does not match EA in Approved List of year {}'.format(df['Approve Year'])\n",
    "    \n",
    "df_Minor_raw_data['Does EA Need Updates?'] = df_Minor_raw_data.apply(ck_EA_consistancy, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does Program Code Need Updates?\n",
    "\n",
    "ck_col = 'Does Program Code Need Updates?'\n",
    "\n",
    "def ck_program_code_update(df):\n",
    "    if pd.isna(df['Program Code_ApprovedList']) or (df['Program Code in Use'] == df['Program Code_ApprovedList']):\n",
    "        return 'OK'\n",
    "    else:\n",
    "        return 'The program code for Section In Use does not match Approved project list.'\n",
    "\n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_program_code_update, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ck_col = 'Does Program Code Need Updates?'\n",
    "# df_Minor_raw_data[ck_col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Minor_raw_data[df_Minor_raw_data['Does Program Code Need Updates?'] != 'OK'][['AMT_ID','Program Code in Use','Program Code_ApprovedList']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-criticism",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drainage, needs to have at least one C activity id\n",
    "# bridge,needs to have at least one A activity id\n",
    "# pavement: needs to have at least one B activity id\n",
    "# safety: needs to have at least one within the list []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ck_shape(*args, **kwargs):\n",
    "#     def wrapper_func(original_func):\n",
    "#         print (kwargs['df'].shape)\n",
    "#         results = original_func(*args, **kwargs)\n",
    "#         print (kwargs['df']..shape)\n",
    "#         return results\n",
    "#     return wrapper_func\n",
    "\n",
    "# @ck_shape(df = df_Minor_raw_data)\n",
    "# def add(x,y):\n",
    "#     return (x+y) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does Construction Capital Cost ($K) Need Updates?\n",
    "\n",
    "ck_col = 'Does Construction Capital Cost ($K) Need Updates?'\n",
    "\n",
    "def ck_construction_capital_cost(df):\n",
    "       \n",
    "    if abs(df['Construction Capital Cost ($K)'] - df['Const Capital in Use']) < 0.01:\n",
    "        return 'OK'\n",
    "    else:\n",
    "        # question to be answered: for construct cost ck, for 22, only check WP band if Section in WP\n",
    "        if df['Section'] == 'ALN' or (df['Section'] == 'WP' and df['Approve Year'] == 22): \n",
    "            return 'Update Capital Cost. It does not match Approved List'\n",
    "        else:\n",
    "            return 'OK'\n",
    "        \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_construction_capital_cost, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-glass",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "australian-focus",
   "metadata": {},
   "source": [
    "### flag if no performance\n",
    " performance value can be zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# FY in Use needs to be the same as the pavement, TMS worksheet plan year\n",
    "\n",
    "# flag the invalid locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Was Performance Tab Completed in Section in Use?'\n",
    "\n",
    "temp = df_Minor_perf_raw_data.groupby(['AMT_ID','Section']).first().reset_index()\n",
    "temp['Has performance raw data?'] = 'Yes'\n",
    "\n",
    "df_Minor_raw_data.drop(columns=['Has performance raw data?',],inplace=True , errors='ignore')\n",
    "print(df_Minor_raw_data.shape)\n",
    "\n",
    "df_Minor_raw_data = pd.merge(df_Minor_raw_data, temp[['AMT_ID','Section','Has performance raw data?']].drop_duplicates(), \n",
    "                             how = 'left', left_on = ['AMT_ID','Section'], right_on=['AMT_ID','Section'])\n",
    "\n",
    "df_Minor_raw_data['Has performance raw data?'].fillna('No', inplace=True)\n",
    "\n",
    "print(df_Minor_raw_data.shape)\n",
    "\n",
    "\n",
    "def ck_performance_availability(df):\n",
    "    if df['Has performance raw data?'] == 'No':\n",
    "        return '\"Please complete Performance Tab in Section {}'.format(df['Section'])\n",
    "    else:\n",
    "        return 'OK'\n",
    "\n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_performance_availability, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-writing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does Performance in Section in Use Match Approved List?\n",
    "# check shape\n",
    "print(df_Minor_raw_data.shape)\n",
    "#remove column\n",
    "\n",
    "col_name = 'Matches Minor Approved List Performance Value and Measure?'\n",
    "df_Minor_raw_data.drop(columns=[col_name],inplace=True , errors='ignore')\n",
    "\n",
    "#join\n",
    "df_Minor_raw_data = pd.merge(\n",
    "    df_Minor_raw_data, \n",
    "    df_Programming_Summary_filtered[['AMT_ID', 'Section',col_name]],\n",
    "    how='left', left_on=['AMT_ID', 'Section'], right_on=['AMT_ID', 'Section']\n",
    ")\n",
    "#fill na\n",
    "#question to be answered: for projects not in the programming summary list, we assigned the performance value and measure check to No\n",
    "\n",
    "df_Minor_raw_data[col_name].fillna('No', inplace=True)\n",
    "\n",
    "print(df_Minor_raw_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Was project with FY Before 2021/22 Closed-Out?'\n",
    "\n",
    "def ck_project_closeout_status(df):\n",
    "    if pd.isna(df['FY In Use']):\n",
    "        return 'Please Identify FY'\n",
    "    elif int(df['FY In Use']) < 22 and df['Section'] == 'ALN':\n",
    "        return 'OK'\n",
    "    else:\n",
    "        return 'Please work with HQ Minor Program to Close-out Project'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_project_closeout_status, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Data Needs Review?'\n",
    "\n",
    "input_cols = ['Does Project have a Repeated EA or Project ID repeated in Minor Profile?',\n",
    "       'Does FY Need Updates?', 'Does EA Need Updates?',\n",
    "       'Does Program Code Need Updates?',\n",
    "       'Does Construction Capital Cost ($K) Need Updates?',\n",
    "       'Has performance raw data?',\n",
    "       'Was Performance Tab Completed in Section in Use?',\n",
    "       'Matches Minor Approved List Performance Value and Measure?',\n",
    "       'Was project with FY Before 2021/22 Closed-Out?']\n",
    "\n",
    "def ck_review_needs(df, input_cols):\n",
    "    for col in input_cols:\n",
    "        if df[col] != 'OK:':\n",
    "            return 'District needs to review project data (Profile and/or RTL)'\n",
    "    return 'OK'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_review_needs, args = [input_cols], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ck_col = 'Data needs review other that Close-out?'\n",
    "\n",
    "input_cols = ['Does Project have a Repeated EA or Project ID repeated in Minor Profile?',\n",
    "       'Does FY Need Updates?', 'Does EA Need Updates?',\n",
    "       'Does Program Code Need Updates?',\n",
    "       'Does Construction Capital Cost ($K) Need Updates?',\n",
    "       'Has performance raw data?',\n",
    "       'Was Performance Tab Completed in Section in Use?',\n",
    "       'Matches Minor Approved List Performance Value and Measure?',\n",
    "#          'Was project with FY Before 2021/22 Closed-Out?'     \n",
    "       ]\n",
    "\n",
    "def ck_review_needs_2(df, input_cols):\n",
    "    for col in input_cols:\n",
    "        if df[col] != 'OK:':\n",
    "            return 'District needs to review project data (Profile and/or RTL)'\n",
    "    return 'OK'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_review_needs_2, args = [input_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question to be answered, can we convert the following checks into \"OK\" or others, to be used in filter out flagged items in the punchlist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Was information Entered in the Allocation Band?'\n",
    "\n",
    "def ck_ALN_band_info_completeness(df):\n",
    "    if pd.isna(df['FY_ALN']) or df['Has performance raw data?'] == 'No' or pd.isna(df['Total Capital Project Cost ($K)']):\n",
    "        return 'No'\n",
    "    else: \n",
    "        return 'Yes'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_ALN_band_info_completeness, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Is Project ready to enter data in the Allocation Band?'\n",
    "\n",
    "def ck_readiness_to_enter_ALN_band(df):\n",
    "    if pd.notna(df['Prog Appr Date_WP']):  #has approval date in WP band\n",
    "        if df['Section'] == 'ALN':\n",
    "            return 'Project was closed-out'\n",
    "        elif df['Was information Entered in the Allocation Band?'] == 'Yes':\n",
    "            return 'Allocation Band needs review by HQ Minor Program. If all data Accurate HQ Minor will enter the approval date'\n",
    "        else:\n",
    "            return 'Project ready to enter data in the Allocation Band (Cost, Schedule, RTL, And/Or Performance Tab)'\n",
    "    else: \n",
    "        return 'Workplan Band needs review by HQ Minor Program. If all data Accurate HQ Minor will enter the approval date'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_readiness_to_enter_ALN_band, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-stock",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ck_col = 'Is Project Project Ready for Review and Approval Date?'\n",
    "\n",
    "def ck_readiness_for_review(df):\n",
    "    if df['Data needs review other that Close-out?'] != 'OK':\n",
    "        return 'No'\n",
    "    elif df['FY In Use'] > 22: \n",
    "        return 'No'\n",
    "    elif pd.isna(df['Prog Appr Date_WP']):\n",
    "        return 'HQ Needs to review Workplan band and enter Approval Date if data is accurate'\n",
    "    \n",
    "    elif df['Was information Entered in the Allocation Band?'] == 'Yes':\n",
    "        if pd.notna(df['Prog Appr Date_ALN']):\n",
    "            return 'No, Project Already Closed-out'\n",
    "        else:\n",
    "            return 'HQ Needs to review Allocation band and enter Approval Date if data is accurate'\n",
    "    else:\n",
    "        return 'No'\n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_readiness_for_review, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Does Worplan Band needs Approval Removal?'\n",
    "\n",
    "def ck_WP_data_error(df):\n",
    "    if pd.isna(df['Prog Appr Date_WP']):  #has no approval data in WP band\n",
    "        return 'No'\n",
    "    elif (pd.isna(df['FY In Use'])\n",
    "        or int(df['FY In Use']) > 22 \n",
    "        or (df['FY In Use'] in ['21', '22'] and df['In the Approved List?'] == 'No')\n",
    "         ): \n",
    "        return 'HQ Minor Program needs to remove Approval date fromWorkplan Band, so District can updated the project FY. Project not in Approved lists or in the future'\n",
    "    else:\n",
    "        return 'No'\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_WP_data_error, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Does Allocation Band needs Approval Removal?'\n",
    "\n",
    "def ck_ALN_data_error(df):\n",
    "    if pd.isna(df['Prog Appr Date_ALN']):  #has no approval data in ALN band\n",
    "        return 'No'\n",
    "    elif df['Data needs review other that Close-out?'] == 'OK': \n",
    "        return 'No'\n",
    "    else:\n",
    "        return 'HQ Minor Program needs to remove Approval date from Allocation Band, so District can updated the project data'\n",
    "\n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_ALN_data_error, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'HQ Minor Program Needs Review?'\n",
    "\n",
    "def ck_review_needs_HQ_Minor(df):\n",
    "    if (df['Is Project Project Ready for Review and Approval Date?'] == \"No\"\n",
    "        and df['Does Worplan Band needs Approval Removal?'] == 'No'\n",
    "        and df['Does Allocation Band needs Approval Removal?'] == 'No'\n",
    "       ):\n",
    "        return 'No'\n",
    "    else: \n",
    "        return \"HQ Minor Needs Review\"\n",
    "    \n",
    "df_Minor_raw_data[ck_col] = df_Minor_raw_data.apply(ck_review_needs_HQ_Minor, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question to be answered: \n",
    "# for every project in Minor raw data, the section-in-use performance needs to be filled. \n",
    "# the performance measure unit and value should match with approved project list performance meansure, if available in approved project list. \n",
    "# if the raw data has all the information needed, including FY and performance data, and it is not only the approved project list, Minor project HQ needs to review and approve the project. \n",
    "#if the project is on the approved list, the HQ needs reach out the district to get the project close out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-pakistan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-bunch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question to be answered: \n",
    "# do we need the following checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-symphony",
   "metadata": {},
   "source": [
    "### flag if total project cost is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ck_total_project_cost(df):\n",
    "    if pd.isna(df['Total Project Cost ($K)']) or df['Total Project Cost ($K)'] == 0:\n",
    "        return 'Total project cost can not Empty or zero.'\n",
    "    else:\n",
    "        return 'OK'\n",
    "    \n",
    "df_Minor_raw_data['Total Project Cost Check'] = df_Minor_raw_data.apply(ck_total_project_cost, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-destination",
   "metadata": {},
   "source": [
    "### flag if project description is blank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ck_project_description(df):\n",
    "    if pd.isna(df['Project Location/Description']) or df['Project Location/Description'] == '':\n",
    "        return 'Project Location/Description can not empty.'\n",
    "    else:\n",
    "        return 'OK'\n",
    "    \n",
    "df_Minor_raw_data['Project Location/Description Check'] = df_Minor_raw_data.apply(ck_project_description, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-gateway",
   "metadata": {},
   "source": [
    "### check pm validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Minor_pm_invalid = df_Minor_pm_check[df_Minor_pm_check['Valid PM'] != 'Yes']\n",
    "\n",
    "AMT_IDs_withInvalidPM = df_Minor_pm_invalid['AMT_ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ck_invalid_pm(df):\n",
    "    if df['AMT_ID'] in AMT_IDs_withInvalidPM:\n",
    "        return 'The PM is invalid.'\n",
    "    else:\n",
    "        return 'OK'\n",
    "    \n",
    "df_Minor_raw_data['PM Validity Check'] = df_Minor_raw_data.apply(ck_invalid_pm, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time =  time.time()\n",
    "elapsed = end_time - start_time\n",
    "print('time elapsed : {} seconds'.format(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-might",
   "metadata": {},
   "source": [
    "<a id='Export_Data'></a>\n",
    "# Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HHMM = datetime.now().strftime(\"%H%M\")\n",
    "\n",
    "file_export_log = open(LOG_FILE, \"a\")  # append mode\n",
    "file_export_log.write(\"#####{}, time(HHMM):{} \\n\".format(TARGETDATE, DATA_HHMM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Minor_raw_data['Data_HourMinute'] = DATA_HHMM\n",
    "df_Minor_raw_data['Data_Date'] = TARGETDATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-catalog",
   "metadata": {},
   "source": [
    "## export check flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_cols = [\n",
    "    'EFIS Uniqueness Check',\n",
    "    'EA Uniqueness Check',\n",
    "    'Does Project have a Repeated EA or Project ID repeated in Minor Profile?',\n",
    "    'Does FY Need Updates?', \n",
    "    'Does EA Need Updates?',\n",
    "    'Does Program Code Need Updates?',\n",
    "    'Does Construction Capital Cost ($K) Need Updates?',\n",
    "    'Has performance raw data?',\n",
    "    'Was Performance Tab Completed in Section in Use?',\n",
    "    'Matches Minor Approved List Performance Value and Measure?',\n",
    "    'Was project with FY Before 2021/22 Closed-Out?', \n",
    "    'Data Needs Review?',\n",
    "    'Data needs review other that Close-out?',\n",
    "           \n",
    "    #additional checks\n",
    "    'PM Validity Check',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-selection",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#export all projects with all checks in matrix\n",
    "out_cols = [\n",
    "    \n",
    "    #project information\n",
    "    'AMT_ID', 'Minor', 'EFIS', 'EA', 'District', \n",
    "    'Data_Date',\n",
    "    'Data_HourMinute',\n",
    "                    ]\n",
    "\n",
    "out_cols.extend(ck_cols)\n",
    "\n",
    "\n",
    "filename = 'minor_datachecks_matrix'\n",
    "\n",
    "try: \n",
    "    df_Minor_raw_data[out_cols].to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "    shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename))\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#table 1\n",
    "\n",
    "df_melted = pd.melt(df_Minor_raw_data, \n",
    "                    id_vars=['AMT_ID'], \n",
    "                    value_vars=ck_cols, var_name = 'Check Description')\n",
    "\n",
    "df_melted.columns = ['AMT_ID','Check Description','Check Summary']\n",
    "df_melted_filtered = df_melted[df_melted['Check Summary']!= 'OK']\n",
    "\n",
    "\n",
    "out_cols = [\n",
    "    \n",
    "    #project information\n",
    "    'AMT_ID', 'Minor', 'EFIS', 'EA', 'District', \n",
    "    'Data_Date',\n",
    "    'Data_HourMinute',\n",
    "                    ]\n",
    "\n",
    "df_out = pd.merge(df_melted_filtered, df_Minor_raw_data[out_cols],\n",
    "                  how = 'left', left_on = 'AMT_ID', right_on = 'AMT_ID')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Minor_Datachecks_Punchlist'\n",
    "try: \n",
    "    df_out.to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "    shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename))\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "\n",
    "hyper_name = '{}.hyper'.format(filename)\n",
    "\n",
    "try: \n",
    "    publish_datasource(df_out, hyper_name)\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}'.format(hyper_name)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}'.format(hyper_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-utility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-mongolia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "altered-childhood",
   "metadata": {},
   "source": [
    "## export action items for Minor District Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-monday",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Minor_District_ActionItem'\n",
    "\n",
    "out_cols = [\n",
    "    #project information\n",
    "    'AMT_ID', 'Minor', 'EFIS', 'EA', 'District', \n",
    "    'Data_Date',\n",
    "    'Data_HourMinute',\n",
    "    \n",
    "    'Is Project ready to enter data in the Allocation Band?'\n",
    "                    ]\n",
    "df_out = df_Minor_raw_data[out_cols]\n",
    "\n",
    "\n",
    "\n",
    "try: \n",
    "    df_out.to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "    shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename))\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "\n",
    "hyper_name = '{}.hyper'.format(filename)\n",
    "\n",
    "try: \n",
    "    publish_datasource(df_out, hyper_name)\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}'.format(hyper_name)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}'.format(hyper_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-stereo",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "underlying-timeline",
   "metadata": {},
   "source": [
    "## export action items for Minor HQ Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Minor_HQ_ActionItem'\n",
    "\n",
    "out_cols = [\n",
    "    #project information\n",
    "    'AMT_ID', 'Minor', 'EFIS', 'EA', 'District', \n",
    "    'Data_Date',\n",
    "    'Data_HourMinute',\n",
    "    \n",
    "    'Is Project Project Ready for Review and Approval Date?',\n",
    "    'Does Worplan Band needs Approval Removal?',\n",
    "    'Does Allocation Band needs Approval Removal?',\n",
    "    'HQ Minor Program Needs Review?',\n",
    "                    ]\n",
    "df_out = df_Minor_raw_data[out_cols]\n",
    "\n",
    "try: \n",
    "    df_out.to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "    shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename))\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "\n",
    "hyper_name = '{}.hyper'.format(filename)\n",
    "\n",
    "try: \n",
    "    publish_datasource(df_out, hyper_name)\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}'.format(hyper_name)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}'.format(hyper_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-republican",
   "metadata": {},
   "source": [
    "<a id='Export_programming_summary'></a>\n",
    "\n",
    "### Export Programming Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_col =df_Programming_Summary_filtered.columns\n",
    "\n",
    "filename = 'Minor_Programming_Summary'\n",
    "df_out = df_Programming_Summary_filtered[out_col]\n",
    "df_out['Data_Date'] = TARGETDATE\n",
    "df_out['Data_HourMinute'] = DATA_HHMM\n",
    "\n",
    "try: \n",
    "    df_out.to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "    shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename))\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "\n",
    "\n",
    "hyper_name = '{}.hyper'.format(filename)\n",
    "\n",
    "try: \n",
    "    publish_datasource(df_out, hyper_name)\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}'.format(hyper_name)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}'.format(hyper_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_export_log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-contents",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-vatican",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "resistant-isaac",
   "metadata": {},
   "source": [
    "\n",
    "<a id='FinalCleanUp'></a>\n",
    "## Final Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#clean up tableau publishing log file\n",
    "\n",
    "import os\n",
    "import glob\n",
    "# get a recursive list of file paths that matches pattern\n",
    "fileList = glob.glob('./*.log')\n",
    "# Iterate over the list of filepaths & remove each file.\n",
    "for filePath in fileList:\n",
    "    try:\n",
    "        os.remove(filePath)\n",
    "    except OSError:\n",
    "        print(\"Error while deleting file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time =  time.time()\n",
    "elapsed = end_time - start_time\n",
    "print('time elapsed : {} seconds'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-colony",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-exercise",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
