{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "foreign-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-rouge",
   "metadata": {},
   "source": [
    "# Update Notes: \n",
    "\n",
    "### 12-20-2021\n",
    "\n",
    "* change Date -> Data_Date\n",
    "\n",
    "### 12-21-2021\n",
    "\n",
    "* add Data_HourMinute column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-roots",
   "metadata": {},
   "source": [
    "## TODO\n",
    "needs to change the FY related number to dynamic number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-diagnosis",
   "metadata": {},
   "source": [
    "# Tip for quick search\n",
    "\n",
    "* Needs attention: the place where needs update or better logic\n",
    "* question to be answered: the place where things are still not clear\n",
    "* Manual Check: Unit test where you can drill in to find the data that leads to the check results for a specific project and specific check\n",
    "* TODO: things needs to be done\n",
    "* bookmark: stop point from last visit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-excess",
   "metadata": {},
   "source": [
    "# Admin Notes:\n",
    "\n",
    "\n",
    "1. The AMTool dataset is archived daily as csv files and used for the project book check. \n",
    "The csv files are located at: \n",
    "r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\DataLake'\n",
    "\n",
    "2. The excel input files are checked daily and archived with datestamp whenever it is modified.\n",
    "The continuously updated excel input files are located at: r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\excel'\n",
    "The excel input file are archived at: r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\Data_MiscInput'\n",
    "To recover the archived excel file used in project book check for a target date, select the excel file with latest datestamp but is still earlier than the target date.\n",
    "\n",
    "3. The check summary export action is logged daily. It can be used for daily monitoring. \n",
    "The file export log is located at: \\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal\\log\n",
    "\n",
    "4. The published data are at:\n",
    "\n",
    "    * csv files for district asset manager: http://svgcshopp.dot.ca.gov/DataLake/ProjectBookCheck/\n",
    "    * csv files for HQ AM: \\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal\n",
    "    * tableau workbook with live data source: https://tableau.dot.ca.gov/#/site/AssetManagement/workbooks/1815/views\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-confidentiality",
   "metadata": {},
   "source": [
    "<a id='TableOfContents'></a>\n",
    "\n",
    "# Table Of Contents\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "### [Global Constants](#GlobalConstants)\n",
    "\n",
    "\n",
    "### [Load and cleanup source data](#Read_Data)\n",
    "\n",
    "* [Counties](#Counties)\n",
    "* [Programming_Summary](#Programming_Summary)\n",
    "* [ProgrammingList](#ProgrammingList)\n",
    "* [SHOPP_Raw_Data](#SHOPP_Raw_Data)\n",
    "* [TenYrShopp_Perf_RawData](#TenYrShopp_Perf_RawData)\n",
    "\n",
    "\n",
    "## Add fields to SHOPP raw data (calculate and join)\n",
    "* [Calculated Fields](#AddDataColumns)\n",
    "* [Join Tables](#DataJoining)\n",
    "\n",
    "\n",
    "## [Export Data](#Export_Data)\n",
    "\n",
    "\n",
    "\n",
    "## [Final Clean Up](#FinalCleanUp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-mozambique",
   "metadata": {},
   "source": [
    "# Import common modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fundamental-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "\n",
    "# import requests\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "small-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "second-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "intellectual-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show dataframe without skip column\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acquired-istanbul",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using the Extract API 2.0, please save the output as .hyper format\n"
     ]
    }
   ],
   "source": [
    "# from config_datasource import *\n",
    "import projectbookcheck_utilityfunction as uf\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-aspect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "piano-celebrity",
   "metadata": {},
   "source": [
    "# Data clean process\n",
    "\n",
    "* funding amount: remove dollar sign, \n",
    "* fill missing value, string, numerical, \n",
    "* remove leading single quote for string value\n",
    "* strip off leading and trailing space \n",
    "\n",
    "* regulate column names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-theory",
   "metadata": {},
   "source": [
    "<a id='GlobalConstants'></a>\n",
    "## Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "experienced-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'TenYrShopp_RawData_'\n",
    "path_to_file = r'{}\\{}.csv'.format(DATALAKE_HTTPSERVER_FOLDER, filename)\n",
    "t = os.path.getmtime(path_to_file)\n",
    "\n",
    "# File_TimeStamp = datetime.fromtimestamp(t).strftime(\"%m-%d-%Y_%H-%M\")\n",
    "Data_TimeStamp = datetime.fromtimestamp(t).strftime(\"%m-%d-%Y %H:%M:%S\")\n",
    "\n",
    "TARGETDATE = datetime.fromtimestamp(t).strftime(\"%m-%d-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sorted-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_FY = uf.fiscalyear (datetime.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-mistress",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "threaded-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_export_log = open(LOG_FILE, \"a\")  # append mode\n",
    "file_export_log.write(\"#####SHOPP Manager Review:{} \\n\".format(Data_TimeStamp))\n",
    "file_export_log.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-ready",
   "metadata": {},
   "source": [
    "<a id='Read_Data'></a>\n",
    "\n",
    "# Read Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "artificial-handy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s151589\\Anaconda3\\envs\\dataprep\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "C:\\Users\\s151589\\Anaconda3\\envs\\dataprep\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (29,30,31,32) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "File_TimeStamp = ''\n",
    "\n",
    "if DATA_SOURCE_TYPE == 'csv':\n",
    "\n",
    "    filename = 'TenYrShopp_RawData_'\n",
    "    df_SHOPP_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, File_TimeStamp))\n",
    "    \n",
    "    filename = 'TenYrShopp_PerfM_Raw_Data_'\n",
    "    df_perf_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, File_TimeStamp))\n",
    "\n",
    "    filename = 'Rawdata_Bridge_Worksheet_'\n",
    "    df_brg_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, File_TimeStamp), skiprows = [0], header = 0)\n",
    "\n",
    "    filename = 'Rawdata_Drainage_Worksheet_'\n",
    "    df_drain_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, File_TimeStamp), \n",
    "                                    header = 0, \n",
    "#                                     keep_default_na=False,\n",
    "#                                     na_values = ['',' ']\n",
    "                                   )\n",
    "\n",
    "    filename = 'Rawdata_TMS_Worksheet_'\n",
    "    df_tms_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, File_TimeStamp), header = 0)\n",
    "\n",
    "    filename = 'Rawdata_FishPassage_Worksheet_'\n",
    "    df_fp_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, File_TimeStamp), header = 0)\n",
    "    \n",
    "    filename = 'projectbook_draft'\n",
    "    filepath_draft_projectbook = r'{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSERVER_FOLDER, filename)\n",
    "    df_draft_pb = pd.read_csv(filepath_draft_projectbook, header = 0)\n",
    "    \n",
    "    \n",
    "else:\n",
    "    print('skip getting csv data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "signal-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Latest_approved_book.xlsx'\n",
    "\n",
    "sht = 'Statewide'\n",
    "\n",
    "df_approved_projectbook = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename), sheet_name = sht) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "different-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Latest_approved_performance.xlsx'\n",
    "\n",
    "sht = 'Statewide_various_dates'\n",
    "\n",
    "df_approved_performance = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename), sheet_name = sht) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accompanied-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rename = {\n",
    "    'SHOPP ID': 'AMT_ID',\n",
    "    'EFIS ID':'EFIS',\n",
    "    'Tool Section': 'Latest Certified Book Tool Section',\n",
    "    'Project Cost ($K)': 'Latest Certified Book Project Cost ($K)',\n",
    "    'Advertised Year': 'Latest Certified Book Advertised Year',\n",
    "    'Planning or Post planning? ': 'Latest Certified Book Planning or Post-Planning'\n",
    "                               }\n",
    "df_approved_projectbook.rename(dict_rename, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "authentic-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rename = {\n",
    "    'ID': 'AMT_ID',\n",
    "              }\n",
    "\n",
    "df_approved_performance.rename(dict_rename, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "checked-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_approved_performance.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "weighted-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-zoning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "classified-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ck_col = 'Is Project in the 2022 PID workplan (No Reservation Project) or a Long Lead that will be a candidate for fully programmed into the 2022 SHOPP?'\n",
    "\n",
    "# #Excel formula\n",
    "# # =IF(OR(H3=\"Safety Improvements\",H3=\"Major Damage - Permanent Restoration\"),\"No\",\n",
    "# # IF(AND(I3=\"Planning\",OR(RIGHT(J3,2)*1=25,RIGHT(J3,2)*1=26)),\"Yes\",\n",
    "# # IF(AND(I3=\"Planning\",AA3=\"Yes\",AB3=\"2022/23\"),\"Yes\",\n",
    "# # IF(AND(I3=\"Post-Planning\",AA3=\"Yes\",OR(RIGHT(J3,2)*1=25,RIGHT(J3,2)*1=26)),\"Yes\",\n",
    "# # \"No\"))))\n",
    "\n",
    "# def ck_2022_SHOPP_candidate(df):\n",
    "#     if df['Advertised Year'] == 'Added to Project Book':\n",
    "#         return 'Added to Project Book'\n",
    "#     if df['Activity'] in ['Safety Improvements', 'Major Damage - Permanent Restoration']:\n",
    "#         return 'No'\n",
    "#     elif df['Planning or Post-Planning'] == 'Planning':\n",
    "#         if int(df['Advertised Year'][-2:]) in [25, 26]:\n",
    "#             return 'Yes'\n",
    "#         elif df['Active Long Lead'] == \"Yes\":\n",
    "#             return 'Yes'\n",
    "#         else: \n",
    "#             return 'No'\n",
    "#     elif df['Planning or Post-Planning'] == 'Post-Planning':\n",
    "#         if df['Active Long Lead'] == \"Yes\" and int(df['Advertised Year'][-2:]) in [25, 26]:\n",
    "#             return 'Yes'\n",
    "#         else:\n",
    "#             return 'No' \n",
    "#     else: #this is redundant\n",
    "#         return 'No'\n",
    "\n",
    "    \n",
    "# df_draft_pb_combined[ck_col] = df_combined_pb.apply(ck_2022_SHOPP_candidate, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-prayer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-pioneer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "vital-chancellor",
   "metadata": {},
   "source": [
    "## Raw Data Bridge Worksheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "incident-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns \n",
    "#with manual edits\n",
    "\n",
    "dict_rename_bridge_worksheet = {\n",
    " 'ID': 'AMT_ID',\n",
    " 'Bridge â„–': 'BridgeNo',\n",
    " 'Work Type': 'WorkType',\n",
    " 'Brdige / TunnelWork Description': 'WorkDescription',\n",
    " 'Bridge /TunnelHealth Pre': 'Health Pre',\n",
    " 'Bridge /TunnelHealth Post': 'Health Post',\n",
    " 'BridgeScourPre': 'Scour_Pre',\n",
    " 'BridgeScourPost': 'Scour_Post',\n",
    " 'BridgeSeismicPre': 'Seismic_Pre',\n",
    " 'BridgeSeismicPost': 'Seismic_Post',\n",
    " 'BridgeGds MvmtPre': 'GdsMvmt_Pre',\n",
    " 'BridgeGds MvmtPost': 'GdsMvmt_Post',\n",
    " 'Exist(sf)': 'Deck_Exist(sf)',\n",
    " 'Additional(sf)': 'Deck_Additional(sf)',\n",
    " 'Y/N': 'Paint_Y/N',\n",
    " 'Condition': 'Paint_Condition',\n",
    " 'Paint Area(sf)': 'Paint Area(sf)',\n",
    " 'Y/N.1': 'ElectricalMechanical_Y/N',\n",
    " 'Condition.1': 'ElectricalMechanical_Condition',\n",
    " 'Area(sf)': 'ElectricalMechanical_Area(sf)',\n",
    " 'Y/N.2': 'ApproachSlab_Y/N',\n",
    " 'Replaced(sf)': 'ApproachSlab_Replaced(sf)',\n",
    " 'New(sf)': 'ApproachSlab_New(sf)',\n",
    " 'Y/N.3': 'Rail_Y/N',\n",
    " 'Good(lf)': 'Rail_Good(lf)',\n",
    " 'Fair(lf)': 'Rail_Fair(lf)',\n",
    " 'Poor(lf)': 'Rail_Poor(lf)',\n",
    " 'Additonal(lf)': 'Rail_Additonal(lf)',\n",
    " 'Post Good(lf)': 'Rail_Post Good(lf)',\n",
    " 'Post Fair(lf)': 'Rail_Post Fair(lf)',\n",
    " 'Post Poor(lf)': 'Rail_Post Poor(lf)',\n",
    " 'Post New(lf)': 'Rail_Post New(lf)',\n",
    " 'FishPassage(Y/N)': 'FishPassage(Y/N)',\n",
    "}\n",
    "\n",
    "df_brg_raw_data.rename(dict_rename_bridge_worksheet, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "prime-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brg_raw_data.name = 'df_brg_raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dynamic-junction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_brg_raw_data['Rail_Good(lf)'].fillna(0, inplace = True)\n",
    "df_brg_raw_data['Rail_Fair(lf)'].fillna(0, inplace = True)\n",
    "df_brg_raw_data['Rail_Poor(lf)'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "egyptian-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brg_raw_data['Rail_Total(lf)'] = (df_brg_raw_data['Rail_Good(lf)'] \n",
    "                                             + df_brg_raw_data[ 'Rail_Fair(lf)'] \n",
    "                                             + df_brg_raw_data['Rail_Poor(lf)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-webmaster",
   "metadata": {},
   "source": [
    "## Raw Data Drainage Worksheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fifty-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drain_raw_data.name = 'df_drain_raw_data'\n",
    "\n",
    "dict_drain_rename = {\n",
    " 'ID': 'AMT_ID',\n",
    " 'Data Date':'Data Date_Drainage'\n",
    "                               }\n",
    "df_drain_raw_data.rename(dict_drain_rename, axis = 1, inplace = True)\n",
    "\n",
    "cols = ['EA','EFIS','SYSNO','INETNO','OUTETNO']\n",
    "for c in cols:\n",
    "    df_drain_raw_data[c] = df_drain_raw_data[c].apply(uf.remove_punction)\n",
    "\n",
    "\n",
    "df_drain_raw_data['Data Date_Drainage'] = df_drain_raw_data['Data Date_Drainage'].apply(uf.regulate_timestamp_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acute-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_drain_raw_data['Unique Culvert ID'] = df_drain_raw_data.apply(uf.calc_drain_unique_ID, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-threat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "excess-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_drain_raw_data[df_drain_raw_data['AMT_ID']==22780]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "seeing-worst",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'N A', 'Yes', 'No'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drain_raw_data[df_drain_raw_data['AMT_ID']==22780]['Is the proposed treatment expected to remediate the fish passage priority barrier? (Yes/No/NA)'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-mortality",
   "metadata": {},
   "source": [
    "## Raw Data TMS Worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "neither-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_TMS_rename = {\n",
    " 'ID': 'AMT_ID',\n",
    " 'Data Date':'Data Date_TMS'\n",
    "                               }\n",
    "df_tms_raw_data.rename(dict_TMS_rename, axis = 1, inplace = True)\n",
    "\n",
    "df_tms_raw_data.name = 'df_tms_raw_data'\n",
    "\n",
    "df_tms_raw_data['Data Date_TMS'] = df_tms_raw_data['Data Date_TMS'].apply(uf.regulate_timestamp_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-embassy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "muslim-tanzania",
   "metadata": {},
   "source": [
    "## Raw Data FP Worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "prompt-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "dict_rename = {\n",
    "    'ID': 'AMT_ID',\n",
    "    'Fish Passage Type(Priority List /Not Priority List)' : 'Fish Passage Type (Priority List / Not Priority List)',\n",
    "    'Should countas addressingFish Passage(Yes/No)?': 'Should count as addressing Fish Passage (Yes/No)?'\n",
    "              }\n",
    "\n",
    "df_fp_raw_data = df_fp_raw_data.rename(dict_rename, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-belief",
   "metadata": {},
   "source": [
    "<a id='TenYrShopp_Perf_RawData'></a>\n",
    "## TenYrShopp_Perf_RawData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "psychological-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "dict_rename_perf_rawdata = {\n",
    "    'ID': 'AMT_ID',\n",
    "              }\n",
    "df_perf_raw_data = df_perf_raw_data.rename(dict_rename_perf_rawdata, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "found-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_strip = ['EA','EFIS','PPNO']\n",
    "for c in cols_strip :\n",
    "    df_perf_raw_data[c] = df_perf_raw_data[c].str.strip(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "sustainable-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data clean \n",
    "#data type regulation\n",
    "\n",
    "df_perf_raw_data['Quantity'] = df_perf_raw_data['Quantity'].fillna(0)\n",
    "df_perf_raw_data['Assets in Good Cond'] = df_perf_raw_data['Assets in Good Cond'].fillna(0)\n",
    "df_perf_raw_data['Assets in Fair Cond'] = df_perf_raw_data['Assets in Fair Cond'].fillna(0)\n",
    "df_perf_raw_data['Assets in Poor Cond'] = df_perf_raw_data['Assets in Poor Cond'].fillna(0)\n",
    "df_perf_raw_data['New Assets Added'] = df_perf_raw_data['New Assets Added'].fillna(0)\n",
    "\n",
    "df_perf_raw_data['EFIS'] = pd.to_numeric(df_perf_raw_data['EFIS'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dedicated-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data trimming\n",
    "#row\n",
    "df_perf_raw_data= df_perf_raw_data[df_perf_raw_data['District'] != 56]\n",
    "#column\n",
    "df_perf_raw_data.drop(['PID Cycle', 'TYP','ProjectedSHOPP Cycle','RequestedRTL FY','DistrictPriority'],\n",
    "  axis='columns', inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "sapphire-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data.name = 'df_perf_raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-congo",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "annual-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns \n",
    "\n",
    "dict_rename_rawdata = {\n",
    "                       'County':'County TYP',\n",
    "                       'Route': 'Route TYP',\n",
    "                       'BackPM':'BackPM TYP',\n",
    "                       'AheadPM':'AheadPM TYP',\n",
    "                       'ID': 'AMT_ID',\n",
    "                       'Ten-Year Plan': 'Ten-Year Plan RD',\n",
    "                       'County.1' : 'County PRG',\n",
    "                       'Route.1' : 'Route PRG',\n",
    "                       'BackPM.1':'BackPM PRG',\n",
    "                       'AheadPM.1' : 'AheadPM PRG',\n",
    "                       'County.2' : 'County PCR',\n",
    "                       'Route.2' : 'Route PCR',\n",
    "                       'BackPM.2':'BackPM PCR',\n",
    "                       'AheadPM.2' : 'AheadPM PCR',\n",
    "                       'Activity Category': 'Activity'\n",
    "                      }\n",
    "df_SHOPP_raw_data = df_SHOPP_raw_data.rename(dict_rename_rawdata, axis = 1)\n",
    "\n",
    "\n",
    "#remove leading puncture for target columns\n",
    "cols_strip = ['District','Route TYP','EA','EFIS','Route PRG','PPNO','Route PCR']\n",
    "for c in cols_strip :\n",
    "    df_SHOPP_raw_data[c] = df_SHOPP_raw_data[c].str.strip(\"'\")\n",
    "\n",
    "    \n",
    "df_SHOPP_raw_data['District'] =df_SHOPP_raw_data['District'].astype(int)\n",
    "\n",
    "df_SHOPP_raw_data['EFIS'] = pd.to_numeric(df_SHOPP_raw_data['EFIS'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-document",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-friday",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-lender",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fluid-partner",
   "metadata": {},
   "source": [
    "# Add columns to performance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "streaming-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include only the project in projectbook and active section\n",
    "\n",
    "df_perf_raw_data_1 = pd.merge(df_perf_raw_data,\n",
    "                              df_draft_pb[['AMT_ID', 'Section','Planning or Post-Planning', 'Advertised Year', 'New SHOPP Candidate?']], \n",
    "                how ='inner', \n",
    "                left_on = ['AMT_ID', 'Section'],\n",
    "                right_on = ['AMT_ID', 'Section'], \n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-knitting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dietary-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data_1['Post-Fair'].fillna(0, inplace = True)\n",
    "\n",
    "df_perf_raw_data_1['F2G Achieved'] = df_perf_raw_data_1['Post-Fair'] - df_perf_raw_data_1['Assets in Fair Cond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "identical-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data_1['Post-Poor'].fillna(0, inplace = True)\n",
    "\n",
    "df_perf_raw_data_1['P2G Achieved'] = df_perf_raw_data_1['Post-Poor'] - df_perf_raw_data_1['Assets in Poor Cond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "systematic-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rename_performance ={\n",
    "    'New Assets Added':'New Achieved',\n",
    "}\n",
    "\n",
    "df_perf_raw_data_1 = df_perf_raw_data_1.rename(dict_rename_performance, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "american-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data_1['Performance Objective'].fillna('',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-pasta",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "disturbed-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data_1['Concatenate ID+Objective'] = df_perf_raw_data_1['AMT_ID'].astype(str) + df_perf_raw_data_1['Performance Objective']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "suburban-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ck_reviewed(df):\n",
    "    if pd.isna(df['Review Date']):\n",
    "        return 'No'\n",
    "    else:\n",
    "        return 'Yes'\n",
    "        \n",
    "df_perf_raw_data_1['Reviewed?'] = df_perf_raw_data_1.apply(ck_reviewed, axis = 1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "biological-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-conclusion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-skiing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "several-insulation",
   "metadata": {},
   "source": [
    "## Approved project book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "infectious-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approved_pb_combined = pd.merge(df_approved_projectbook, \n",
    "    df_draft_pb[['AMT_ID', 'Planning or Post-Planning']], \n",
    "    how='left', \n",
    "    left_on= 'AMT_ID', right_on= 'AMT_ID'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "described-thirty",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approved_pb_combined['In Current Draft Book?'] = df_approved_pb_combined['Planning or Post-Planning'].apply(\n",
    "lambda x: 'No' if pd.isna(x) else 'Yes'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "compatible-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approved_pb_combined['Current Draft Book Status'] = df_approved_pb_combined['Planning or Post-Planning'].apply(\n",
    "lambda x: 'Not in Current Draft Book' if pd.isna(x) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "sudden-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Different Project Status?'\n",
    "\n",
    "def ck_project_status(df):\n",
    "    if df['Current Draft Book Status'] != df['Planning or Post-Planning']:\n",
    "        'Yes'\n",
    "    else:\n",
    "        return 'No'\n",
    "\n",
    "df_approved_pb_combined[ck_col] = df_approved_pb_combined.apply(ck_project_status, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "different-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum_project_deleted(series):\n",
    "    deleted = 0\n",
    "    for v in series:\n",
    "        if v == 'No':\n",
    "            deleted += 1\n",
    "    return deleted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "improved-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approved_pb_summary = df_approved_pb_combined.groupby(['District','Latest Certified Book Planning or Post-Planning' ]).agg(\n",
    "    {'AMT_ID': 'count',\n",
    "    'In Current Draft Book?':cum_project_deleted,\n",
    "    'Latest Certified Book Project Cost ($K)':sum,\n",
    "    }\n",
    ").reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "federal-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rename = {\n",
    "            'Latest Certified Book Planning or Post-Planning':'Project Status',\n",
    "            'Total Project Cost ($K)_sum':'Current Draft Book Total Project Cost ($K)',\n",
    "            'AMT_ID': 'Latest Certified Book Number of projects',\n",
    "            'In Current Draft Book?':'Number of projects Deleted',\n",
    "            'Latest Certified Book Project Cost ($K)':'Latest Certified Book Total Project Cost ($K)',\n",
    "              }\n",
    "\n",
    "df_approved_pb_summary.rename(dict_rename, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "recognized-buffalo",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 24it [00:00, 24116.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing Approved_ProjectBook_Changes.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "df_approved_pb_summary['Data_TimeStamp'] = Data_TimeStamp\n",
    "uf.export_hyper(df_approved_pb_summary, 'Approved_ProjectBook_Changes', LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-restoration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "noble-riverside",
   "metadata": {},
   "source": [
    "## draft project book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "curious-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_draft_pb_combined = pd.merge(\n",
    "    df_draft_pb, df_approved_projectbook[['AMT_ID','Latest Certified Book Tool Section', \n",
    "                                          'Latest Certified Book Project Cost ($K)',\n",
    "                                          'Latest Certified Book Advertised Year']], \n",
    "    how='left', \n",
    "    left_on= 'AMT_ID', right_on= 'AMT_ID'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "threaded-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['Latest Certified Book Tool Section', \n",
    "          'Latest Certified Book Project Cost ($K)',\n",
    "          'Latest Certified Book Advertised Year']:\n",
    "    df_draft_pb_combined[c].fillna('Added to Project Book', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-secondary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "annoying-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ck_match_data_in_cols(df, col1, col2):\n",
    "    \n",
    "    if df[col2] == 'Added to Project Book':\n",
    "        return df[col2]\n",
    "    elif df[col1] == df[col2]:\n",
    "        return 'No'\n",
    "    else:\n",
    "        return 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "stretch-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Any Change in RTL?'\n",
    "\n",
    "df_draft_pb_combined[ck_col] = df_draft_pb_combined.apply(ck_match_data_in_cols, args = ['Advertised Year','Latest Certified Book Advertised Year'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "strong-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Any Change in Project Cost?'\n",
    "\n",
    "df_draft_pb_combined[ck_col] = df_draft_pb_combined.apply(ck_match_data_in_cols, args = ['Total Project Cost ($K)','Latest Certified Book Project Cost ($K)'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "limited-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Any Change in Tool Section?'\n",
    "\n",
    "df_draft_pb_combined[ck_col] = df_draft_pb_combined.apply(ck_match_data_in_cols, args = ['Section','Latest Certified Book Tool Section'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "democratic-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Changes in Schedule, Cost, Performance, or Tool Section?'\n",
    "\n",
    "def combine_changes(df):\n",
    "    if (df['Any Change in RTL?'] == 'Yes' \n",
    "        or df['Any Change in Project Cost?'] == 'Yes' \n",
    "        or df['Any Change in Tool Section?'] == 'Yes'):\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return 'No'\n",
    "\n",
    "df_draft_pb_combined[ck_col] = df_draft_pb_combined.apply(combine_changes, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "coordinated-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Changes in Schedule, Cost, Performance, or Tool Section?'\n",
    "\n",
    "def combine_changes(df):\n",
    "    if (df['Any Change in RTL?'] == 'Yes' \n",
    "        or df['Any Change in Project Cost?'] == 'Yes' \n",
    "        or df['Any Change in Tool Section?'] == 'Yes'):\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return 'No'\n",
    "\n",
    "df_draft_pb_combined[ck_col] = df_draft_pb_combined.apply(combine_changes, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "vertical-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approved_performance_filtered = df_approved_performance[\n",
    "    (~df_approved_performance['Performance Objective'].isna()) \n",
    "    & (df_approved_performance['Performance Objective'] != 'No Performance Objective in the SHSMP') \n",
    "    & (df_approved_performance['Performance Objective'] != '') \n",
    "    & (df_approved_performance['ActID'] != 'H55')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "mental-vessel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s151589\\Anaconda3\\envs\\dataprep\\lib\\site-packages\\pandas\\core\\frame.py:4459: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n"
     ]
    }
   ],
   "source": [
    "df_approved_performance_filtered[['Assets in Fair Cond','Assets in Poor Cond']].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-humor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "rough-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data_filtered = df_perf_raw_data_1[\n",
    "    (~df_perf_raw_data_1['Performance Objective'].isna()) \n",
    "    & (df_perf_raw_data_1['Performance Objective'] != 'No Performance Objective in the SHSMP') \n",
    "    & (df_perf_raw_data_1['Performance Objective'] != '') \n",
    "    & (df_perf_raw_data_1['ActID'] != 'H55')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "remarkable-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data_grouped = df_perf_raw_data_filtered.groupby(['AMT_ID','Performance Objective'])[['Assets in Good Cond', 'Assets in Fair Cond']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "hybrid-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_approved_performance_grouped = df_approved_performance_filtered.groupby(['AMT_ID','Performance Objective'])[['Assets in Good Cond', 'Assets in Fair Cond']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eight-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.merge(df_perf_raw_data_grouped, \n",
    "                df_approved_performance_grouped, \n",
    "                how = 'inner', \n",
    "                left_on=['AMT_ID','Performance Objective'], \n",
    "                right_on=['AMT_ID','Performance Objective'])\n",
    "\n",
    "ck_col = 'Any Change in Performance (SHSMP Objectives)?'\n",
    "\n",
    "def ck_performance(df):\n",
    "    target_columns = ['Assets in Good Cond', 'Assets in Fair Cond']\n",
    "    for c in target_columns:\n",
    "        col1 = c + '_x'\n",
    "        col2 = c + '_y'\n",
    "        if df[col1] != df[col2]:\n",
    "            return 'Yes'\n",
    "    return 'No'\n",
    "\n",
    "\n",
    "temp[ck_col] = temp.apply(ck_performance, axis = 1)\n",
    "\n",
    "temp_grouped = temp.groupby('AMT_ID')['Any Change in Performance (SHSMP Objectives)?'].apply(lambda x: 'Yes' if 'Yes' in x.values else 'No').reset_index()\n",
    "\n",
    "df_draft_pb_combined = pd.merge(\n",
    "df_draft_pb_combined, temp_grouped,\n",
    "how = 'left', left_on = 'AMT_ID', right_on = 'AMT_ID'\n",
    ")\n",
    "\n",
    "df_draft_pb_combined['Any Change in Performance (SHSMP Objectives)?'].fillna('Can not be compared', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "healthy-satin",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 1955it [00:00, 4383.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing Draft_ProjectBook_Changes.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "df_draft_pb_combined['Data_TimeStamp'] = Data_TimeStamp\n",
    "uf.export_hyper(df_draft_pb_combined, 'Draft_ProjectBook_Changes', LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "operating-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_draft_pb_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-furniture",
   "metadata": {},
   "source": [
    "## Performance_Change_Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "spatial-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "joined-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "sonic-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data_filtered.shape\n",
    "df_perf_raw_data_filtered_SIU = pd.merge(df_perf_raw_data_filtered,df_SHOPP_raw_data[['AMT_ID','Section In Use']],\n",
    "                                        how='inner', left_on=['AMT_ID','Section'], right_on=['AMT_ID','Section In Use'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "historical-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data_filtered_SIU[df_perf_raw_data_filtered_SIU['AMT_ID'] == 9133]\n",
    "\n",
    "# df_perf_raw_data_FP_sum[df_perf_raw_data_FP_sum['AMT_ID'] == 9133]\n",
    "\n",
    "# df_approved_performance_FP_sum[df_approved_performance_FP_sum['AMT_ID'] == 9133]\n",
    "\n",
    "# df_perf_change_details[df_perf_change_details['AMT_ID'] == 9133]\n",
    "\n",
    "# temp[temp['AMT_ID'] == 9133]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-conjunction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "sound-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data_FP_sum = df_perf_raw_data_filtered_SIU.groupby(['AMT_ID','Performance Objective'])[['Assets in Fair Cond','Assets in Poor Cond',]].sum().reset_index()\n",
    "\n",
    "df_approved_performance_FP_sum = df_approved_performance_filtered.groupby(['AMT_ID','Performance Objective'])[['Assets in Fair Cond','Assets in Poor Cond',]].sum().reset_index()\n",
    "\n",
    "temp = pd.merge(\n",
    "df_perf_raw_data_FP_sum[['AMT_ID','Performance Objective','Assets in Fair Cond','Assets in Poor Cond',]], \n",
    "df_approved_performance_FP_sum[['AMT_ID','Performance Objective','Assets in Fair Cond','Assets in Poor Cond',]],\n",
    "    how='outer', left_on=['AMT_ID','Performance Objective',], right_on=['AMT_ID','Performance Objective'],\n",
    "    suffixes = ['_Draft', '_Approved']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "global-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[['Assets in Fair Cond_Draft', 'Assets in Poor Cond_Draft',\n",
    "       'Assets in Fair Cond_Approved', 'Assets in Poor Cond_Approved']] = temp[['Assets in Fair Cond_Draft', 'Assets in Poor Cond_Draft',\n",
    "       'Assets in Fair Cond_Approved', 'Assets in Poor Cond_Approved']].fillna(0)\n",
    "\n",
    "temp['Assets in Fair Cond_Change'] = temp['Assets in Fair Cond_Draft'] - temp['Assets in Fair Cond_Approved']\n",
    "\n",
    "temp['Assets in Poor Cond_Change'] = temp['Assets in Poor Cond_Draft'] - temp['Assets in Poor Cond_Approved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "defined-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_change_details = pd.merge(\n",
    "temp, \n",
    "df_SHOPP_raw_data[['AMT_ID','EA','EFIS','District']],\n",
    "    how='left', left_on=['AMT_ID',], right_on=['AMT_ID',],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "variable-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_change_details.groupby(['AMT_ID','Performance Objective']).count().reset_index().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fancy-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp.groupby(['AMT_ID','Performance Objective']).count().reset_index().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "developed-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debug\n",
    "#project number of 9133\n",
    "#the performance of bridge health should be 27340\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "administrative-iraqi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Performance Objective</th>\n",
       "      <th>Assets in Fair Cond_Draft</th>\n",
       "      <th>Assets in Poor Cond_Draft</th>\n",
       "      <th>Assets in Fair Cond_Approved</th>\n",
       "      <th>Assets in Poor Cond_Approved</th>\n",
       "      <th>Assets in Fair Cond_Change</th>\n",
       "      <th>Assets in Poor Cond_Change</th>\n",
       "      <th>EA</th>\n",
       "      <th>EFIS</th>\n",
       "      <th>District</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9133</td>\n",
       "      <td>Bridge Goods Movement Upgrades</td>\n",
       "      <td>27340.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27340.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40110</td>\n",
       "      <td>100000154.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9133</td>\n",
       "      <td>Bridge Rail Replacement and Upgrade</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40110</td>\n",
       "      <td>100000154.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9133</td>\n",
       "      <td>Bridge Scour Mitigation</td>\n",
       "      <td>27340.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27340.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40110</td>\n",
       "      <td>100000154.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9133</td>\n",
       "      <td>Bridge Seismic Restoration</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27340.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27340.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40110</td>\n",
       "      <td>100000154.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9133</td>\n",
       "      <td>Bridge and Tunnel Health</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27340.00</td>\n",
       "      <td>27340.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-27340.0</td>\n",
       "      <td>27340.00</td>\n",
       "      <td>40110</td>\n",
       "      <td>100000154.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9133</td>\n",
       "      <td>Fish Passage</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40110</td>\n",
       "      <td>100000154.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9133</td>\n",
       "      <td>Proactive Safety</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>40110</td>\n",
       "      <td>100000154.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AMT_ID                Performance Objective  Assets in Fair Cond_Draft  \\\n",
       "5     9133       Bridge Goods Movement Upgrades                    27340.0   \n",
       "6     9133  Bridge Rail Replacement and Upgrade                        0.0   \n",
       "7     9133              Bridge Scour Mitigation                    27340.0   \n",
       "8     9133           Bridge Seismic Restoration                        0.0   \n",
       "9     9133             Bridge and Tunnel Health                        0.0   \n",
       "10    9133                         Fish Passage                        0.0   \n",
       "11    9133                     Proactive Safety                        0.0   \n",
       "\n",
       "    Assets in Poor Cond_Draft  Assets in Fair Cond_Approved  \\\n",
       "5                        0.00                       27340.0   \n",
       "6                     2018.00                           0.0   \n",
       "7                        0.00                       27340.0   \n",
       "8                    27340.00                           0.0   \n",
       "9                    27340.00                       27340.0   \n",
       "10                       0.00                           0.0   \n",
       "11                       0.01                           0.0   \n",
       "\n",
       "    Assets in Poor Cond_Approved  Assets in Fair Cond_Change  \\\n",
       "5                            0.0                         0.0   \n",
       "6                         2018.0                         0.0   \n",
       "7                            0.0                         0.0   \n",
       "8                        27340.0                         0.0   \n",
       "9                            0.0                    -27340.0   \n",
       "10                           0.0                         0.0   \n",
       "11                           0.0                         0.0   \n",
       "\n",
       "    Assets in Poor Cond_Change     EA         EFIS  District  \n",
       "5                         0.00  40110  100000154.0       1.0  \n",
       "6                         0.00  40110  100000154.0       1.0  \n",
       "7                         0.00  40110  100000154.0       1.0  \n",
       "8                         0.00  40110  100000154.0       1.0  \n",
       "9                     27340.00  40110  100000154.0       1.0  \n",
       "10                        0.00  40110  100000154.0       1.0  \n",
       "11                        0.01  40110  100000154.0       1.0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_perf_change_details[df_perf_change_details['AMT_ID'] == 9133]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "realistic-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data_TimeStamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "yellow-friend",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 6251it [00:00, 25935.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing ProjectBook_Performance_Change_Details.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "df_perf_change_details['Data_TimeStamp'] = Data_TimeStamp\n",
    "uf.export_hyper(df_perf_change_details, 'ProjectBook_Performance_Change_Details', LOG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-incident",
   "metadata": {},
   "source": [
    "## Data Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bibliographic-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum_changed(series):\n",
    "    cum = 0\n",
    "    changed = 0\n",
    "    for v in series:\n",
    "        if v == 'Yes':\n",
    "            changed += 1\n",
    "        cum += 1\n",
    "#     print(changed, cum)\n",
    "    return changed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "arabic-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum_project_added(series):\n",
    "    added = 0\n",
    "    for v in series:\n",
    "        if v == 'Added to Project Book':\n",
    "            added += 1\n",
    "    return added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "endangered-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_draft_pb_summary = df_draft_pb_combined.groupby(['District', 'Planning or Post-Planning']).agg({\n",
    "#     'Total Project Cost ($K)': {'Current Draft Book Total Project Cost ($K)':'sum'},\n",
    "#     'AMT_ID': {'Current Draft Book Number of projects':'count'},\n",
    "# #     'Any Change in RTL?': {'% with RTL change': cum_change_percent, 'Number of projects Added':cum_project_added},\n",
    "# #     'Any Change in Project Cost?': {'% with Project Cost Change':cum_change_percent},\n",
    "# }).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "structured-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_draft_pb_summary = df_draft_pb_combined.groupby(['District', 'Planning or Post-Planning']).agg({\n",
    "    'Total Project Cost ($K)': sum,\n",
    "    'AMT_ID': 'count',\n",
    "    'Any Change in RTL?':  [cum_changed, cum_project_added],\n",
    "    'Any Change in Project Cost?':cum_changed,\n",
    "}).reset_index()\n",
    "\n",
    "df_draft_pb_summary.columns = ['_'.join(col) for col in df_draft_pb_summary.columns.values]\n",
    "\n",
    "dict_rename = {'District_':'District',\n",
    "            'Planning or Post-Planning_':'Project Status',\n",
    "            'Total Project Cost ($K)_sum':'Current Draft Book Total Project Cost ($K)',\n",
    "            'AMT_ID_count': 'Current Draft Book Number of projects',\n",
    "            'Any Change in RTL?_cum_changed':'No of Projects with RTL change',\n",
    "            'Any Change in RTL?_cum_project_added':'Number of projects Added',\n",
    "            'Any Change in Project Cost?_cum_changed':'No of Projects with Project Cost Change',\n",
    "              }\n",
    "\n",
    "df_draft_pb_summary.rename(dict_rename, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-organic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "resistant-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_combined=pd.merge(df_draft_pb_summary,df_approved_pb_summary, \n",
    "                             how = 'left', \n",
    "                             left_on = ['District','Project Status'],\n",
    "                            right_on = ['District','Project Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-bicycle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-authorization",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "amino-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_total = df_summary_combined.groupby(['District']).agg(sum).reset_index()\n",
    "\n",
    "sub_total['Project Status'] = 'Total'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "round-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_combined = pd.concat([df_summary_combined, sub_total]).sort_values(['District','Project Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "frank-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ck_col = '% with RTL change'  \n",
    "df_summary_combined[ck_col] = df_summary_combined['No of Projects with RTL change']/df_summary_combined['Current Draft Book Number of projects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "golden-bidding",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = '% with Project Cost Change'  \n",
    "df_summary_combined[ck_col] = df_summary_combined['No of Projects with Project Cost Change']/df_summary_combined['Current Draft Book Number of projects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "graphic-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Total Change in Cost ($K)'  \n",
    "df_summary_combined[ck_col] = df_summary_combined['Current Draft Book Total Project Cost ($K)']-df_summary_combined['Latest Certified Book Total Project Cost ($K)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "comparative-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_col = 'Total cost change (%)'  \n",
    "df_summary_combined[ck_col] = df_summary_combined['Total Change in Cost ($K)']/df_summary_combined['Latest Certified Book Total Project Cost ($K)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "killing-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_output = df_summary_combined[[\n",
    "    'District', 'Project Status',\n",
    "    'Latest Certified Book Number of projects','Latest Certified Book Total Project Cost ($K)', \n",
    "    'Current Draft Book Number of projects', 'Current Draft Book Total Project Cost ($K)',\n",
    "     'Number of projects Added', 'Number of projects Deleted',\n",
    "       '% with RTL change',\n",
    "       '% with Project Cost Change', \n",
    "    'Total Change in Cost ($K)',\n",
    "       'Total cost change (%)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-gazette",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "earned-gregory",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-91-40b696403123>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_summary_output['Data_TimeStamp'] = Data_TimeStamp\n",
      "processing table: 36it [00:00, 17956.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing Draft_ProjectBook_Change_Summary.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "df_summary_output['Data_TimeStamp'] = Data_TimeStamp\n",
    "uf.export_hyper(df_summary_output, 'Draft_ProjectBook_Change_Summary', LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-chrome",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-vacuum",
   "metadata": {},
   "source": [
    "## common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "inner-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_review_status(df, col_name, NA_msg = 'No relavent data for review'):\n",
    "    \n",
    "    # if there is active entry of \"NO\" or \"New\", no active entry of \"YES\" --> Needs Review\n",
    "    # if there is active entry of \"NO\" or \"New\", and active entry of \"YES\" --> Partially Reviewed\n",
    "    # if there is no active entry of \"NO\" or \"New\", and active entry of \"YES\" --> Review Complete\n",
    "    # if there is no active entry of \"NO\" or \"New\", no active entry of \"YES\" --> No relavent data for review\n",
    "        \n",
    "    if ('No' in df[col_name]) : \n",
    "        if 'Yes' in df[col_name]:\n",
    "            return 'Partially Reviewed'\n",
    "        else:\n",
    "            return 'Needs Review'\n",
    "    elif 'Yes' in df[col_name]:\n",
    "        return 'Review Complete'\n",
    "    elif 'New' in df[col_name]:\n",
    "        return 'All New'\n",
    "    else:\n",
    "        return NA_msg\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "enabling-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only projects within project book and active section\n",
    "\n",
    "df_brg_raw_data_1 = pd.merge(df_brg_raw_data, df_draft_pb[['AMT_ID', 'Section']], \n",
    "                             how = 'inner', left_on =['AMT_ID', 'Section'],right_on =['AMT_ID', 'Section'],)\n",
    "\n",
    "#keep only projects within project book and active section\n",
    "\n",
    "df_tms_raw_data_1 = pd.merge(df_tms_raw_data, df_draft_pb[['AMT_ID', 'Section']], \n",
    "                             how = 'inner', left_on =['AMT_ID', 'Section'],right_on =['AMT_ID', 'Section'],)\n",
    "\n",
    "\n",
    "#keep only projects within project book and active section\n",
    "\n",
    "df_drain_raw_data_1 = pd.merge(df_drain_raw_data, df_draft_pb[['AMT_ID', 'Section']], \n",
    "                             how = 'inner', left_on =['AMT_ID', 'Section'],right_on =['AMT_ID', 'Section'],)\n",
    "\n",
    "\n",
    "df_fp_raw_data_1= pd.merge(df_fp_raw_data, df_draft_pb[['AMT_ID', 'Section']], \n",
    "                             how = 'inner', left_on =['AMT_ID', 'Section'],right_on =['AMT_ID', 'Section'],)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-constant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dried-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Bridge WS Health Review Status column to performance raw data\n",
    "def ck_brg_health_data(df):\n",
    "    if pd.isna(df['Health Pre']):\n",
    "        return \"No Bridge Health\"\n",
    "    elif pd.isna(df['Health Post']):\n",
    "        return 'No'\n",
    "    else:\n",
    "        return 'Yes'\n",
    "        \n",
    "df_brg_raw_data_1['Post-Condition for Bridge Health entered?']= df_brg_raw_data_1.apply(ck_brg_health_data, axis = 1)     \n",
    "\n",
    "temp1 = df_brg_raw_data_1.groupby(['AMT_ID', 'Section'])['Post-Condition for Bridge Health entered?'].agg(['unique']).reset_index()\n",
    "\n",
    "temp1['Bridge WS Health Review Status'] = temp1.apply(calc_review_status, args = ['unique'], axis = 1)\n",
    "        \n",
    "df_perf_raw_data_1 = pd.merge(df_perf_raw_data_1, temp1[['AMT_ID', 'Section','Bridge WS Health Review Status']], \n",
    "                              how = 'left', left_on = ['AMT_ID', 'Section'],  right_on = ['AMT_ID', 'Section'])\n",
    "\n",
    "df_perf_raw_data_1['Bridge WS Health Review Status'].fillna('No Bridge Worksheet', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "private-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data_1.groupby(['AMT_ID', 'Section'])['Post-Condition for Bridge Health entered?'].agg(['unique']).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "generic-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "synthetic-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp1 = df_brg_raw_data_1.groupby(['AMT_ID', 'Section'])['Post-Condition for Bridge Health entered?'].agg(['unique']).reset_index()\n",
    "\n",
    "# temp1['Bridge WS Health Review Status'] = temp1.apply(calc_review_status, args = ['unique'], axis = 1)\n",
    "\n",
    "\n",
    "# temp1[temp1['AMT_ID'] ==  11281]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "understood-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add TMS WS Health Review Status column to performance raw data\n",
    "\n",
    "def ck_tms_data(df):\n",
    "    if pd.isna(df['Asset Post-Condition']):\n",
    "        return 'No'\n",
    "    elif df['Asset Post-Condition'] == 'New':\n",
    "        return 'New'\n",
    "    else:\n",
    "        return 'Yes'\n",
    "        \n",
    "df_tms_raw_data_1['Post-Condition entered?']= df_tms_raw_data_1.apply(ck_tms_data, axis = 1)     \n",
    "\n",
    "temp1 = df_tms_raw_data_1.groupby(['AMT_ID', 'Section','TMS Structural or Technology'])['Post-Condition entered?'].agg(['unique']).reset_index()\n",
    "\n",
    "temp1['TMS WS Review Status'] = temp1.apply(calc_review_status, args = ['unique', 'No TMS Worksheet'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-marine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "allied-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1['Performance Objective'] = temp1.apply(lambda df: 'Transportation Management System Structures'  if 'Structures' in df['TMS Structural or Technology'] else np.nan, axis = 1)\n",
    "temp1['TMS Structure Review Status'] = temp1.apply(lambda df: df['TMS WS Review Status']  if 'Structures' in df['TMS Structural or Technology'] else np.nan, axis = 1)\n",
    "df_perf_raw_data_1 = pd.merge(df_perf_raw_data_1, temp1[['AMT_ID', 'Section','Performance Objective','TMS Structure Review Status']], \n",
    "                              how = 'left', left_on = ['AMT_ID', 'Section','Performance Objective'],  right_on = ['AMT_ID', 'Section','Performance Objective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "freelance-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1['Performance Objective'] = temp1.apply(lambda df: 'Transportation Management Systems' if 'Technology' in df['TMS Structural or Technology'] else np.nan, axis = 1)\n",
    "temp1['TMS Technology Review Status'] = temp1.apply(lambda df: df['TMS WS Review Status']  if 'Technology' in df['TMS Structural or Technology'] else np.nan, axis = 1)\n",
    "df_perf_raw_data_1 = pd.merge(df_perf_raw_data_1, temp1[['AMT_ID', 'Section','Performance Objective','TMS Technology Review Status']], \n",
    "                              how = 'left', left_on = ['AMT_ID', 'Section','Performance Objective'],  right_on = ['AMT_ID', 'Section','Performance Objective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "foster-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_tms_ws_reviews(df):\n",
    "    '''\n",
    "    combine review status of the two columns of the tms structure and tms technology\n",
    "    '''\n",
    "    if pd.isnull(df['TMS Technology Review Status']):\n",
    "        return df['TMS Structure Review Status']\n",
    "    else:\n",
    "        return df['TMS Technology Review Status']\n",
    "df_perf_raw_data_1['TMS WS Review Status'] = df_perf_raw_data_1.apply(combine_tms_ws_reviews, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "improving-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data_1 = pd.merge(df_perf_raw_data_1, temp1[['AMT_ID', 'Section','TMS Structural or Technology','TMS WS Review Status']], \n",
    "#                               how = 'left', left_on = ['AMT_ID', 'Section'],  right_on = ['AMT_ID', 'Section'])\n",
    "\n",
    "df_perf_raw_data_1['TMS WS Review Status'].fillna('No TMS Worksheet', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "skilled-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tms_raw_data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "conceptual-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data_1['Performance Objective'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "amino-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AMT_ID = 19289\n",
    "# df_perf_raw_data_1[(df_perf_raw_data_1['AMT_ID'] == AMT_ID)\n",
    "#                    & (df_perf_raw_data_1['Performance Objective'].isin(['Transportation Management System', 'Transportation Management System Structures']))\n",
    "# #                   & (df_perf_raw_data_1['TMS Structural or Technology'] == 'Technology')\n",
    "                   \n",
    "# #                    & (df_perf_raw_data_1['TMS Structural or Technology'] == 'Technology & Structures')\n",
    "#                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "lesbian-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp1 = df_tms_raw_data_1.groupby(['AMT_ID', 'Section','TMS Structural or Technology'])['Post-Condition entered?'].agg(['unique']).reset_index()\n",
    "\n",
    "# temp1['TMS WS Review Status'] = temp1.apply(calc_review_status, args = ['unique'], axis = 1)\n",
    "\n",
    "# temp1[temp1['AMT_ID'] == AMT_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "twelve-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tms_raw_data_1[df_tms_raw_data_1['AMT_ID'] == AMT_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "advance-wireless",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_review_status_for_same_performance_objective(df, ws_review_status_col, WS_missing_msg):\n",
    "    \n",
    "    if WS_missing_msg in df[ws_review_status_col] :\n",
    "        return WS_missing_msg\n",
    "    \n",
    "    elif len(df['Reviewed?']) ==1 and ('No' in df['Reviewed?']):\n",
    "        if 'Review Complete' not in df[ws_review_status_col]:\n",
    "            return 'Needs Review'\n",
    "        else: \n",
    "            return 'Partially Reviewed'\n",
    "    else:    # df['Reviewed?'] = 'Yes'\n",
    "        if 'Needs Review' not in df[ws_review_status_col]:\n",
    "            return 'Review Complete'\n",
    "        else:\n",
    "            return 'Partially Reviewed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "banned-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data_2 = df_perf_raw_data_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "stable-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data_1 = df_perf_raw_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "periodic-marathon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-111-73290855e2b7>:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp1 = df_perf_raw_data_1[\n"
     ]
    }
   ],
   "source": [
    "performance_objective = 'Transportation Management Systems'\n",
    "ws_review_status_col = 'TMS WS Review Status'\n",
    "combined_ws_review_status_col = 'Combined TMS Technology Review Status'\n",
    "\n",
    "temp1 = df_perf_raw_data_1[\n",
    "    (df_perf_raw_data_1['Performance Objective'] == performance_objective) \n",
    "#     & (df_perf_raw_data_1['TMS Structural or Technology'] == 'Technology')                 \n",
    "                          ].groupby(['AMT_ID', 'Section','Performance Objective'])['Reviewed?', ws_review_status_col ].agg(set).reset_index()\n",
    "\n",
    "temp1[combined_ws_review_status_col] = temp1.apply(\n",
    "    combine_review_status_for_same_performance_objective, \n",
    "    args = [ws_review_status_col,'No TMS Worksheet'], axis = 1)\n",
    "\n",
    "\n",
    "df_perf_raw_data_1 = pd.merge(df_perf_raw_data_1, temp1[['AMT_ID', 'Section', 'Performance Objective',combined_ws_review_status_col]], \n",
    "                              how = 'left', left_on = ['AMT_ID', 'Section','Performance Objective'],  right_on = ['AMT_ID', 'Section','Performance Objective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "saving-grace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-112-85585e497dfa>:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp1 = df_perf_raw_data_1[\n"
     ]
    }
   ],
   "source": [
    "performance_objective = 'Transportation Management System Structures'\n",
    "ws_review_status_col = 'TMS WS Review Status'\n",
    "combined_ws_review_status_col = 'Combined TMS Structures Review Status'\n",
    "\n",
    "temp1 = df_perf_raw_data_1[\n",
    "    (df_perf_raw_data_1['Performance Objective'] == performance_objective)\n",
    "#     &(df_perf_raw_data_1['TMS Structural or Technology'] == 'Technology & Structures')        \n",
    "                          ].groupby(['AMT_ID', 'Section','Performance Objective'])['Reviewed?', ws_review_status_col ].agg(set).reset_index()\n",
    "\n",
    "temp1[combined_ws_review_status_col] = temp1.apply(\n",
    "    combine_review_status_for_same_performance_objective, \n",
    "    args = [ws_review_status_col,'No TMS Worksheet'], axis = 1)\n",
    "\n",
    "\n",
    "df_perf_raw_data_1 = pd.merge(df_perf_raw_data_1, temp1[['AMT_ID', 'Section', 'Performance Objective',combined_ws_review_status_col]], \n",
    "                              how = 'left', left_on = ['AMT_ID', 'Section','Performance Objective'],  right_on = ['AMT_ID', 'Section','Performance Objective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "under-transaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-113-44914227c22e>:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp1 = df_perf_raw_data_1[df_perf_raw_data_1['Performance Objective'] == performance_objective].groupby(['AMT_ID', 'Section', 'Performance Objective'])['Reviewed?', ws_review_status_col ].agg(set).reset_index()\n"
     ]
    }
   ],
   "source": [
    "performance_objective = 'Bridge and Tunnel Health'\n",
    "ws_review_status_col = 'Bridge WS Health Review Status'\n",
    "combined_ws_review_status_col = 'Combined Bridge Health Review Status'\n",
    "\n",
    "temp1 = df_perf_raw_data_1[df_perf_raw_data_1['Performance Objective'] == performance_objective].groupby(['AMT_ID', 'Section', 'Performance Objective'])['Reviewed?', ws_review_status_col ].agg(set).reset_index()\n",
    "\n",
    "temp1[combined_ws_review_status_col] = temp1.apply(\n",
    "    combine_review_status_for_same_performance_objective, \n",
    "    args = [ws_review_status_col, 'No Bridge Worksheet'], axis = 1)\n",
    "\n",
    "\n",
    "df_perf_raw_data_1 = pd.merge(df_perf_raw_data_1, temp1[['AMT_ID', 'Section', combined_ws_review_status_col]], \n",
    "                              how = 'left', left_on = ['AMT_ID', 'Section'],  right_on = ['AMT_ID', 'Section'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "complimentary-drunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-114-b6a7f2088214>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp1[temp1['Combined ActID']!= 'Can not be combined']['Combined ActID Review Status'] = 'Not Applicable'\n"
     ]
    }
   ],
   "source": [
    "#group performance objectives and calculate review status for groupable ACT Ids\n",
    "#summarize review status for each group of [AMT_ID, Section, Combined ActID]\n",
    "\n",
    "def group_target_act_id(df):\n",
    "    '''\n",
    "    CS, SLR, ADA, \n",
    "    '''\n",
    "    if df['ActID'] in ['H05','H06','H08','H13','H21','H33']:\n",
    "        return 'Complete Street'\n",
    "    elif df['ActID'] in ['I19','I20']:\n",
    "        return 'Sea Level Rise'\n",
    "    elif df['ActID'] in ['F21','F22','F23','F24','F25','F26','F27','F28', 'F31', 'F34']:\n",
    "        return 'ADA'    \n",
    "    else:\n",
    "        return 'Can not be combined'\n",
    "    \n",
    "df_perf_raw_data_1['Combined ActID'] = df_perf_raw_data_1.apply(group_target_act_id, axis = 1)     \n",
    "\n",
    "temp1 = df_perf_raw_data_1.groupby(['AMT_ID', 'Section','Combined ActID'])['Reviewed?'].agg(['unique']).reset_index()\n",
    "\n",
    "temp1['Combined ActID Review Status'] = temp1.apply(calc_review_status, args = ['unique'], axis = 1)   \n",
    "\n",
    "temp1[temp1['Combined ActID']!= 'Can not be combined']['Combined ActID Review Status'] = 'Not Applicable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fifth-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\n",
    "    'Combined ActID': 'Combined Performance Objective',\n",
    "}\n",
    "\n",
    "temp1 = temp1.rename(rename_dict, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-siemens",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "secret-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_combined_act_id(df):\n",
    "    if df['Performance Objective'] in [\"Complete Streets Fix Existing\",\"Complete Streets Build New\"]:\n",
    "        return 'Complete Street'\n",
    "        \n",
    "    elif df['Performance Objective'] in [\"ADA Pedestrian Infrastructure\"]:\n",
    "        return 'ADA'\n",
    "\n",
    "    elif df['Performance Objective'] in [\"Sea Level Rise\"]:\n",
    "        return 'Sea Level Rise'\n",
    "    else:\n",
    "        return 'Can not be combined'\n",
    "\n",
    "    \n",
    "df_perf_raw_data_1['Combined Performance Objective'] = df_perf_raw_data_1.apply(mark_combined_act_id, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "oriental-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data_1 = pd.merge(df_perf_raw_data_1, temp1[['AMT_ID', 'Section', 'Combined Performance Objective','Combined ActID Review Status']], \n",
    "                              how = 'left', left_on = ['AMT_ID', 'Section', 'Combined Performance Objective',],  \n",
    "                              right_on = ['AMT_ID', 'Section', 'Combined Performance Objective',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dated-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data_1 ['Combined ActID Review Status'].fillna('No Valid Act ID Data Available', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-milton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "abandoned-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarize review status for each group of [AMT_ID, Section, Program Objective]\n",
    "\n",
    "temp = df_perf_raw_data_1.groupby(['AMT_ID', 'Section','Performance Objective'])['Reviewed?'].agg(['unique']).reset_index()\n",
    "\n",
    "temp['Performance Objective Review Status'] = temp.apply(calc_review_status, args = ['unique'], axis = 1)   \n",
    "\n",
    "df_perf_raw_data_1 = pd.merge(df_perf_raw_data_1, temp[['AMT_ID', 'Section', 'Performance Objective','Performance Objective Review Status']], \n",
    "                              how = 'left', left_on = ['AMT_ID', 'Section', 'Performance Objective'],  \n",
    "                              right_on = ['AMT_ID', 'Section', 'Performance Objective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "floral-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_review_status(df):\n",
    "    if df['Combined Performance Objective'] == 'Can not be combined':\n",
    "        return df['Performance Objective Review Status']\n",
    "    else:\n",
    "        return df['Combined ActID Review Status']\n",
    "\n",
    "df_perf_raw_data_1['Review Status'] = df_perf_raw_data_1.apply(combine_review_status, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "rubber-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data_1['Review Status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-locator",
   "metadata": {},
   "source": [
    "## Fish Passage review status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-texture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "informative-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ck_priority_fp_review(df, FP1, FP2):\n",
    "    '''\n",
    "    check if the FP1 column to see if the activity for current data row is within FP priority list\n",
    "    return 'Not in Priority list' if not in the priority list\n",
    "    If it is in the priority list, check FP2 column, to see the data should be counted as priority list \n",
    "    '''\n",
    "    if df[FP1] != 'Priority List':\n",
    "        return \"Not in Priority list\"\n",
    "    elif pd.isna(df[FP2]) : \n",
    "        return 'No'\n",
    "    else:\n",
    "        return 'Yes'\n",
    "\n",
    "def ck_NONpriority_fp_review(df, FP1, FP2):\n",
    "    if df[FP1] == 'Priority List':\n",
    "        return \"In Priority list\"\n",
    "    elif pd.isna(df[FP2]): \n",
    "        return 'No'\n",
    "    else:\n",
    "        return 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-breakfast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "asian-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\n",
    "    'Fish PassagePriority List(Yes/No)': 'Fish Passage Priority List (Yes/No)',\n",
    "    'Is the proposedtreatmentexpected toremediate thefish passagepriority barrier?(Yes/No/NA)': 'Should Count toward Fish Passage Priority List (Yes/No)',\n",
    "    'PriorityIdentifier': 'Priority Identifier',\n",
    "    'AddressingFish Passagenot in the Priority List(Yes/No)': 'Addressing Fish Passage not in the Priority List (Yes/No)?',\n",
    "}\n",
    "\n",
    "df_brg_raw_data_1 = df_brg_raw_data_1.rename(rename_dict, axis = 1)\n",
    "\n",
    "\n",
    "rename_dict = {\n",
    "    'Is the proposed treatment expected to remediate the fish passage priority barrier? (Yes/No/NA)': 'Should Count toward Fish Passage Priority List (Yes/No)',\n",
    "}\n",
    "\n",
    "df_drain_raw_data_1 = df_drain_raw_data_1.rename(rename_dict, axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "rename_dict = {\n",
    "    'Fish Passage Type (Priority List / Not Priority List)': 'Fish Passage Priority List (Yes/No)',\n",
    "    'Should count as addressing Fish Passage (Yes/No)?': 'Should Count toward Fish Passage Priority List (Yes/No)',\n",
    "    'Priority Identifieror FP Identification': 'Priority Identifier',    \n",
    "}\n",
    "\n",
    "df_fp_raw_data_1 = df_fp_raw_data_1.rename(rename_dict, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "respiratory-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_brg_raw_data_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-hearts",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "heard-aurora",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP1 = 'Fish Passage Priority List (Yes/No)'\n",
    "FP2 = 'Should Count toward Fish Passage Priority List (Yes/No)'\n",
    "\n",
    "df_brg_raw_data_1['Fish Passage in the Priority List'] = df_brg_raw_data_1['Fish Passage Priority List (Yes/No)'].apply(lambda x: 'Yes' if x == 'Yes' else 'No')\n",
    "df_brg_raw_data_1['FP in Priority List reviewed by FP program?'] = df_brg_raw_data_1.apply(ck_priority_fp_review, args = [FP1, FP2], axis = 1)  \n",
    "df_brg_raw_data_1['Fish Passage NOT in the Priority List'] = df_brg_raw_data_1['Addressing Fish Passage not in the Priority List (Yes/No)?'].apply(lambda x: 'Yes' if x == 'Yes' else 'No')\n",
    "df_brg_raw_data_1['FP NOT in Priority List reviewed by FP program?'] = df_brg_raw_data_1.apply(ck_NONpriority_fp_review, args = [FP1, FP2], axis = 1)     \n",
    "\n",
    "\n",
    "df_drain_raw_data_1['Fish Passage in the Priority List'] = df_drain_raw_data_1['Fish Passage Priority List (Yes/No)'].apply(lambda x: 'Yes' if x == 'Yes' else 'No')\n",
    "df_drain_raw_data_1['FP in Priority List reviewed by FP program?'] = df_drain_raw_data_1.apply(ck_priority_fp_review, args = [FP1, FP2], axis = 1)  \n",
    "df_drain_raw_data_1['Fish Passage NOT in the Priority List'] = df_drain_raw_data_1['Addressing Fish Passage not in the Priority List (Yes/No)?'].apply(lambda x: 'Yes' if x == 'Yes' else 'No')\n",
    "df_drain_raw_data_1['FP NOT in Priority List reviewed by FP program?'] = df_drain_raw_data_1.apply(ck_NONpriority_fp_review, args = [FP1, FP2], axis = 1)  \n",
    "\n",
    "\n",
    "df_fp_raw_data_1['Fish Passage in the Priority List'] = df_fp_raw_data_1['Fish Passage Priority List (Yes/No)'].apply(lambda x: 'Yes' if x == 'Priority List' else 'No')\n",
    "df_fp_raw_data_1['FP in Priority List reviewed by FP program?'] = df_fp_raw_data_1.apply(ck_priority_fp_review, args = [FP1, FP2], axis = 1)\n",
    "df_fp_raw_data_1['Fish Passage NOT in the Priority List'] = df_fp_raw_data_1['Fish Passage Priority List (Yes/No)'].apply(lambda x: 'No' if x == 'Priority List' else 'Yes')\n",
    "df_fp_raw_data_1['FP NOT in Priority List reviewed by FP program?'] = df_fp_raw_data_1.apply(ck_NONpriority_fp_review, args = [FP1, FP2], axis = 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "actual-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_drain_raw_data_1[df_drain_raw_data_1['AMT_ID']==22867]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "intellectual-secretary",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['AMT_ID', 'Section','District','Priority Identifier','Should Count toward Fish Passage Priority List (Yes/No)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "tested-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_brg_raw_data_1[df_brg_raw_data_1['Fish Passage Priority List (Yes/No)'] == 'Yes'][target_cols]\n",
    "temp['Worksheet'] = 'Bridge'\n",
    "\n",
    "temp1 = df_drain_raw_data_1[df_drain_raw_data_1['Fish Passage Priority List (Yes/No)'] == 'Yes'][target_cols]\n",
    "temp1['Worksheet'] = 'Drainage'\n",
    "temp = temp.append(temp1)\n",
    "\n",
    "temp2 = df_fp_raw_data_1[df_fp_raw_data_1['Fish Passage Priority List (Yes/No)'] == 'Priority List'][target_cols]\n",
    "temp2['Worksheet'] = 'Fish Passage'\n",
    "temp = temp.append(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "thrown-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['Priority Identifier'].fillna(0, inplace = True)\n",
    "temp['Priority Identifier'] = temp['Priority Identifier'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "junior-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bookmark\n",
    "\n",
    "# temp[temp['AMT_ID']==22780]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "current-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['Should Count toward Fish Passage Priority List (Yes/No)'].fillna('Needs Review', inplace = True)\n",
    "\n",
    "temp_group = temp.groupby(['Worksheet','AMT_ID', 'Section', 'District', 'Priority Identifier'])['Should Count toward Fish Passage Priority List (Yes/No)'].agg('value_counts').reset_index(name = 'Counts')\n",
    "\n",
    "df_fp_list = temp_group.pivot(index=['Worksheet','AMT_ID', 'Section', 'District', 'Priority Identifier',], columns='Should Count toward Fish Passage Priority List (Yes/No)', values='Counts').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "controlled-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "handed-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "caring-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add columns if the pivot table did not generate this column\n",
    "if 'Needs Review' not in df_fp_list.columns:\n",
    "    df_fp_list['Needs Review'] = 0\n",
    "\n",
    "if 'N A' not in df_fp_list.columns:\n",
    "    df_fp_list['N A'] = 0\n",
    "\n",
    "if 'No' not in df_fp_list.columns:\n",
    "    df_fp_list['No'] = 0\n",
    "\n",
    "if 'Yes' not in df_fp_list.columns:\n",
    "    df_fp_list['Yes'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fossil-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fp_list.fillna(0, inplace = True)\n",
    "\n",
    "df_fp_list['Grand Total'] = df_fp_list['Needs Review'] + df_fp_list['N A'] + df_fp_list['No'] + df_fp_list['Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "isolated-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fp_list = pd.merge(df_fp_list, df_draft_pb[['AMT_ID','Section','EA_','Advertised Year',]],\n",
    "                     how = 'left', left_on = ['AMT_ID','Section',], right_on = ['AMT_ID','Section',]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "distinguished-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fp_list['RTL'] =  df_fp_list['Advertised Year'].apply(lambda x: int(x[-2:]) +2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "clean-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\n",
    "    'EA_': 'EA',\n",
    "    'Needs Review': 'Should Count Towards FP Priority List: Needs Review',\n",
    "    'N A':'Should Count Towards FP Priority List: Not Applicable',\n",
    "    'No':'Should Count Towards FP Priority List: No',\n",
    "    'Yes':'Should Count Towards FP Priority List: Yes',\n",
    "    'Grand Total': 'Should Count Towards FP Priority List: Grand Total',\n",
    "}\n",
    "\n",
    "df_fp_list = df_fp_list.rename(rename_dict, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dental-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fp_list['EA'] = df_fp_list['EA'].apply(uf.remove_punction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "elder-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fp_list= df_fp_list[['Worksheet', 'AMT_ID', 'Section', 'District', 'EA','RTL', \n",
    "                        'Priority Identifier',\n",
    "       'Should Count Towards FP Priority List: Needs Review',\n",
    "        'Should Count Towards FP Priority List: Not Applicable',\n",
    "       'Should Count Towards FP Priority List: No',\n",
    "       'Should Count Towards FP Priority List: Yes',\n",
    "       'Should Count Towards FP Priority List: Grand Total', ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "regulation-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "impossible-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_fp_list.groupby(['Worksheet', 'AMT_ID', 'Section','District', 'EA','RTL',])[[\n",
    "    'Should Count Towards FP Priority List: Needs Review',\n",
    "    'Should Count Towards FP Priority List: Not Applicable',\n",
    "       'Should Count Towards FP Priority List: No',\n",
    "       'Should Count Towards FP Priority List: Yes',\n",
    "       'Should Count Towards FP Priority List: Grand Total', ]].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ignored-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_FP_review_status(df):\n",
    "#     if df['Priority Identifier'] == 0: \n",
    "#         return 'No priority FP identified'\n",
    "    \n",
    "    if df['Should Count Towards FP Priority List: Needs Review'] == 0:\n",
    "        return 'Review Complete'\n",
    "    elif df['Should Count Towards FP Priority List: Not Applicable'] + df['Should Count Towards FP Priority List: No'] + df['Should Count Towards FP Priority List: Yes'] == 0:\n",
    "        return 'Needs Review'\n",
    "    else:\n",
    "        return 'Partially Reviewed'\n",
    "temp['Priority FP Review Status'] = temp.apply(calc_FP_review_status, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ecological-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fp_worksheet(df):\n",
    "    if df['Performance Objective'] == 'Fish Passage':\n",
    "        if df['Perf Activity Category'] == 'Sustainability/Climate Change':\n",
    "            return 'Fish Passage'\n",
    "        else:\n",
    "            return df['Perf Activity Category']\n",
    "    else:\n",
    "        return 'NA'\n",
    "    \n",
    "df_perf_raw_data_1['Worksheet'] = df_perf_raw_data_1.apply(calc_fp_worksheet, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "thermal-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data_1 = pd.merge(df_perf_raw_data_1, \n",
    "                              temp[['AMT_ID','Section','Worksheet','Priority FP Review Status']], \n",
    "                              how = 'left', \n",
    "                              left_on = ['AMT_ID','Section','Worksheet'], \n",
    "                              right_on = ['AMT_ID','Section','Worksheet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "becoming-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fp_list.groupby(['AMT_ID','Section','Worksheet'])['AMT_ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "thousand-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data_1['Priority FP Review Status'].fillna('No priority FP identified', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "injured-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_review_status_columns(df):\n",
    "    '''\n",
    "    combine review status from different review status columns into one combined review status column\n",
    "    '''\n",
    "    AMT_ID = df['AMT_ID']\n",
    "    Section = df['Section']\n",
    "    \n",
    "    if df['Performance Objective'] == 'Fish Passage':\n",
    "        return df['Priority FP Review Status']\n",
    "    \n",
    "    elif df['Performance Objective'] == \"Bridge and Tunnel Health\":\n",
    "        return df['Combined Bridge Health Review Status']\n",
    "    \n",
    "    elif df['Performance Objective'] == \"Transportation Management Systems\":\n",
    "        return df['Combined TMS Technology Review Status']\n",
    "    \n",
    "    elif df['Performance Objective'] == \"Transportation Management System Structures\":\n",
    "        return df['Combined TMS Structures Review Status']        \n",
    "    \n",
    "    else:\n",
    "        return df['Review Status'] \n",
    "    \n",
    "df_perf_raw_data_1['Combined Review Status'] = df_perf_raw_data_1.apply(combine_review_status_columns, axis = 1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-norfolk",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "incorrect-birthday",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# AMT_ID = 18672 \n",
    "# Section = 'PRG'\n",
    "\n",
    "# df_perf_raw_data_1[(df_perf_raw_data_1['AMT_ID'] == AMT_ID) & (df_perf_raw_data_1['Section'] == Section)\n",
    "#                    & (df_perf_raw_data_1['Performance Objective'] == 'Complete Streets Fix Existing')\n",
    "#                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "complimentary-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AMT_ID = 18672 \n",
    "# Section = 'PRG'\n",
    "\n",
    "# df_perf_raw_data_1[(df_perf_raw_data_1['AMT_ID'] == AMT_ID) & (df_perf_raw_data_1['Section'] == Section)\n",
    "#                    & (df_perf_raw_data_1['Combined ActID'] == \"Complete Street\")\n",
    "#                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "coral-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ck_HQ_review_complete(df):\n",
    "    # if modified after review, return Needs Review\n",
    "    if pd.notna(df['PerformanceChange Date After Review']):\n",
    "        return 'Needs Re-review'\n",
    "    else: #\n",
    "        return df['Combined Review Status']\n",
    "     \n",
    "df_perf_raw_data_1['Is HQ Review Complete?'] = df_perf_raw_data_1.apply(ck_HQ_review_complete, axis = 1)   \n",
    "\n",
    "df_perf_raw_data_1['Is HQ Review Complete?'].fillna('No Need for Review', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-sending",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "necessary-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data_1['PerformanceChange Date After Review'].fillna('NA', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-adolescent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-friday",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "indonesian-heading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #DEBUG: Bridge Health\n",
    "# # AMT_ID = 13550\n",
    "# AMT_ID = 23253\n",
    "# AMT_ID = 21974\n",
    "\n",
    "# df_perf_raw_data_1[\n",
    "#     (df_perf_raw_data_1['AMT_ID'] == AMT_ID)\n",
    "#     & (df_perf_raw_data_1['Performance Objective'].isin([\"Bridge and Tunnel Health\"]))\n",
    "# #     & (df_perf_raw_data_1['Performance Objective'] == 'No Performance Objective in the SHSMP')\n",
    "# ][['AMT_ID','Section','ActID','Review Date','Reviewed?','Worksheet','Combined ActID','Bridge WS Health Review Status','Is HQ Review Complete?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "anticipated-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_brg_raw_data_1[df_brg_raw_data_1['AMT_ID'] == AMT_ID][['AMT_ID', 'Section','Health Pre','Health Post','Post-Condition for Bridge Health entered?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "matched-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #DEBUG: TMS Technology\n",
    "\n",
    "# AMT_ID = 15955   # No TMS worksheet\n",
    "# AMT_ID = 21663   # Partially Reviewed\n",
    "# # AMT_ID = 19289  # Needs Review\n",
    "# AMT_ID = 19939   # Partially Reviewed\n",
    "# df_perf_raw_data_1[\n",
    "#     (df_perf_raw_data_1['AMT_ID'] == AMT_ID)\n",
    "#     & (df_perf_raw_data_1['Performance Objective']==\"Transportation Management Systems\")\n",
    "# #     & (df_perf_raw_data_1['Performance Objective'] == 'No Performance Objective in the SHSMP')\n",
    "# ][['AMT_ID','Section','ActID','Review Date','Reviewed?','Worksheet','Performance Objective','TMS WS Review Status','Combined TMS Technology Review Status','Is HQ Review Complete?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "enhanced-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #DEBUG: TMS Structures\n",
    "# AMT_ID = 19543   # Partially Reviewed\n",
    "\n",
    "# df_perf_raw_data_1[\n",
    "#     (df_perf_raw_data_1['AMT_ID'] == AMT_ID)\n",
    "#     & (df_perf_raw_data_1['Performance Objective'].isin([\"Transportation Management System Structures\"]))\n",
    "# #     & (df_perf_raw_data_1['Performance Objective'] == 'No Performance Objective in the SHSMP')\n",
    "# ][['AMT_ID','Section','ActID','Review Date','Reviewed?','Worksheet','Performance Objective','TMS WS Review Status','Combined TMS Technology Review Status','Combined TMS Structures Review Status','Is HQ Review Complete?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "lightweight-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tms_raw_data_1[(df_tms_raw_data_1['AMT_ID'] == AMT_ID)]\n",
    "# [['AMT_ID','Section','TMS Structural or Technology','Post-Condition entered?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "inappropriate-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #DEBUG: Complete Street\n",
    "\n",
    "# AMT_ID = 20245\n",
    "# df_perf_raw_data_1[\n",
    "#     (df_perf_raw_data_1['AMT_ID'] == AMT_ID)\n",
    "# #     & (df_perf_raw_data_1['Performance Objective'].isin([\"Complete Streets Fix Existing\",\"Complete Streets Build New\"]))\n",
    "# #     & (df_perf_raw_data_1['Performance Objective'] == 'No Performance Objective in the SHSMP')\n",
    "# ][['AMT_ID','Section','ActID','Review Date','Reviewed?','Worksheet',\n",
    "#    'Combined ActID','Combined ActID Review Status','Performance Objective','Performance Objective Review Status','Review Status','Is HQ Review Complete?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bronze-testimony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>ActID</th>\n",
       "      <th>Review Date</th>\n",
       "      <th>Reviewed?</th>\n",
       "      <th>Worksheet</th>\n",
       "      <th>Combined ActID</th>\n",
       "      <th>Priority FP Review Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10478</th>\n",
       "      <td>22780</td>\n",
       "      <td>TYP</td>\n",
       "      <td>C17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Drainage</td>\n",
       "      <td>Can not be combined</td>\n",
       "      <td>Partially Reviewed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AMT_ID Section ActID Review Date Reviewed? Worksheet  \\\n",
       "10478   22780     TYP   C17         NaN        No  Drainage   \n",
       "\n",
       "            Combined ActID Priority FP Review Status  \n",
       "10478  Can not be combined        Partially Reviewed  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DEBUG Fish Passage\n",
    "\n",
    "AMT_ID = 22780\n",
    "# AMT_ID = 20275\n",
    "df_perf_raw_data_1[\n",
    "    (df_perf_raw_data_1['AMT_ID'] == AMT_ID)\n",
    "    & (df_perf_raw_data_1['Performance Objective'] == 'Fish Passage')\n",
    "#     & (df_perf_raw_data_1['Performance Objective'] == 'No Performance Objective in the SHSMP')\n",
    "][['AMT_ID','Section','ActID','Review Date','Reviewed?','Worksheet','Combined ActID','Priority FP Review Status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "residential-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fp_list[df_fp_list['AMT_ID'] == AMT_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "hawaiian-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data_1[\n",
    "#     (df_perf_raw_data_1['AMT_ID'] == 20240)\n",
    "#     & (df_perf_raw_data_1['Performance Objective'] == 'Complete Streets Fix Existing')\n",
    "# #     & (df_perf_raw_data_1['Performance Objective'] == 'No Performance Objective in the SHSMP')\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-freeze",
   "metadata": {},
   "source": [
    "<a id='Export_Data'></a>\n",
    "\n",
    "# Export Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-tennessee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "romance-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drain_raw_data_1['Should Count toward Fish Passage not in the Priority List (Yes/No)'].fillna('N/A', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "defensive-saskatchewan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 891it [00:00, 6229.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing bridge_worksheet.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 11222it [00:02, 5552.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing drainage_worksheet.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 5it [00:00, 4999.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing fishpassage_worksheet.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 26it [00:00, 5196.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing fishpassage_list.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "df_brg_raw_data_1['Data_TimeStamp'] = Data_TimeStamp\n",
    "df_drain_raw_data_1['Data_TimeStamp'] = Data_TimeStamp\n",
    "df_fp_raw_data_1['Data_TimeStamp'] = Data_TimeStamp\n",
    "df_fp_list['Data_TimeStamp'] = Data_TimeStamp\n",
    "\n",
    "\n",
    "uf.export_csv(df_brg_raw_data_1, 'bridge_worksheet', PROJECTBOOKCHECK_HTTPSERVER_FOLDER, LOG_FILE)\n",
    "uf.export_csv(df_drain_raw_data_1, 'drainage_worksheet', PROJECTBOOKCHECK_HTTPSERVER_FOLDER, LOG_FILE)\n",
    "uf.export_csv(df_fp_raw_data_1, 'fishpassage_worksheet', PROJECTBOOKCHECK_HTTPSERVER_FOLDER, LOG_FILE)\n",
    "uf.export_csv(df_fp_list, 'fishpassage_list', PROJECTBOOKCHECK_HTTPSERVER_FOLDER, LOG_FILE)\n",
    "\n",
    "uf.export_hyper(df_brg_raw_data_1, 'bridge_worksheet', LOG_FILE)\n",
    "uf.export_hyper(df_drain_raw_data_1, 'drainage_worksheet', LOG_FILE)\n",
    "uf.export_hyper(df_fp_raw_data_1, 'fishpassage_worksheet', LOG_FILE)\n",
    "uf.export_hyper(df_fp_list, 'fishpassage_list', LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "alternate-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_quantity(df):\n",
    "    '''\n",
    "    get the numerical rows of the quanity, assign zero for non-numerical rows\n",
    "    '''\n",
    "    try: \n",
    "        return float(df['Quantity'])\n",
    "    except:\n",
    "        if df['Quantity'] == 'Yes':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "df_perf_raw_data_1['Quantity_Number'] = df_perf_raw_data_1.apply(convert_quantity, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "fallen-worker",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 20917it [00:03, 5326.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing performance_review_summary.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "# export performance raw data with review summary\n",
    "df_perf_raw_data_1['Data_TimeStamp'] = Data_TimeStamp\n",
    "\n",
    "out_cols = [\n",
    "    'District', 'AMT_ID', 'EA', 'EFIS', 'PPNO', 'Location', 'County',\n",
    "       'Route', 'BackPM', 'AheadPM', 'ProjectedRTL FY',\n",
    "       'Main Activity Category', 'Section', 'ActID', 'Perf Activity Category',\n",
    "       'Activity Detail', 'Performance Objective', 'Unit of Measurement',\n",
    "       'Quantity_Number', 'Assets in Good Cond', 'Assets in Fair Cond',\n",
    "       'Assets in Poor Cond', 'New Achieved', 'Comment', 'Guidance',\n",
    "       'Last Saved', 'Saved By', 'Post-Good', 'Post-Fair', 'Post-Poor',\n",
    "       'HQ ProgramReview - Agree with District?', 'HQ Comment', 'Review Date',\n",
    "       'PerformanceChange Date After Review', 'Status','Concatenate ID+Objective',\n",
    "       'Planning or Post-Planning', 'Advertised Year', 'F2G Achieved',\n",
    "       'P2G Achieved', \n",
    "       'Is HQ Review Complete?','Combined ActID','Combined Performance Objective',\n",
    "    'New SHOPP Candidate?',\n",
    "    'Data_TimeStamp']\n",
    "\n",
    "uf.export_csv(df_perf_raw_data_1[out_cols], 'performance_review_summary', PROJECTBOOKCHECK_HTTPSERVER_FOLDER, LOG_FILE)\n",
    "uf.export_hyper(df_perf_raw_data_1[out_cols], 'performance_review_summary', LOG_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-baptist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "resistant-isaac",
   "metadata": {},
   "source": [
    "\n",
    "<a id='FinalCleanUp'></a>\n",
    "## Final Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-machine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "understanding-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#clean up tableau publishing log file\n",
    "\n",
    "import os\n",
    "import glob\n",
    "# get a recursive list of file paths that matches pattern\n",
    "fileList = glob.glob('./*.log')\n",
    "# Iterate over the list of filepaths & remove each file.\n",
    "for filePath in fileList:\n",
    "    try:\n",
    "        os.remove(filePath)\n",
    "    except OSError:\n",
    "        print(\"Error while deleting file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time =  time.time()\n",
    "elapsed = end_time - start_time\n",
    "print('time elapsed : {} seconds'.format(elapsed))\n",
    "\n",
    "file_export_log = open(LOG_FILE, \"a\")  # append mode\n",
    "file_export_log.write('#####time elapsed : {} seconds \\n'.format(elapsed))\n",
    "file_export_log.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-consultancy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-baghdad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
