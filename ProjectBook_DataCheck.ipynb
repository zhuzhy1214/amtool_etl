{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "final-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-diagnosis",
   "metadata": {},
   "source": [
    "# Tip for quick search\n",
    "\n",
    "* Needs attention: the place where needs update or better logic\n",
    "* question to be answered: the place where things are still not clear\n",
    "* Manual Check: Unit test where you can drill in to find the data that leads to the check results for a specific project and specific check\n",
    "* TODO: things needs to be done\n",
    "* bookmark: stop point from last visit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-hawaii",
   "metadata": {},
   "source": [
    "# Update Note: \n",
    "\n",
    "11-2-2021: group activities in internal project book output file  <br>\n",
    "12-15-2021: \n",
    "* bring back the live data reading option\n",
    "* remove duplicated project ID in the internal project book\n",
    "12-17-2021:\n",
    "* download all SHOPP/Minor/HM worksheets. Filter the dataframe before data checks\n",
    "* remove defaul na option when downloading data\n",
    "\n",
    "12-20-2021:\n",
    "* import projectbookcheck_utilityfunction as uf \n",
    "* skip safety checks for TYP=9999\n",
    "* add Data_HourMinute, change Data_TimeStamp to Data_Date\n",
    "* use TenYrShopp_RawData_ file create time as Data_HourMinute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-excess",
   "metadata": {},
   "source": [
    "# Admin Notes:\n",
    "\n",
    "\n",
    "1. The AMTool dataset is archived daily as csv files and used for the project book check. \n",
    "The csv files are located at: \n",
    "r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\DataLake'\n",
    "\n",
    "2. The excel input files are checked daily and archived with datestamp whenever it is modified.\n",
    "The continuously updated excel input files are located at: r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\excel'\n",
    "The excel input file are archived at: r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\Data_MiscInput'\n",
    "To recover the archived excel file used in project book check for a target date, select the excel file with latest datestamp but is still earlier than the target date.\n",
    "\n",
    "3. The check summary export action is logged daily. It can be used for daily monitoring. \n",
    "The file export log is located at: \\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal\\log\n",
    "\n",
    "4. The published data are at:\n",
    "\n",
    "    * csv files for district asset manager: http://svgcshopp.dot.ca.gov/DataLake/ProjectBookCheck/\n",
    "    * csv files for HQ AM: \\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal\n",
    "    * tableau workbook with live data source: https://tableau.dot.ca.gov/#/site/AssetManagement/workbooks/1815/views\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-confidentiality",
   "metadata": {},
   "source": [
    "<a id='TableOfContents'></a>\n",
    "\n",
    "# Table Of Contents\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "### [Global Constants](#GlobalConstants)\n",
    "\n",
    "\n",
    "### [Load and cleanup source data](#Read_Data)\n",
    "\n",
    "* [Bridge_Inventory](#Bridge_Inventory)\n",
    "* [Bridge_Worksheet](#Bridge_Worksheet)\n",
    "* [Check_Exceptions](#Check_Exceptions)\n",
    "* [Counties](#Counties)\n",
    "* [Drainage_Worksheet](#Drainage_Worksheet)\n",
    "* [Minor_Raw_Data](#Minor_Raw_Data)\n",
    "* [Pavement_Worksheet](#Pavement_Worksheet)\n",
    "* [PID_Workload](#PID_Workload)\n",
    "* [Postmile_Check](#Postmile_Check)\n",
    "* [Programming_Summary](#Programming_Summary)\n",
    "* [ProgrammingList](#ProgrammingList)\n",
    "* [Project_Detail_Report](#Project_Detail_Report)\n",
    "* [Project_Obselete](#Project_Obselete)\n",
    "* [SHOPP_Candidates](#SHOPP_Candidates)\n",
    "* [SHOPP_Raw_Data](#SHOPP_Raw_Data)\n",
    "* [TenYrShopp_Perf_RawData](#TenYrShopp_Perf_RawData)\n",
    "* [TMS_Worksheet](#TMS_Worksheet)\n",
    "\n",
    "\n",
    "## Add fields to SHOPP raw data (calculate and join)\n",
    "* [Calculated Fields](#AddDataColumns)\n",
    "* [Join Tables](#DataJoining)\n",
    "\n",
    "\n",
    "\n",
    "## Data Check and Export\n",
    "\n",
    "\n",
    "## [Data Check List](#Issue_Table1)\n",
    "The main table of check issues, \n",
    "one issue per row, \n",
    "\n",
    "\n",
    "* [Will_this_project_be_included_in_the_Project_Book](#Will_this_project_be_included_in_the_Project_Book)\n",
    "* [Does_project_cost_exceed_Minor_Program_limits](#Does_project_cost_exceed_Minor_Program_limits)\n",
    "* [Is_Major_Damage_or_Mobility_Subcategory_Identified (Obselete)](#Is_Major_Damage_or_Mobility_Subcategory_Identified)\n",
    "* [Is_Planned_Project_RTL_in_a_FY_that_can_be_programmed_in_future_SHOPP_cycles](#Is_Planned_Project_RTL_in_a_FY_that_can_be_programmed_in_future_SHOPP_cycles)\n",
    "* [Is_the_PID_cycle_consistent_with_the_project_status_and_RTL](#Is_the_PID_cycle_consistent_with_the_project_status_and_RTL)\n",
    "* [Is_PIP_uploaded_(Active_and_Complete_PIDs)](#Is_PIP_uploaded_(Active_and_Complete_PIDs))\n",
    "* [Is_District_Director_Approval_Date_in_the_Future](#Is_District_Director_Approval_Date_in_the_Future)\n",
    "* [Is_the_EA_or_Project_ID_repeated_in_the_AM_tool](#Is_the_EA_or_Project_ID_repeated_in_the_AM_tool)\n",
    "* [Does_project_include_performance_related_to_each_location](#Does_project_include_performance_related_to_each_location)\n",
    "* [Is_Performance_tab_Complete](#Is_Performance_tab_Complete)\n",
    "* [Is_at_least_one_performance_activities_related_to_the_Activity_Category_of_planned_project](#Is_at_least_one_performance_activities_related_to_the_Activity_Category_of_planned_project)\n",
    "* [Is_Long_Lead_Project_Cost_and_RTL_completed_and_consistent](#Is_Long_Lead_Project_Cost_and_RTL_completed_and_consistent)\n",
    "* [Are_all_Project_Locations_(PM)_Valid](#Are_all_Project_Locations_(PM)_Valid)\n",
    "* [Is_Drainage_Worksheet_Complete](#Is_Drainage_Worksheet_Complete)\n",
    "* [Are_all_conditions_selected_for_bridge_replacements](#Are_all_conditions_selected_for_bridge_replacements)\n",
    "* [Does_Bridge_Worksheet_need_updates](#Does_Bridge_Worksheet_need_updates)\n",
    "* [Does_the_Plan_Year_in_the_Pavement_Worksheet_match_the_Project_RTL](#Does_the_Plan_Year_in_the_Pavement_Worksheet_match_the_Project_RTL)\n",
    "* [Is_Pavement_Worksheet_Complete](#Is_Pavement_Worksheet_Complete)\n",
    "* [Is_the_Pavement_Work_Limits_Direction_in_the_Pavement_Worksheet_complete (Obselete)](#Is_the_Pavement_Work_Limits_Direction_in_the_Pavement_Worksheet_complete)\n",
    "* [Is_TMS_Worksheet_Complete](#Is_TMS_Worksheet_Complete)\n",
    "* [Does_the_RTL_Plan_Year_in_the_TMS_Worksheet_match_the_Project_RTL](#Does_the_RTL_Plan_Year_in_the_TMS_Worksheet_match_the_Project_RTL)\n",
    "* [Do_SHOPP_project_data_in_the_AM_Tool_match_CTIPS_data](#Do_SHOPP_project_data_in_the_AM_Tool_match_CTIPS_data)\n",
    "* [Is_PID_completed_and_uploaded_for_current_SHOPP_Candidates](#Is_PID_completed_and_uploaded_for_current_SHOPP_Candidates)\n",
    "* [Is_CCE_uploaded](#Is_CCE_uploaded)\n",
    "* [LL_not_in_POR](#LL_not_in_POR)\n",
    "* [Is_Pavement_limits_repeating_in_the_same_project](#Is_Pavement_limits_repeating_in_the_same_project)\n",
    "* [Repeated_Bridge_within_the_same_project](#Repeated_Bridge_within_the_same_project)\n",
    "* [Is_TMS_Asset_repeating_in_the_same_project](#Is_TMS_Asset_repeating_in_the_same_project)\n",
    "* [Repeated_Culvert_within_the_same_project](#Repeated_Culvert_within_the_same_project)\n",
    "* [Check_Flag](#Check_Flag)\n",
    "* [Project_missing_AMT_ID](#Project_missing_AMT_ID)\n",
    "\n",
    "* Is the Pavement Worksheet using updated inventory and condition data (2019 APCS) for planned projects?\n",
    "* Is the Drainage Worksheet using updated inventory and condition data (Sept 2021 or later) for planned projects?\n",
    "* Is the TMS Worksheet using updated inventory and condition data (June 2021 or later) for planned projects?\n",
    "* Is this project in the Project Book but not in the PID Workplan?  (Applies to non-reservation planned projects in years 6 or 7, and to Long Lead planned projects with PA&ED allocation in year 4.)\n",
    "* Is this project in the PID Workplan but not in the Project Book?  (Applies to non-reservation planned projects in years 6 or 7, and to Long Lead planned projects with PA&ED allocation in year 4.)\n",
    "* For planned projects, does the Performance Tab include a response to \"Is any location within the project limits Ped/Bike accessible?\"\n",
    "* Does the CCA date in the AM Tool match PRSM?\n",
    "* Does the CCA section including performance need to be completed?  (Applies to projects with CCA date on or after July 1, 2020)\n",
    "\n",
    "## [New Checks](#NewChecks)\n",
    "* 'Check Safety Comment'\n",
    "#Check comments about ActID of E55 and E58\n",
    "#if ActID == E55 and E58 and the comments include: 'HQ added the activity and District needs to review it.', mark the project\n",
    "* 'TMS data update needed for the project?'\n",
    "\n",
    "## [Internal Checks](#InteralChecks)\n",
    "* Does amendment date needs to be removed?\n",
    "* Need to add Resource in the PID workplan?\n",
    "* PRG section needs amendment date?\n",
    "* PPC section needs amendment date?\n",
    "\n",
    "## [Export Internal Check Summary](#Export_internal_check_summary)\n",
    "* internal check summary (csv)\n",
    "\n",
    "\n",
    "## [Export Check Summary](#Export_Table1)\n",
    "* data check summary matrix (csv)\n",
    "* data check summary punchlist (csv, tableau datasource)\n",
    "* project missing AMT_ID (csv)\n",
    "\n",
    "\n",
    "## [Export repeated EA or EFIS](#Export_repated_EA_EFIS)\n",
    "* repeated EA (csv)\n",
    "* repeated EFIS (csv)\n",
    "\n",
    "## [Export repeated assets](#Export_repeated_assets)\n",
    "* repeated assets (csv, tableau datasource)\n",
    "\n",
    "\n",
    "## [Export Projectbook](#Export_ProjectBook)\n",
    "* Project book for District asset manager (csv, tableau datasource)\n",
    "* Project book for HQ internal use (csv)\n",
    "\n",
    "\n",
    "## [Export Projectbook Check Sumary Key Dates](#Export_KeyDates)\n",
    "\n",
    "\n",
    "\n",
    "## [Final Clean Up](#FinalCleanUp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-mozambique",
   "metadata": {},
   "source": [
    "# Import common modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fundamental-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "\n",
    "# import requests\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "second-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intellectual-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show dataframe without skip column\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acquired-istanbul",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using the Extract API 2.0, please save the output as .hyper format\n"
     ]
    }
   ],
   "source": [
    "# from config_datasource import *\n",
    "# from projectbookcheck_utilityfunction import *\n",
    "from constants import *\n",
    "import projectbookcheck_utilityfunction as uf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-aspect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "comic-disaster",
   "metadata": {},
   "source": [
    "# General Approach\n",
    "\n",
    "use SHOPP raw data as basis for data checks. \n",
    "Each project only occupies one line\n",
    "\n",
    "can expand columns, only if it will not create duplicate rows in the SHOPP raw dataset. \n",
    "\n",
    "\n",
    "Question: what is the entire list of projects, how to include projects without AMT_ID (SHOPP ID)\n",
    "Ans: use raw data, check missing SHOPP ID seperately \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-museum",
   "metadata": {},
   "source": [
    "# Data update procedure\n",
    "\n",
    "data schema: name, data type, default value if missing\n",
    "\n",
    "Option 1: Keep Excel column header fixed (number and sequence)\n",
    "\n",
    "Option 2: Maintain a dictionary of Excel column name and dataframe column name\n",
    "\n",
    "\n",
    "\n",
    "# Check update procedure\n",
    "\n",
    "Create utility function in python, in seperate module\n",
    "add the additional check in the main ETL module\n",
    "update the final data visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-celebrity",
   "metadata": {},
   "source": [
    "# Data clean process\n",
    "\n",
    "* funding amount: remove dollar sign, \n",
    "* fill missing value, string, numerical, \n",
    "* remove leading single quote for string value\n",
    "* strip off leading and trailing space \n",
    "\n",
    "* regulate column names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-theory",
   "metadata": {},
   "source": [
    "<a id='GlobalConstants'></a>\n",
    "## Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "million-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use 'csv' to read data from data lake, use 'live' to read data directly from AmTool Server\n",
    "# AMTool_Data_Type = 'csv'\n",
    "\n",
    "# # DATALAKE_FOLDER = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\DataLake'\n",
    "\n",
    "# #input data\n",
    "# DATALAKE_FOLDER = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\DataLake'\n",
    "# PROJECTBOOKCHECK_INPUT_FOLDER = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\excel'\n",
    "\n",
    "# #output data\n",
    "# DATALAKE_HTTPSEVER_FOLDER = 'C:\\inetpub\\wwwroot\\DataLake\\ProjectBookCheck'\n",
    "# PROJECTBOOKCHECK_OUTPUT_FOLDER = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal'\n",
    "\n",
    "# #log data\n",
    "# log_folder = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal\\log'\n",
    "\n",
    "# # TARGET_FY = 2021\n",
    "\n",
    "\n",
    "# # # CURRENT_FY\n",
    "\n",
    "# TARGETDATE = datetime.today().strftime(\"%m-%d-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sorted-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_HHMM = datetime.now().strftime(\"%H%M\")\n",
    "TARGETDATE = datetime.today().strftime(\"%m-%d-%Y\")\n",
    "CURRENT_FY = uf.fiscalyear(datetime.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "distinct-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#override to get the live data\n",
    "# DATA_SOURCE_TYPE = 'live'\n",
    "\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# TARGETDATE = datetime.strptime('09-12-2021', \"%m-%d-%Y\").strftime(\"%m-%d-%Y\")\n",
    "\n",
    "\n",
    "# PROJECTBOOKCHECK_INPUT_FOLDER = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_DataChecksSupport\\dev\\input'\n",
    "# PROJECTBOOKCHECK_HTTPSEVER_FOLDER = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_DataChecksSupport\\dev\\output'\n",
    "# PROJECTBOOKCHECK_OUTPUT_FOLDER = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_DataChecksSupport\\dev\\output'\n",
    "\n",
    "# LOG_FILE = r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_DataChecksSupport\\dev\\log\\ProjectBookExport.log'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-ready",
   "metadata": {},
   "source": [
    "<a id='Read_Data'></a>\n",
    "\n",
    "# Read Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suitable-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #DO NOT USE LIVE DATA, USE THE 5AM DATA LAKE ARCHIVES INSTEAD:\n",
    "# # for live data reading code, go to get_live_data.py\n",
    "# #it takes about 5 minutes to read live data, instead of 0.5 minute to read archived csv files.\n",
    "\n",
    "# if DATA_SOURCE_TYPE == 'live':\n",
    "\n",
    "#     import urllib\n",
    "\n",
    "#     #get live data\n",
    "#     dict_resource = {\n",
    "#         'TenYrShopp_RawData_' : \"http://10.56.12.86/pirs/tenyrshopp/Raw_data.cfm?selectdistrict=all&selectcounty=all&Route=&program=all&pid_cycle=all&shopp_yr=all&tenyearshopp=all&EA=&pID=&projectID=&proj_prog=all&report=Rawdata\"\n",
    "#         ,\n",
    "#         'TenYrShopp_PerfM_Raw_Data_': \"http://10.56.12.86/pirs/tenyrshopp/Raw_data_PerfM.cfm?selectdistrict=all&selectcounty=all&Route=&program=all&pid_cycle=all&shopp_yr=all&tenyearshopp=all&EA=&pID=&projectID=&proj_prog=all&fsection=all\"\n",
    "#         ,\n",
    "#         'Rawdata_Pavement_Worksheet_' : \"http://10.56.12.86/pirs/tenyrshopp/Rawdata_Pavement_WS.cfm?Program=SHOPP&fsection=all\"\n",
    "#         ,\n",
    "#         'Rawdata_Drainage_Worksheet_' : \"http://10.56.12.86/pirs/tenyrshopp/Rawdata_Drainage_WS.cfm?Program=SHOPP&fsection=all\"\n",
    "#         ,\n",
    "#         'Rawdata_Bridge_Worksheet_' : \"http://10.56.12.86/pirs/tenyrshopp/Rawdata_Bridge_WS.cfm?Program=SHOPP&fsection=all\"\n",
    "#         ,\n",
    "#         'Rawdata_TMS_Worksheet_' : \"http://10.56.12.86/pirs/tenyrshopp/Rawdata_TMS_WS.cfm?Program=SHOPP&fsection=all\"\n",
    "#         ,\n",
    "#         'PAC_Perfomrance_RawData_all_' : \"http://10.56.12.86/pirs/tenyrshopp/PAC_Performance_RawData.cfm?District=All\"\n",
    "#         ,\n",
    "#         'Project_Postmile_Check_' : \"http://10.56.12.86/pirs/TenYrShopp/project_Locations.cfm?District=all&view=All&program=All\",\n",
    "\n",
    "#         'Programming_Summary_' : \"http://10.56.12.86/pirs/tenyrshopp/?District=All&program=All&fsection=All&pID=&Placeholder=All&SType=A&page=RawdataProg&report=RawdataProg&selectdistrict=All&getreport=yes&submit=Get+Report\",\n",
    "\n",
    "#         'Minor_Project_Details_Raw_Data_' : 'http://10.56.12.86/pirs/tenyrshopp/?select&Route=&fPType=All&fAllocated=All&fAwarded=All&program=All&pID=&ProjectID=&EA=&FYInUse=&page=RawdataM&report=RawdataM&selectdistrict=All&getreport=yes&submit=Get+Report',\n",
    "\n",
    "#         'HM_Project_Details_Raw_Data_' : 'http://10.56.12.86/pirs/tenyrshopp/?selectcounty=All&Route=&program=All&pID=&ProjectID=&EA=&FYInUse=&Placeholder=All&page=RawdataHM&report=RawdataHM&selectdistrict=All&getreport=yes&submit=Get+Report'\n",
    "#     }\n",
    "\n",
    "#     sleep = 1\n",
    "\n",
    "#     filename = 'TenYrShopp_RawData_'\n",
    "#     url = dict_resource[filename]\n",
    "#     with urllib.request.urlopen(url) as response:\n",
    "#         df_SHOPP_raw_data = pd.read_html(response.read())[-1]\n",
    "\n",
    "#     time.sleep(sleep)\n",
    "#     filename = 'TenYrShopp_PerfM_Raw_Data_'\n",
    "#     url = dict_resource[filename]\n",
    "#     with urllib.request.urlopen(url) as response:\n",
    "#         df_perf_raw_data = pd.read_html(response.read())[-1]\n",
    "\n",
    "\n",
    "\n",
    "#     time.sleep(sleep)\n",
    "#     filename = 'Rawdata_Pavement_Worksheet_'\n",
    "#     url = dict_resource[filename]\n",
    "#     with urllib.request.urlopen(url) as response:\n",
    "#         df_pav_raw_data = pd.read_html(response.read())[-1]\n",
    "#     df_pav_raw_data.columns = df_pav_raw_data.columns.droplevel()\n",
    "#     df_pav_raw_data.columns = df_pav_raw_data.columns.droplevel()\n",
    "\n",
    "#     time.sleep(sleep)\n",
    "#     filename = 'Rawdata_Drainage_Worksheet_'\n",
    "#     url = dict_resource[filename]\n",
    "#     with urllib.request.urlopen(url) as response:\n",
    "#         df_drain_raw_data = pd.read_html(response.read())[-1]\n",
    "\n",
    "\n",
    "#     time.sleep(sleep)    \n",
    "#     filename = 'Rawdata_Bridge_Worksheet_'\n",
    "#     url = dict_resource[filename]\n",
    "#     with urllib.request.urlopen(url) as response:\n",
    "#         df_brg_raw_data = pd.read_html(response.read())[-1]\n",
    "#     df_brg_raw_data.columns = df_brg_raw_data.columns.droplevel()\n",
    "\n",
    "\n",
    "#     time.sleep(sleep)    \n",
    "#     filename = 'Rawdata_TMS_Worksheet_'\n",
    "#     url = dict_resource[filename]\n",
    "#     with urllib.request.urlopen(url) as response:\n",
    "#         df_tms_raw_data = pd.read_html(response.read())[-1]\n",
    "\n",
    "\n",
    "#     time.sleep(sleep)    \n",
    "#     filename = 'Project_Postmile_Check_'\n",
    "#     url = dict_resource[filename]\n",
    "#     with urllib.request.urlopen(url) as response:\n",
    "#         df_pm_check = pd.read_html(response.read())[-1]\n",
    "\n",
    "\n",
    "#     time.sleep(sleep)\n",
    "#     filename = 'Programming_Summary_'\n",
    "#     url = dict_resource[filename]\n",
    "#     with urllib.request.urlopen(url) as response:\n",
    "#         df_program_summary = pd.read_html(response.read())[-1]\n",
    "\n",
    "\n",
    "#     time.sleep(sleep)    \n",
    "#     filename = 'HM_Project_Details_Raw_Data_'\n",
    "#     url = dict_resource[filename]\n",
    "#     with urllib.request.urlopen(url) as response:\n",
    "#         df_HM_raw_data = pd.read_html(response.read())[-1]\n",
    "\n",
    "\n",
    "#     time.sleep(sleep)    \n",
    "#     filename = 'Minor_Project_Details_Raw_Data_'\n",
    "#     url = dict_resource[filename]\n",
    "#     with urllib.request.urlopen(url) as response:\n",
    "#         df_Minor_raw_data = pd.read_html(response.read())[-1]\n",
    "        \n",
    "        \n",
    "#     DATA_HHMM = datetime.now().strftime(\"%H%M\")\n",
    "# else:\n",
    "#     print('skip getting live data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "artificial-handy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s151589\\Anaconda3\\envs\\dataprep\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (38) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "C:\\Users\\s151589\\Anaconda3\\envs\\dataprep\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (29,30,31,32,34) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "if DATA_SOURCE_TYPE == 'csv':\n",
    "    filename = 'TenYrShopp_RawData_'\n",
    "    df_SHOPP_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE))\n",
    "\n",
    "    filename = 'TenYrShopp_PerfM_Raw_Data_'\n",
    "    df_perf_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE))\n",
    "\n",
    "    filename = 'Rawdata_Bridge_Worksheet_'\n",
    "    df_brg_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE), skiprows = [0], header = 0)\n",
    "\n",
    "    filename = 'Rawdata_Pavement_Worksheet_'\n",
    "    df_pav_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE), skiprows = [0], header = 1)\n",
    "\n",
    "\n",
    "    filename = 'Rawdata_Drainage_Worksheet_'\n",
    "    df_drain_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE), header = 0)\n",
    "\n",
    "    filename = 'Rawdata_TMS_Worksheet_'\n",
    "    df_tms_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE), header = 0)\n",
    "\n",
    "    filename = 'Project_Postmile_Check_'\n",
    "    df_pm_check = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE), header = 0)\n",
    "\n",
    "    filename = 'Programming_Summary_'\n",
    "    df_program_summary = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE), header = 0)\n",
    "\n",
    "\n",
    "    filename = 'Minor_Project_Details_Raw_Data_'\n",
    "    df_Minor_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE))\n",
    "\n",
    "\n",
    "    filename = 'HM_Project_Details_Raw_Data_'\n",
    "    df_HM_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE))\n",
    "    \n",
    "    \n",
    "    filename = 'TenYrShopp_RawData_'\n",
    "    path_to_file = r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE)\n",
    "    t = os.path.getmtime(path_to_file)\n",
    "    DATA_HHMM = int(datetime.fromtimestamp(t).strftime('%H%M'))\n",
    "#     Data_TimeStamp = datetime.fromtimestamp(t).strftime(\"%m-%d-%Y %H:%M:%S\")\n",
    "else:\n",
    "    print('skip getting csv data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-cleaning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aerial-reservation",
   "metadata": {},
   "source": [
    "## Read the AMT_ID with TMS data change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "suspended-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'AM tool Ids_TMS needs to update if in POR.xlsx'\n",
    "\n",
    "df_TMS_Datachange = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "indirect-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "sht = 'KeyDates'\n",
    "\n",
    "filename = 'GlobalParameters.xlsx'\n",
    "\n",
    "df_GlobalParameters = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename), sheet_name =sht) \n",
    "\n",
    "TMS_Data_Date = df_GlobalParameters.loc[0,'TMS_Data_Date'].to_pydatetime().strftime(\"%m-%d-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-guess",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "charming-handling",
   "metadata": {},
   "source": [
    "<a id='Minor_Raw_Data'></a>\n",
    "\n",
    "## Minor and HM Raw Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "solid-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_Minor_raw_data['District'] = df_Minor_raw_data['District'].apply(uf.remove_punction)\n",
    "df_Minor_raw_data['District'] = df_Minor_raw_data['District'].astype(int)\n",
    "\n",
    "df_Minor_raw_data['Unique EA'] = df_Minor_raw_data.apply(uf.calc_unique_EA, axis = 1)\n",
    "\n",
    "dict_rename = {\n",
    "    'Project ID':'EFIS'\n",
    "              }\n",
    "df_Minor_raw_data = df_Minor_raw_data.rename(dict_rename, axis = 1)\n",
    "\n",
    "#conver EFIS to numeric, \n",
    "#filter null and 0 \n",
    "\n",
    "\n",
    "df_Minor_raw_data['EFIS'] = pd.to_numeric(df_Minor_raw_data['EFIS'], errors='coerce')\n",
    "df_Minor_raw_data = df_Minor_raw_data[(df_Minor_raw_data['EFIS'].notna()) & df_Minor_raw_data['EFIS'] != 0]\n",
    "\n",
    "#rename ID\n",
    "dict_rename = {\n",
    "    'ID': 'AMT_ID',\n",
    "    }\n",
    "df_Minor_raw_data= df_Minor_raw_data.rename(dict_rename, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "operational-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_HM_raw_data['Unique EA'] = df_HM_raw_data.apply(uf.calc_unique_EA, axis = 1)\n",
    "\n",
    "df_HM_raw_data['EFIS'] = pd.to_numeric(df_HM_raw_data['EFIS'], errors='coerce')\n",
    "df_HM_raw_data = df_HM_raw_data[(df_HM_raw_data['EFIS'].notna()) & df_HM_raw_data['EFIS'] != 0]\n",
    "\n",
    "#rename ID\n",
    "dict_rename = {'ID': 'AMT_ID',}\n",
    "df_HM_raw_data= df_HM_raw_data.rename(dict_rename, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-exception",
   "metadata": {},
   "source": [
    "<a id='SHOPP_Raw_Data'></a>\n",
    "## SHOPP Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "palestinian-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SHOPP_raw_data.name = 'df_SHOPP_raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "usual-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns \n",
    "\n",
    "dict_rename_rawdata = {\n",
    "                       'County':'County TYP',\n",
    "                       'Route': 'Route TYP',\n",
    "                       'BackPM':'BackPM TYP',\n",
    "                       'AheadPM':'AheadPM TYP',\n",
    "                       'ID': 'AMT_ID',\n",
    "                       'Ten-Year Plan': 'Ten-Year Plan RD',\n",
    "                       'County.1' : 'County PRG',\n",
    "                       'Route.1' : 'Route PRG',\n",
    "                       'BackPM.1':'BackPM PRG',\n",
    "                       'AheadPM.1' : 'AheadPM PRG',\n",
    "                       'County.2' : 'County PCR',\n",
    "                       'Route.2' : 'Route PCR',\n",
    "                       'BackPM.2':'BackPM PCR',\n",
    "                       'AheadPM.2' : 'AheadPM PCR',\n",
    "                       'Activity Category': 'Activity'\n",
    "                      }\n",
    "df_SHOPP_raw_data = df_SHOPP_raw_data.rename(dict_rename_rawdata, axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "directed-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove leading puncture for target columns\n",
    "cols_strip = ['District','Route TYP','EA','EFIS','Route PRG','PPNO','Route PCR']\n",
    "for c in cols_strip :\n",
    "    df_SHOPP_raw_data[c] = df_SHOPP_raw_data[c].str.strip(\"'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aquatic-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cost_columns = [\n",
    "    'RW Cost ($K)',\n",
    "    'Const Cost ($K)',\n",
    "    'Support Cost ($)',\n",
    "    'TYP Total Project Cost ($K)',\n",
    "    'PAED ($K)',\n",
    "    'PSE ($K)',\n",
    "    'R/W ($K)',\n",
    "    'CONS ($K)',\n",
    "    'Prog Support Cost ($)',\n",
    "    'Prog RW Cost ($K)',\n",
    "    'Prog Const Cost ($K)',\n",
    "    'Prog Total Project Cost ($K)',\n",
    "    'PCR R/W Cap ($K)',\n",
    "    'PCR Const Cap ($K)',\n",
    "    'PCR Support Cost ($K)',\n",
    "    'PCR Total Cost ($K)',\n",
    "    'Project Cost In Use',\n",
    "    'Total LL Prog ($K)',\n",
    "    'LL PAED Cost ($K)',\n",
    "    'LL CONS Cap ($K)'\n",
    "               ]\n",
    "\n",
    "for c in cost_columns:\n",
    "    df_SHOPP_raw_data[c] = df_SHOPP_raw_data[c].apply(uf.curreny_to_float)\n",
    "    df_SHOPP_raw_data[c].fillna(0, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "checked-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data clean \n",
    "#data type regulation\n",
    "#string/text data regulation\n",
    "\n",
    "df_SHOPP_raw_data['District'] =df_SHOPP_raw_data['District'].astype(int)\n",
    "\n",
    "df_SHOPP_raw_data['EFIS'] = pd.to_numeric(df_SHOPP_raw_data['EFIS'], errors='coerce')\n",
    "\n",
    "df_SHOPP_raw_data['Route PCR'] = df_SHOPP_raw_data['Route PCR'].astype(str)\n",
    "\n",
    "#data trimming\n",
    "#row trimming\n",
    "df_SHOPP_raw_data= df_SHOPP_raw_data[df_SHOPP_raw_data['District'] != 56]\n",
    "\n",
    "#column trimming\n",
    "df_SHOPP_raw_data.drop(['District Priority', 'PIR Performance Report'],\n",
    "  axis='columns', inplace=True, errors='ignore')\n",
    "\n",
    "\n",
    "\n",
    "#Question to be answered:\n",
    "#for EA Raw Data, the missing data is not null , but ''. Should we handle the missing data uniformly for string data?\n",
    "\n",
    "#TODO:\n",
    "#fill missing data\n",
    "#data quality check (checksum,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bright-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_SHOPP_raw_data['CCA Date Miilestone (M600)'] = df_SHOPP_raw_data['CCA Date Miilestone (M600)'].apply(uf.regulate_timestamp_format)\n",
    "\n",
    "\n",
    "# df_SHOPP_raw_data['Data_HourMinute'] = TARGETDATE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "responsible-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-belief",
   "metadata": {},
   "source": [
    "<a id='TenYrShopp_Perf_RawData'></a>\n",
    "## TenYrShopp_Perf_RawData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "psychological-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "dict_rename_perf_rawdata = {\n",
    "                           'ID': 'AMT_ID',\n",
    "#                             'ProjectedRTL FY': 'Projected RTL FY',\n",
    "    \n",
    "# 'ActID':'Performance_ActID',\n",
    "# 'Quantity':    'Performance_Quantity'\n",
    "              }\n",
    "\n",
    "df_perf_raw_data = df_perf_raw_data.rename(dict_rename_perf_rawdata, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "found-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_strip = ['EA','EFIS','PPNO']\n",
    "for c in cols_strip :\n",
    "    df_perf_raw_data[c] = df_perf_raw_data[c].str.strip(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "secure-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-economy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sustainable-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data clean \n",
    "#data type regulation\n",
    "\n",
    "df_perf_raw_data['Quantity'] = df_perf_raw_data['Quantity'].fillna(0)\n",
    "df_perf_raw_data['Assets in Good Cond'] = df_perf_raw_data['Assets in Good Cond'].fillna(0)\n",
    "df_perf_raw_data['Assets in Fair Cond'] = df_perf_raw_data['Assets in Fair Cond'].fillna(0)\n",
    "df_perf_raw_data['Assets in Poor Cond'] = df_perf_raw_data['Assets in Poor Cond'].fillna(0)\n",
    "df_perf_raw_data['New Assets Added'] = df_perf_raw_data['New Assets Added'].fillna(0)\n",
    "\n",
    "df_perf_raw_data['EFIS'] = pd.to_numeric(df_perf_raw_data['EFIS'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dedicated-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data trimming\n",
    "#row\n",
    "df_perf_raw_data= df_perf_raw_data[df_perf_raw_data['District'] != 56]\n",
    "#column\n",
    "df_perf_raw_data.drop(['PID Cycle', 'TYP','ProjectedSHOPP Cycle','RequestedRTL FY','DistrictPriority'],\n",
    "  axis='columns', inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sapphire-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data.name = 'df_perf_raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-tampa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "finnish-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw = df_perf_raw_data.merge(df_SHOPP_raw_data, \n",
    "#                               how = 'outer', \n",
    "#                               left_on = 'AMT_ID', right_on = 'AMT_ID',\n",
    "#                              suffixes = ['_raw_perf', '_raw_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-healthcare",
   "metadata": {},
   "source": [
    "<a id='ProgrammingList'></a>\n",
    "## Programming List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "completed-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "shts = ['2010 SHOPP',\n",
    "        '2012 SHOPP',\n",
    "        '2014 SHOPP',\n",
    "        '2016 SHOPP',\n",
    "        '2018 SHOPP',\n",
    "        '2020 SHOPP',\n",
    "        'Long Lead'\n",
    "        ]\n",
    "\n",
    "filename = 'Programming_list.xlsx'\n",
    "\n",
    "df_dict = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename), sheet_name =shts) \n",
    "\n",
    "\n",
    "df_program = pd.DataFrame()\n",
    "\n",
    "for k, v in df_dict.items():\n",
    "#     print(type(v))\n",
    "#     print(k)\n",
    "    v['Table Names'] = k\n",
    "#     print(v.columns)\n",
    "    df_program = df_program.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "optional-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "dict_rename_program = {\n",
    "#                         'EA':'EA', \n",
    "                        'EFIS':'EFIS_Program', \n",
    "#                         'PPNO':'PPNO Programming', \n",
    "                        'Total Capital & Support':'Total Capital & Support Cost',\n",
    "#                         'Route': 'Route Programming',\n",
    "              }\n",
    "\n",
    "df_program = df_program.rename(dict_rename_program, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "thick-drunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s151589\\Anaconda3\\envs\\dataprep\\lib\\site-packages\\pandas\\core\\frame.py:4459: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n"
     ]
    }
   ],
   "source": [
    "#data clean \n",
    "#data type regulation\n",
    "# df_program['Dist'] = df_program['Dist'].astype(int)\n",
    "# df_program['EFIS'] = pd.to_numeric(df_program['EFIS'], errors='coerce')\n",
    "\n",
    "fillna_columns = ['Con Sup','RW Sup','PA&ED','PS&E', 'PA&ED', 'RW', 'Con']\n",
    "\n",
    "df_program[fillna_columns].fillna(0, inplace=True)\n",
    "df_program['Route'].fillna('Various', inplace=True)\n",
    "\n",
    "df_program['Support Cost'] = df_program['Con Sup']+df_program['RW Sup']+df_program['PA&ED']+df_program['PS&E']\n",
    "df_program['Capital Cost'] = df_program['Con']+df_program['RW']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "royal-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_program[['Con Sup','RW Sup','PA&ED','PS&E']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "supreme-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_program['PA&ED'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "hydraulic-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove leading puncture for all string columns\n",
    "# df_program.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "vulnerable-twelve",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "#data transformation\n",
    "\n",
    "# df_program.dropna(subset = ['EFIS_Program'], inplace = True)\n",
    "df_program['FY'] = df_program['FY'].apply(uf.FY_cleanup)\n",
    "\n",
    "df_program['Begin Post Miles'] = df_program['Post Miles'].apply(lambda x: str(x).split('/')[0])\n",
    "df_program['End Post Miles'] = df_program['Post Miles'].apply(lambda x: str(x).split('/')[0] if '/' in str(x) else np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "settled-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data trimming\n",
    "df_program.drop(['PM1BF', 'PM1B', 'PM1AF','PM1A',], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "suburban-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_program.name = 'df_program'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "promising-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_program.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "coastal-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data sanity check\n",
    "#check duplicates\n",
    "#check null\n",
    "#check data type\n",
    "\n",
    "if df_program['EFIS_Program'].value_counts(dropna = False).max() > 1:\n",
    "    Print('Duplicate EFIS ID found, please check the source data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "civilian-particle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_program['EFIS_Program'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-citizenship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "nearby-maldives",
   "metadata": {},
   "source": [
    "<a id='SHOPP_Candidates'></a>\n",
    "## SHOPP candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "alternate-treaty",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SHOPP candidates.xlsx'\n",
    "\n",
    "df_shopp_candidate = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "appreciated-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rename_candidate = {\n",
    "                        'SHOPP ID':'AMT_ID', \n",
    "    'Advertised Year': 'Advertised Year_Candidate',\n",
    "    'Project Cost ($K)' : 'Project Cost ($K)_Candidate'\n",
    "              }\n",
    "\n",
    "df_shopp_candidate = df_shopp_candidate.rename(dict_rename_candidate, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "common-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shopp_candidate['AMT_ID'] = df_shopp_candidate['AMT_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bridal-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_columns = ['AMT_ID', 'Candidate Type','Advertised Year_Candidate','Project Cost ($K)_Candidate']\n",
    "df_shopp_candidate = df_shopp_candidate[export_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "affecting-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shopp_candidate.name = 'df_shopp_candidate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "specialized-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_shopp_candidate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-edition",
   "metadata": {},
   "source": [
    "<a id='Counties'></a>\n",
    "## Counties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "standing-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Counties.xlsx'\n",
    "\n",
    "df_counties = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "virtual-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counties['Co. Name Abbr.'] = df_counties['Co. Name Abbr.'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bigger-termination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 6)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_counties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "informative-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counties.name = 'df_counties'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "spectacular-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_prog_county = df_perf_raw_prog_candidate.merge(df_counties, how = 'left', left_on = 'County', right_on = 'Co. Name Abbr.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "therapeutic-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no need for the following, already added to the df_perf_raw_data\n",
    "\n",
    "# #rename columns\n",
    "# dict_rename_4= {\n",
    "#                'Performance Objective':'Performance Objective Original', \n",
    "#               }\n",
    "\n",
    "# df_perf_raw_prog_county = df_perf_raw_prog_county.rename(dict_rename_4, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-server",
   "metadata": {},
   "source": [
    "<a id='Bridge_Inventory'></a>\n",
    "\n",
    "## Bridge Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "baking-leather",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'GFP_BrInvList_AllDistricts.xlsx'\n",
    "\n",
    "df_bridge_inventory = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename), skiprows = 4, header = [0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "respiratory-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filename = 'GFP_BrInvList_AllDistricts_March_2020_05042020.xlsx'\n",
    "\n",
    "# df_bridge_inventory = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename), skiprows = 4, header = [0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "capital-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_columns = ['Bridge #', 'Deck Area, SF', 'Date', 'Health', 'Deck (58)',\n",
    "       'Super (59)', 'Sub (60)', 'Culv (62)', 'Scour', 'Seismic', 'Overall',\n",
    "       'VC', 'Permit', 'Rail Overall', 'Good, LF', 'Fair, LF', 'Poor, LF',\n",
    "       'Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "refined-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bridge_inventory = df_bridge_inventory[keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "unknown-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns \n",
    "\n",
    "dict_rename_bridge_inventory = {'Bridge #':'BridgeNo',\n",
    "                               'Date':'Inspection Date', \n",
    "                               'Health': 'Bridge Health',\n",
    "                                'Scour':'Bridge Scour', \n",
    "                                'Seismic':'Bridge Seismic', \n",
    "                               'Deck (58)' : 'NBI Condition Ratings_Deck (58)',\n",
    "                                'Super (59)': 'NBI Condition Ratings_Super (59)',\n",
    "                                'Sub (60)':'NBI Condition Ratings_Sub (60)',\n",
    "                                'Culv (62)':'NBI Condition Ratings_Culv (62)',\n",
    "                                'Overall': 'Bridge Goods Movement_Overall',\n",
    "                                'VC': 'Bridge Goods Movement_VC',\n",
    "                                'Permit':'Bridge Goods Movement_Permit',\n",
    "                                'Rail Overall': 'Bridge Rail Upgrade_Rail Overall', \n",
    "                                'Good, LF': 'Bridge Rail Upgrade_Good, LF', \n",
    "                                'Fair, LF': 'Bridge Rail Upgrade_Fair, LF', \n",
    "                                'Poor, LF': 'Bridge Rail Upgrade_Poor, LF', \n",
    "                      }\n",
    "\n",
    "df_bridge_inventory.rename(dict_rename_bridge_inventory, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "neural-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_to_good(value):\n",
    "    if value and value in ['Poor','Fair','Good']:\n",
    "        return value\n",
    "    else:\n",
    "        return 'Good'\n",
    "\n",
    "data_recondition_columns = ['Bridge Health','Bridge Scour','Bridge Seismic','Bridge Goods Movement_Overall',\n",
    "       'Bridge Goods Movement_VC', 'Bridge Goods Movement_Permit','Bridge Rail Upgrade_Rail Overall',]\n",
    "\n",
    "for c in data_recondition_columns:\n",
    "    df_bridge_inventory[c] = df_bridge_inventory[c].apply(default_to_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "descending-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bridge_inventory.name = 'df_bridge_inventory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-dependence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "coated-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bridge_inventory.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-prisoner",
   "metadata": {},
   "source": [
    "<a id='Bridge_Worksheet'></a>\n",
    "\n",
    "## Raw Data Bridge Worksheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "economic-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns \n",
    "#with manual edits\n",
    "\n",
    "dict_rename_bridge_worksheet = {\n",
    " 'ID': 'AMT_ID',\n",
    " 'Bridge №': 'BridgeNo',\n",
    " 'Work Type': 'WorkType',\n",
    " 'Brdige / TunnelWork Description': 'WorkDescription',\n",
    " 'Bridge /TunnelHealth Pre': 'Health Pre',\n",
    " 'Bridge /TunnelHealth Post': 'Health Post',\n",
    " 'BridgeScourPre': 'Scour_Pre',\n",
    " 'BridgeScourPost': 'Scour_Post',\n",
    " 'BridgeSeismicPre': 'Seismic_Pre',\n",
    " 'BridgeSeismicPost': 'Seismic_Post',\n",
    " 'BridgeGds MvmtPre': 'GdsMvmt_Pre',\n",
    " 'BridgeGds MvmtPost': 'GdsMvmt_Post',\n",
    " 'Exist(sf)': 'Deck_Exist(sf)',\n",
    " 'Additional(sf)': 'Deck_Additional(sf)',\n",
    " 'Y/N': 'Paint_Y/N',\n",
    " 'Condition': 'Paint_Condition',\n",
    " 'Paint Area(sf)': 'Paint Area(sf)',\n",
    " 'Y/N.1': 'ElectricalMechanical_Y/N',\n",
    " 'Condition.1': 'ElectricalMechanical_Condition',\n",
    " 'Area(sf)': 'ElectricalMechanical_Area(sf)',\n",
    " 'Y/N.2': 'ApproachSlab_Y/N',\n",
    " 'Replaced(sf)': 'ApproachSlab_Replaced(sf)',\n",
    " 'New(sf)': 'ApproachSlab_New(sf)',\n",
    " 'Y/N.3': 'Rail_Y/N',\n",
    " 'Good(lf)': 'Rail_Good(lf)',\n",
    " 'Fair(lf)': 'Rail_Fair(lf)',\n",
    " 'Poor(lf)': 'Rail_Poor(lf)',\n",
    " 'Additonal(lf)': 'Rail_Additonal(lf)',\n",
    " 'Post Good(lf)': 'Rail_Post Good(lf)',\n",
    " 'Post Fair(lf)': 'Rail_Post Fair(lf)',\n",
    " 'Post Poor(lf)': 'Rail_Post Poor(lf)',\n",
    " 'Post New(lf)': 'Rail_Post New(lf)',\n",
    " 'FishPassage(Y/N)': 'FishPassage(Y/N)',\n",
    "}\n",
    "\n",
    "df_brg_raw_data.rename(dict_rename_bridge_worksheet, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "unlike-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brg_raw_data.name = 'df_brg_raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "correct-tanzania",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_brg_raw_data['Rail_Good(lf)'].fillna(0, inplace = True)\n",
    "df_brg_raw_data['Rail_Fair(lf)'].fillna(0, inplace = True)\n",
    "df_brg_raw_data['Rail_Poor(lf)'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "latin-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brg_raw_data['Rail_Total(lf)'] = (df_brg_raw_data['Rail_Good(lf)'] \n",
    "                                             + df_brg_raw_data[ 'Rail_Fair(lf)'] \n",
    "                                             + df_brg_raw_data['Rail_Poor(lf)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-shipping",
   "metadata": {},
   "source": [
    "<a id='Pavement_Worksheet'></a>\n",
    "\n",
    "## Raw Data Pavement Worksheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "natural-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # df_pav_raw_data['Date'] = TARGETDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "sixth-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns \n",
    "#with manual editing\n",
    "\n",
    "dict_rename_pavement_worksheet = {\n",
    " 'ID': 'AMT_ID',\n",
    " 'Class': 'RoadwayClass',\n",
    " 'Green': 'TriditionalCondition_Green',\n",
    " 'Yellow': 'TriditionalCondition_Yellow',\n",
    " 'Blue': 'TriditionalCondition_Blue',\n",
    " 'Orange': 'TriditionalCondition_Orange',\n",
    " 'Red': 'TriditionalCondition_Red',\n",
    " 'Good': 'MAP21_Good',\n",
    " 'Fair': 'MAP21_Fair',\n",
    " 'Poor': 'MAP21_Poor',\n",
    " 'Total LaneMiles': 'Total LaneMiles',\n",
    " 'Green.1': 'TriditionalCondition_Post_Green',\n",
    " 'Yellow.1': 'TriditionalCondition_Post_Yellow',\n",
    " 'Blue.1': 'TriditionalCondition_Post_Blue',\n",
    " 'Orange.1': 'TriditionalCondition_Post_Orange',\n",
    " 'Red.1': 'TriditionalCondition_Post_Red',\n",
    " 'Good.1': 'MAP21_Post_Good',\n",
    " 'Fair.1': 'MAP21_Post_Fair',\n",
    " 'Poor.1': 'MAP21_Post_Poor',\n",
    "#  'Date': 'Date'\n",
    "                               }\n",
    "df_pav_raw_data.rename(dict_rename_pavement_worksheet, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-potter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ordered-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pav_raw_data.name = 'df_pav_raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "controlling-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pav_raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "collect-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pav_raw_data['Plan Year']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-canvas",
   "metadata": {},
   "source": [
    "<a id='Drainage_Worksheet'></a>\n",
    "## Raw Data Drainage Worksheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "collective-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drain_raw_data.name = 'df_drain_raw_data'\n",
    "\n",
    "dict_drain_rename = {\n",
    " 'ID': 'AMT_ID',\n",
    " 'Data Date':'Data Date_Drainage'\n",
    "                               }\n",
    "df_drain_raw_data.rename(dict_drain_rename, axis = 1, inplace = True)\n",
    "\n",
    "cols = ['EA','EFIS','SYSNO','INETNO','OUTETNO']\n",
    "for c in cols: \n",
    "    df_drain_raw_data[c] = df_drain_raw_data[c].apply(uf.remove_punction)\n",
    "\n",
    "\n",
    "df_drain_raw_data['Data Date_Drainage'] = df_drain_raw_data['Data Date_Drainage'].apply(uf.regulate_timestamp_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "infectious-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#question to be answered: what to do with meanless or null values.\n",
    "#return null if DrainageWorksheet_SYSNO,DrainageWorksheet_INETNO,DrainageWorksheet_OUTETNO are null or empty\n",
    "\n",
    "# df_drain_raw_data['Unique Culvert ID'] = (df_drain_raw_data['SYSNO'] + \"_\"\n",
    "#                                           + df_drain_raw_data['INETNO'] + \"_\"\n",
    "#                                          + df_drain_raw_data['OUTETNO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "located-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_drain_raw_data['SYSNO'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "particular-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_drain_unique_ID(df):\n",
    "    if pd.isnull(df['SYSNO']) or pd.isnull(df['INETNO']) or pd.isnull(df['OUTETNO']):\n",
    "        return None\n",
    "    else:\n",
    "        return (df['SYSNO'] + \"_\"+ df['INETNO'] + \"_\"+ df['OUTETNO'])\n",
    "df_drain_raw_data['Unique Culvert ID'] = df_drain_raw_data.apply(calc_drain_unique_ID, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "liberal-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_drain_raw_data.select_dtypes(include=[object]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "acknowledged-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (columnName, columnData) in df_drain_raw_data.select_dtypes(include=[object]).iteritems():\n",
    "#     df_drain_raw_data[columnName]=columnData.apply(remove_punction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "generous-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_drain_ws = df_drain_raw_data.merge(df_SHOPP_raw_data, how = 'left', \n",
    "#                   left_on = ['AMT_ID', 'Date'], \n",
    "#                   right_on = ['AMT_ID', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-patio",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "virgin-conclusion",
   "metadata": {},
   "source": [
    "<a id='TMS_Worksheet'></a> \n",
    "## Raw Data TMS Worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "happy-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_TMS_rename = {\n",
    " 'ID': 'AMT_ID',\n",
    " 'Data Date':'Data Date_TMS'\n",
    "                               }\n",
    "df_tms_raw_data.rename(dict_TMS_rename, axis = 1, inplace = True)\n",
    "\n",
    "# df_tms_ws = df_tms_raw_data.merge(df_SHOPP_raw_data, how = 'left', \n",
    "#                   left_on = ['AMT_ID', 'Date'], \n",
    "#                   right_on = ['AMT_ID', 'Date'])\n",
    "\n",
    "df_tms_raw_data.name = 'df_tms_raw_data'\n",
    "\n",
    "df_tms_raw_data.shape\n",
    "\n",
    "\n",
    "\n",
    "df_tms_raw_data['Data Date_TMS'] = df_tms_raw_data['Data Date_TMS'].apply(uf.regulate_timestamp_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-processor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "classified-boost",
   "metadata": {},
   "source": [
    "<a id='Postmile_Check'></a>\n",
    "## Postmile Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "adult-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_PM_ck_rename = {\n",
    " 'ID': 'AMT_ID',\n",
    " '№': 'No'                            }\n",
    "df_pm_check.rename(dict_PM_ck_rename, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "alike-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pm_check['District'] = df_pm_check['District'].str.strip(\"'\")\n",
    "df_pm_check['District'] =df_pm_check['District'].astype(int)\n",
    "df_pm_check = df_pm_check[df_pm_check['District']!= 56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "neutral-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pm_check = df_pm_check[df_pm_check['Program'] == 'SHOPP']\n",
    "df_pm_check['AMT_ID'] = df_pm_check['AMT_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "differential-directory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['No', 'District', 'AMT_ID', 'EA', 'EFIS', 'Location', 'Section',\n",
       "       'County', 'Route', 'BackPM', 'AheadPM', 'Alignment', 'Valid PM',\n",
       "       'Activity Category', 'Program', 'BackPMLatitude', 'BackPMLongitude',\n",
       "       'BackPMAssemblyDistrict', 'BackPMCongressDistrict',\n",
       "       'BackPMSenateDistrict', 'AheadPMLatitude', 'AheadPMLongitude',\n",
       "       'AheadPMAssemblyDistrict', 'AheadPMCongressDistrict',\n",
       "       'AheadPMSenateDistrict', 'AssemblyDistrict(s)', 'CongressDistrict(s)',\n",
       "       'SenateDistrict(s)', 'Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pm_check.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "amazing-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pm_check.columns = ['No', 'District', 'AMT_ID', 'EA', 'EFIS', 'Location',\n",
    "#        'Section', 'County', 'Route', 'BackPM', 'AheadPM',\n",
    "#        'Alignment', 'Valid PM', 'Activity Category', 'Program',\n",
    "#        'BackPMLatitude', 'BackPMLongitude',\n",
    "#        'BackPMAssemblyDistrict', 'BackPMCongressDistrict',\n",
    "#        'BackPMSenateDistrict', 'AheadPMLatitude',\n",
    "#        'AheadPMLongitude', 'AheadPMAssemblyDistrict',\n",
    "#        'AheadPMCongressDistrict', 'AheadPMSenateDistrict',\n",
    "#        'AssemblyDistrict(s)', 'CongressDistrict(s)',\n",
    "#        'SenateDistrict(s)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "molecular-passenger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7862, 29)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pm_check.name = 'df_pm_check'\n",
    "df_pm_check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "governing-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dataCheck_perf_loc = df_dataCheckFlow_all_ws.merge(df_pm_check, how = 'outer', \n",
    "#                   left_on = ['AMT_ID','Date'], \n",
    "#                   right_on = ['AMT_ID', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "shared-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dataCheck_perf_loc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "annoying-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dataCheck_perf_loc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-ensemble",
   "metadata": {},
   "source": [
    "<a id='PID_Workload'></a>\n",
    "\n",
    "## 2022 PID workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "interim-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PID_workload = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "turkish-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'PID SHOPP WL.xlsx'\n",
    "shts = ['PID workload', 'ColumnHeaderDictionary']\n",
    "\n",
    "dict_df = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename), sheet_name = shts) \n",
    "\n",
    "df_PID_workload = dict_df['PID workload']\n",
    "df_rename = dict_df['ColumnHeaderDictionary'].iloc[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "robust-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns \n",
    "\n",
    "# dict_rename_PID_workplan = {'SHOPP Tool ID': 'AMT_ID',\n",
    "#                                }\n",
    "\n",
    "dict_col_rename = dict(zip(df_rename.OriginalName, df_rename.NewName))\n",
    "df_PID_workload.rename(dict_col_rename, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "friendly-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PID_workload['District'] = df_PID_workload['District'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "latin-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PID_workload.name = 'df_PID_workload'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "incident-collectible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306, 33)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_PID_workload.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-feelings",
   "metadata": {},
   "source": [
    "<a id='Check_Exceptions'></a>\n",
    "## Check Exceptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "downtown-landscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s151589\\Anaconda3\\envs\\dataprep\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "filename = 'Checks_exception.xlsx'\n",
    "\n",
    "df_ck_exceptions = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "female-extraction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 4)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ck_exceptions.name = 'df_ck_exceptions'\n",
    "df_ck_exceptions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "authentic-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rename_ck_exception = {'Exception ID': 'AMT_ID',\n",
    "                               }\n",
    "df_ck_exceptions.rename(dict_rename_ck_exception, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "invalid-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dataCheckwException = df_dataCheck_PID.merge(df_ck_exceptions, how = 'outer', \n",
    "#                   left_on = ['AMT_ID'], \n",
    "#                   right_on = ['AMT_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "hairy-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_ck_exceptions.shape)\n",
    "# print(df_dataCheckwException.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "presidential-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question\n",
    "#we will not ensure only one entry in the exception\n",
    "#we need to consider all exception\n",
    "#  df_ck_exceptions[(df_ck_exceptions['AMT_ID'] == AMT_ID) & ( df_ck_exceptions['Type of Exception'] =='Repeated Culvert')].shape[0]>0:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-cookie",
   "metadata": {},
   "source": [
    "<a id='Project_Obselete'></a>\n",
    "## Project to be obseleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dependent-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Combined projects.xlsx'\n",
    "\n",
    "df_project_obselete = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "agricultural-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_project_obselete.name = 'df_project_obselete'\n",
    "# df_project_obselete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "medium-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_rename_project_obselete = {'TOOL ID to obsolete': 'AMT_ID to obsolete',\n",
    "                               }\n",
    "df_project_obselete.rename(dict_rename_project_obselete, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "entertaining-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dataCheck_combined =  df_dataCheckwException.merge(df_project_obselete, how = 'left', \n",
    "#                   left_on = ['AMT_ID'], \n",
    "#                   right_on = ['TOOL ID to obsolete'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "killing-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_project_obselete['TOOL ID to obsolete'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-comedy",
   "metadata": {},
   "source": [
    "<a id='Project_Detail_Report'></a>\n",
    "## Project Detail Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "blank-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'project_detail_report_nickname.xlsx'\n",
    "\n",
    "df_project_detail =pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename), sheet_name = 'project_detail_report') \n",
    "\n",
    "\n",
    "\n",
    "# shts = ['project_detail_report','Instruction']\n",
    "\n",
    "# dict_df = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename), sheet_name = shts) \n",
    "\n",
    "# df_project_detail = dict_df['project_detail_report']\n",
    "\n",
    "# datatimestamp = dict_df['Instruction'].iloc[0,0]\n",
    "# df_project_detail['QMRS Report Date'] = datatimestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "conscious-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_cca_date(dt):\n",
    "    if dt == '-':\n",
    "        return np.nan\n",
    "    elif dt < datetime.strptime('01-01-1978', '%M-%d-%Y'):\n",
    "        dt = datetime(dt.year+100, dt.month, dt.day, dt.hour, dt.minute, dt.second, dt.microsecond, dt.tzinfo)\n",
    "    return dt.strftime(\"%m-%d-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "approximate-completion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_project_detail['Cca Finish Date']=df_project_detail['Cca Finish Date'].apply(cleanup_cca_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "extraordinary-triple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN           8663\n",
       "12-31-2021      64\n",
       "11-01-2022      60\n",
       "12-01-2022      59\n",
       "12-01-2023      58\n",
       "              ... \n",
       "02-14-2029       1\n",
       "01-20-2026       1\n",
       "11-09-2016       1\n",
       "07-12-2019       1\n",
       "03-03-2013       1\n",
       "Name: Cca Finish Date, Length: 4295, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_project_detail['Cca Finish Date'].value_counts(dropna =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "theoretical-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_project_detail.name = 'df_project_detail'\n",
    "# df_project_detail.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "demanding-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rename_project_detail = {'Project ID': 'EFIS',\n",
    "                               }\n",
    "df_project_detail.rename(dict_rename_project_detail, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cheap-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dataCheckwNickname = df_dataCheck_combined.merge(df_project_detail, how = 'left', \n",
    "#                   left_on = ['EFIS'], \n",
    "#                   right_on = ['Project ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-authorization",
   "metadata": {},
   "source": [
    "<a id='Programming_Summary'></a>\n",
    "## Programming Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-lighting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "equivalent-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data trimming\n",
    "#row\n",
    "df_program_summary = df_program_summary[df_program_summary['Program'] == 'SHOPP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "handed-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temporary for debug\n",
    "df_program_summary['ID'] = df_program_summary['ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fatty-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rename_program_summary = {'ID': 'AMT_ID',\n",
    "                               }\n",
    "df_program_summary.rename(dict_rename_program_summary, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "advanced-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_program_summary.dropna(subset = ['District'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "russian-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_program_summary['Performance Value'] = df_program_summary['Performance Value'].astype(str)\n",
    "df_program_summary['Performance Value'].fillna('N/A', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "solar-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove leading puncture for all string columns\n",
    "col_strip=['EA', 'EFIS',  'Program Code',]\n",
    "for c in col_strip:\n",
    "    df_program_summary[c] = df_program_summary[c].str.strip(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "actual-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_program_summary['AMT_ID'] = df_program_summary['AMT_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "executed-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_program_summary['Performance Value'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "documentary-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_program_summary['Performance Value'] = df_program_summary['Performance Value'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "grave-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_program_summary.name = 'df_program_summary'\n",
    "# df_program_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-blend",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cultural-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert percentage to actual quantity\n",
    "\n",
    "def percent_to_quantity(df, col, subtotal_col):\n",
    "    if isinstance(df[c], str) and '%' in df[c]:\n",
    "        return (float(df[c].strip('%'))/100) * df[subtotal_col]\n",
    "    else:\n",
    "        return float(df[c])\n",
    "\n",
    "ck_cols = [ 'Pre-Good', 'Pre-Fair', 'Pre-Poor',]\n",
    "\n",
    "for c in ck_cols:\n",
    "    df_program_summary[c] = df_program_summary.apply(percent_to_quantity, args=(c,'Pre-Total'), axis = 1)\n",
    "\n",
    "ck_cols = [ 'Post Good', 'New', 'Post Good+New', 'Post-Fair',\n",
    "       'Post-Poor']\n",
    "\n",
    "for c in ck_cols:\n",
    "    df_program_summary[c] = df_program_summary.apply(percent_to_quantity, args=(c,'Post-Total'), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-defensive",
   "metadata": {},
   "source": [
    "<a id='AddDataColumns'></a>\n",
    "## Calculate and join additional fields\n",
    "\n",
    "- Section\n",
    "- County\n",
    "- Route\n",
    "- End Postmile\n",
    "- Begin Postmile\n",
    "\n",
    "\n",
    "* Advertised Year\n",
    "* Last Year FY POR\n",
    "* Last Year of Fiscal Year\n",
    "* Will this project be included in the Project Book?\n",
    "* AM Tool RTL (Section in Use)\n",
    "* FY\n",
    "* Activity (group)\n",
    "\n",
    "* Total Project Cost ($K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "linear-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SHOPP_raw_data['EA_'] = df_SHOPP_raw_data['EA'].apply(lambda x: \"'\" + x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-affect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "favorite-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'FY','Total Capital & Support Cost' to raw data\n",
    "df_SHOPP_raw_data.drop(columns =['EFIS_Program','FY','Total Capital & Support Cost','Capital Cost', 'Support Cost'], inplace=True, errors = 'ignore')\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, df_program[['EFIS_Program','FY','Total Capital & Support Cost','Capital Cost', 'Support Cost' ]], \n",
    "                             how = 'left', left_on = 'EFIS', right_on='EFIS_Program')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-salmon",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "stunning-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_and_convert_FY(FY):\n",
    "    #get the last two number of FY string and convert to 4 digit FY value, \n",
    "    #for na value, fill 0\n",
    "    if FY is np.nan:\n",
    "        return 0\n",
    "#     elif int(FY[-2:]) == 0:\n",
    "#         return 0\n",
    "    else:\n",
    "        return int(FY[-2:])+2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "aggressive-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SHOPP_raw_data['Target RTL FY Number'] = df_SHOPP_raw_data['Target RTL FY'].apply(calc_and_convert_FY)\n",
    "\n",
    "df_SHOPP_raw_data['Requested RTL FY Number'] = df_SHOPP_raw_data['Requested RTL FY'].apply(calc_and_convert_FY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "raised-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data['Target RTL FY Number'].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "tough-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this logic needs to consider the programming list\n",
    "df_SHOPP_raw_data['Section'] = df_SHOPP_raw_data.apply(uf.cal_section_in_use, axis=1)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fancy-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reconcile: \n",
    "# AMT_ID = 16813\n",
    "# df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] == AMT_ID][['AMT_ID','Section',\n",
    "# 'CCA Date Miilestone (M600)' ,'PCR SHOPP Amendment Date' ,\n",
    "# 'SHOPP Amendment Date' ,'EFIS_Program' ,'Long Lead' ,\n",
    "\n",
    "# 'Resourced In PID WP' ,'Requested RTL FY' ,'Dist Dir Appr','PID Uploaded' ,\n",
    "# 'LL RTL FY PRG' ,\n",
    "\n",
    "# ] ]#needs to be TYP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-diabetes",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "secret-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SHOPP_raw_data['County'] = df_SHOPP_raw_data.apply(uf.county_to_use, axis=1)\n",
    "# df_SHOPP_raw_data['County'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "reserved-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_SHOPP_raw_data['Route'] = df_SHOPP_raw_data.apply(uf.route_to_use, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "auburn-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_SHOPP_raw_data['Begin Postmile'] = df_SHOPP_raw_data.apply(uf.beginPM_to_use, axis=1)\n",
    "df_SHOPP_raw_data['End Postmile'] = df_SHOPP_raw_data.apply(uf.endPM_to_use, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "outdoor-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_SHOPP_raw_data['Unique EA'] = df_SHOPP_raw_data.apply(uf.calc_unique_EA, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "gross-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_SHOPP_raw_data['Activity (group)'] = df_SHOPP_raw_data['Activity'].apply(uf.calc_activity_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "figured-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_SHOPP_raw_data['Activity Book'] = df_SHOPP_raw_data['Activity'].apply(uf.calc_activity_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "enclosed-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_SHOPP_raw_data['AM Tool RTL (Section in Use)'] = df_SHOPP_raw_data.apply(uf.calc_SIU_RTL, axis=1)\n",
    "\n",
    "df_SHOPP_raw_data['AM Tool RTL (Section in Use)'].fillna('00', inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-actress",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "local-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_SHOPP_raw_data['Advertised Year'] = df_SHOPP_raw_data.apply(\n",
    "    lambda x: x['AM Tool RTL (Section in Use)'] if pd.isnull(x['FY']) else x['FY'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "grand-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data[['AM Tool RTL (Section in Use)','FY','Advertised Year','Last Year of Fiscal Year', 'PID Cycle']].head()\n",
    "# 'Last Year of FY POR', 'Plan Year','RTL Plan Year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "sixth-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Last Year of Fiscal Year\n",
    "\n",
    "# cal ='''\n",
    "# FLOAT(Right([Advertised Year],2))\n",
    "# '''\n",
    "\n",
    "df_SHOPP_raw_data['Last Year of Fiscal Year'] = df_SHOPP_raw_data['Advertised Year'].str[-2:].astype(int)+2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "chemical-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data[df_SHOPP_raw_data['Last Year of Fiscal Year'] != df_SHOPP_raw_data['Last Year FY POR'] ][['AMT_ID','Last Year of Fiscal Year','Last Year FY POR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "adaptive-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] == 11296][]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "excessive-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Last Year FY POR\n",
    "\n",
    "# cal ='''\n",
    "# FLOAT(Right([AM Tool RTL (Section in Use)],2))\n",
    "# '''\n",
    "\n",
    "df_SHOPP_raw_data['Last Year FY POR'] = df_SHOPP_raw_data['AM Tool RTL (Section in Use)'].str[-2:].astype(int)+2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "attached-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data['Last Year FY POR'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-nightlife",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "automated-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Planning or Post-Planning\n",
    "\n",
    "\n",
    "# cal ='''\n",
    "# IF(isnull([EFIS Programmed Projects]) and isnull([SHOPP Amendment Date])) Then \"Planning\"\n",
    "# ELSE \"Post-Planning\"\n",
    "# END\n",
    "# '''\n",
    "\n",
    "#Loren: is it possible logic does not compare well between different sources? Currently EFIS is converted as integer.\n",
    "\n",
    "df_SHOPP_raw_data['Planning or Post-Planning'] = df_SHOPP_raw_data.apply(lambda x: \n",
    "                                                                         'Planning' if (pd.isnull(x['EFIS_Program']) and pd.isnull(x['SHOPP Amendment Date']))\n",
    "                                                                         else 'Post-Planning'\n",
    "                                                                        , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "familiar-familiar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EFIS</th>\n",
       "      <th>EFIS_Program</th>\n",
       "      <th>SHOPP Amendment Date</th>\n",
       "      <th>Section</th>\n",
       "      <th>Planning or Post-Planning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4758</th>\n",
       "      <td>421000191.0</td>\n",
       "      <td>421000191.0</td>\n",
       "      <td>08/18/21</td>\n",
       "      <td>PRG</td>\n",
       "      <td>Post-Planning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             EFIS  EFIS_Program SHOPP Amendment Date Section  \\\n",
       "4758  421000191.0   421000191.0             08/18/21     PRG   \n",
       "\n",
       "     Planning or Post-Planning  \n",
       "4758             Post-Planning  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID']==22875][['EFIS','EFIS_Program','SHOPP Amendment Date','Section','Planning or Post-Planning']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "civic-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data['Planning or Post-Planning'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "historical-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ck_missing_data_columns = ['Section','Unique EA',\n",
    "#                            'AM Tool RTL (Section in Use)',\n",
    "#                            'Advertised Year','Last Year FY POR',\n",
    "#                            'Planning or Post-Planning',\n",
    "#                           ]\n",
    "\n",
    "# for c in ck_missing_data_columns:\n",
    "#     if df_SHOPP_raw_data[c].isna().any():\n",
    "#         print('Missing information for: {}'.format(c))\n",
    "# print('all columns checked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "naughty-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data['Requested RTL FY'] =  df_SHOPP_raw_data['Requested RTL FY'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-piano",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "jewish-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SB-1 Priority\n",
    "\n",
    "# IF([Activity (group)]=\"SB-1\") Then \"Yes\"\n",
    "# Else \" \"\n",
    "# END\n",
    "\n",
    "\n",
    "df_SHOPP_raw_data['SB-1 Priority'] = df_SHOPP_raw_data['Activity'].apply(uf.calc_SB1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-batch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "pressed-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long Lead?\n",
    "\n",
    "# cal = '''\n",
    "# If([Last Year of Fiscal Year]>24 and [Long Lead]=\"Y\") THEN \"Yes\" Else \"No\"\n",
    "# END\n",
    "# '''\n",
    "\n",
    "def verify_longlead(df):\n",
    "    if df['Last Year of Fiscal Year'] > TARGET_FY + 5 and df['Long Lead'] == \"Y\": \n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return 'No'\n",
    "\n",
    "df_SHOPP_raw_data['Active Long Lead']= df_SHOPP_raw_data.apply(verify_longlead, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "posted-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df_SHOPP_raw_data['Target RTL FY'].str[-2:].astype(str)\n",
    "\n",
    "# df_SHOPP_raw_data['Requested RTL FY'].value_counts(dropna = False)\n",
    "\n",
    "df_SHOPP_raw_data['PA&ED FY Number'] = df_SHOPP_raw_data.apply(uf.calc_PAED_FY, axis = 1).astype(int)\n",
    "\n",
    "# df_SHOPP_raw_data[df_SHOPP_raw_data['Target RTL FY'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "impressive-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "reflected-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data=df_SHOPP_raw_data_copy\n",
    "\n",
    "# df_SHOPP_raw_data_copy = df_SHOPP_raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "plastic-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_include_5year_POR(df):\n",
    "    if df['Ten-Year Plan RD'] == 9999:\n",
    "        return  'No'\n",
    "    elif(df['Last Year FY POR']>TARGET_FY and df['Last Year FY POR']<TARGET_FY + 6) :   \n",
    "        if df['Activity (group)'] == 'Reservation' and pd.isnull(df['SHOPP Amendment Date']): \n",
    "            return  'Yes' \n",
    "        else: \n",
    "            return 'No' \n",
    "    elif (df['Last Year FY POR']>TARGET_FY + 5 and df['Last Year FY POR']<TARGET_FY + 11) : \n",
    "        if(df['Long Lead'] == \"Y\") and (df['Section'] == \"PRG\")  :\n",
    "             return  'Yes'\n",
    "        elif pd.isnull(df['SHOPP Amendment Date']): \n",
    "             return  'Yes' \n",
    "        else: \n",
    "            return 'No' \n",
    "    else: \n",
    "        return 'No'\n",
    "\n",
    "df_SHOPP_raw_data['Include 5-year POR?'] = df_SHOPP_raw_data.apply(calc_include_5year_POR, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-carrier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "final-finance",
   "metadata": {},
   "source": [
    "<a id='DataJoining'></a>\n",
    "## Data Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "accessible-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add performance entry counts to raw data \n",
    "#Done: count unique location based on column 'Location'\n",
    "temp = df_perf_raw_data.groupby(['AMT_ID','Section'])['Location'].nunique().reset_index(name = 'perf_entry_count')\n",
    "\n",
    "df_SHOPP_raw_data.drop(columns=['perf_entry_count'],inplace=True , errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp, how = 'left', \n",
    "                  left_on = ['AMT_ID','Section'], \n",
    "                  right_on = ['AMT_ID','Section'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "liable-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add Candidate Type to raw data \n",
    "\n",
    "df_SHOPP_raw_data.drop(columns=['Candidate Type', 'Advertised Year_Candidate','Project Cost ($K)_Candidate'],inplace=True , errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, df_shopp_candidate[['AMT_ID','Candidate Type', 'Advertised Year_Candidate','Project Cost ($K)_Candidate']], \n",
    "                             how = 'left', left_on = 'AMT_ID', right_on='AMT_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "musical-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add MPO/RTPA to raw data \n",
    "\n",
    "df_SHOPP_raw_data.drop(columns=['MPO/RTPA','County Name',],inplace=True , errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, df_counties[['Co. Name Abbr.','County Name','MPO/RTPA']].drop_duplicates(), \n",
    "                             how = 'left', left_on = 'County', right_on='Co. Name Abbr.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "contemporary-sympathy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find number of drainage worksheet entries for each project\n",
    "temp = df_drain_raw_data.groupby(['AMT_ID','Section'])['AMT_ID'].count().reset_index(name = 'No of Drainage Entries')\n",
    "\n",
    "df_SHOPP_raw_data.drop(columns=['No of Drainage Entries'],inplace=True , errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp, how = 'left', \n",
    "                  left_on = ['AMT_ID','Section'], \n",
    "                  right_on = ['AMT_ID','Section'])\n",
    "\n",
    "df_SHOPP_raw_data['No of Drainage Entries'].fillna(0, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-cyprus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "suitable-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data['drainage_in_performance'] = df_perf_raw_data['Performance Objective'].str[:20] == 'Drainage Restoration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "hairy-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_perf_raw_data.groupby(['AMT_ID','Section'])['drainage_in_performance'].agg(max).reset_index()\n",
    "\n",
    "df_SHOPP_raw_data.drop(columns=['drainage_in_performance'],inplace=True , errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp[['AMT_ID','Section','drainage_in_performance']], how = 'left', \n",
    "                  left_on = ['AMT_ID','Section'], \n",
    "                  right_on = ['AMT_ID','Section'])\n",
    "\n",
    "df_SHOPP_raw_data['drainage_in_performance'].fillna(False, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bearing-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data[(df_perf_raw_data['AMT_ID'] == 9000) & (df_perf_raw_data['Section'] == 'PPC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "stuck-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-programming",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "homeless-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add drainage cleaned dates\n",
    "temp = df_drain_raw_data[~df_drain_raw_data['Cleaned date'].isna()]\n",
    "# temp['Cleaned date'] = temp['Cleaned date'].apply(lambda x: x.strftime(\"%m-%d-%Y\"))\n",
    "\n",
    "temp_group = temp.groupby(['AMT_ID','Section',])['Cleaned date'].agg(set).reset_index(name = 'Cleaned Dates')\n",
    "\n",
    "df_SHOPP_raw_data.drop(columns=['Cleaned Dates'],inplace=True , errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp_group[['AMT_ID','Section','Cleaned Dates']], \n",
    "                             how = 'left', \n",
    "                  left_on = ['AMT_ID','Section'], \n",
    "                  right_on = ['AMT_ID','Section'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-classroom",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "adaptive-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if performance objective has pavement\n",
    "\n",
    "temp = df_perf_raw_data[df_perf_raw_data['Performance Objective'].str[:8] == \"Pavement\"].groupby(['AMT_ID','Section']).first().reset_index()\n",
    "\n",
    "temp['Performance Objective has Pavement'] = 'Yes'\n",
    "\n",
    "df_SHOPP_raw_data.drop(columns=['Performance Objective has Pavement'],inplace=True , errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp[['AMT_ID','Section','Performance Objective has Pavement']], \n",
    "                             how= 'left', left_on = ['AMT_ID', 'Section'], right_on = ['AMT_ID','Section'])\n",
    "\n",
    "df_SHOPP_raw_data['Performance Objective has Pavement'].fillna('No', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "directed-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data[df_perf_raw_data['Performance Objective'].str[:8] == \"Pavement\"].groupby(['AMT_ID','Section']).agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "functional-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if performance objective has TMS\n",
    "\n",
    "temp =df_perf_raw_data[df_perf_raw_data['Performance Objective'].isin([\"Transportation Management Systems\", 'Transportation Management System Structures'])].groupby(['AMT_ID','Section']).first().reset_index()\n",
    "\n",
    "temp['Performance Objective has TMS'] = 'Yes'\n",
    "\n",
    "df_SHOPP_raw_data.drop(columns =['Performance Objective has TMS'],inplace=True, errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp[['AMT_ID','Section','Performance Objective has TMS']], \n",
    "                             how= 'left', left_on = ['AMT_ID', 'Section'], right_on = ['AMT_ID','Section'])\n",
    "\n",
    "df_SHOPP_raw_data['Performance Objective has TMS'].fillna('No', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "resistant-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add pavement plan year to df_SHOPP_raw_data\n",
    "\n",
    "temp =df_pav_raw_data.groupby(['AMT_ID','Section',])['Plan Year'].agg(Pavement_PlanYear='first', No_Pavement_PlanYear='nunique').reset_index()\n",
    "df_SHOPP_raw_data.drop(columns=['Pavement_PlanYear', 'No_Pavement_PlanYear'], inplace=True, errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp, how= 'left', \n",
    "                             left_on = ['AMT_ID', 'Section'], right_on = ['AMT_ID','Section'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "subject-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp =df_pav_raw_data.groupby(['AMT_ID','Section',])['Plan Year'].agg(Pavement_PlanYears=set, No_Pavement_PlanYear='nunique').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "august-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp[temp['No_Pavement_PlanYear']> 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-writer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "equivalent-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #add pavement plan year to df_SHOPP_raw_data\n",
    "\n",
    "\n",
    "# temp =df_pav_raw_data.groupby(['AMT_ID','Section',])['Plan Year'].agg(Pavement_PlanYears=set, No_Pavement_PlanYear='nunique').reset_index()\n",
    "# df_SHOPP_raw_data.drop(columns=['Pavement_PlanYears', 'No_Pavement_PlanYear'], inplace=True, errors='ignore')\n",
    "\n",
    "# df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp, how= 'left', \n",
    "#                              left_on = ['AMT_ID', 'Section'], right_on = ['AMT_ID','Section'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "chief-helping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Program', 'District', 'AMT_ID', 'County-Route-PM', 'Section',\n",
       "       'Plan Year', 'District.1', 'County', 'Route', 'RS', 'BPP', 'Beg PM',\n",
       "       'BPS', 'EPP', 'End PM', 'EPS', 'Direction', 'Lane', 'Treatment',\n",
       "       'ActID', 'RoadwayClass', 'TriditionalCondition_Green',\n",
       "       'TriditionalCondition_Yellow', 'TriditionalCondition_Blue',\n",
       "       'TriditionalCondition_Orange', 'TriditionalCondition_Red', 'MAP21_Good',\n",
       "       'MAP21_Fair', 'MAP21_Poor', 'Total LaneMiles', 'SHOPPEffectiveness %',\n",
       "       'RehabEffectiveness %', 'MAP-21Effective-ness %', 'PCRScenarioNo',\n",
       "       'District's Notes', 'Last Saved', 'Saved by', 'Data Year', 'Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pav_raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "tight-clear",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s151589\\Anaconda3\\envs\\dataprep\\lib\\site-packages\\pandas\\core\\series.py:4460: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n"
     ]
    }
   ],
   "source": [
    "# add pavement direction check to df_SHOPP_raw_data\n",
    "temp = df_pav_raw_data[df_pav_raw_data['Direction'].isna()]\n",
    "#Question do you mean to catch the project with pavement direction missing? data missing in the original dataset. \n",
    "# Left     1451\n",
    "# Right    1428\n",
    "# NaN        49\n",
    "\n",
    "temp['Direction'].fillna('Direction Info Missing', inplace= True) \n",
    "temp = temp.groupby(['AMT_ID', 'Section'])['Direction'].first().reset_index()\n",
    "temp.columns = ['AMT_ID', 'Section','Direction_check']\n",
    "df_SHOPP_raw_data.drop(columns=['Direction_check'],inplace=True , errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp[['AMT_ID', 'Section','Direction_check']], \n",
    "                             how= 'left', left_on = ['AMT_ID','Section'], right_on = ['AMT_ID', 'Section'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "banned-developer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to get all scenarios of the pavement, how to deal with nan values\n",
    "# skip check for nan data of PCR Scenario\n",
    "df_pav_raw_data['PCRScenarioNo'] = df_pav_raw_data['PCRScenarioNo'].astype(str)\n",
    "temp = df_pav_raw_data[df_pav_raw_data['PCRScenarioNo']!= 'nan'].groupby(['AMT_ID', 'Section'])['PCRScenarioNo'].agg(first_PCRScenarioNo='first', count_PCRScenarioNo='nunique').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "former-locator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>first_PCRScenarioNo</th>\n",
       "      <th>count_PCRScenarioNo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>15879</td>\n",
       "      <td>PPC</td>\n",
       "      <td>2671 ( PCR Scenario 2671 Mod #D02R01Y2020 )</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>16476</td>\n",
       "      <td>PPC</td>\n",
       "      <td>3096</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>18329</td>\n",
       "      <td>PPC</td>\n",
       "      <td>2671</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>18329</td>\n",
       "      <td>PRG</td>\n",
       "      <td>2671</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>18437</td>\n",
       "      <td>TYP</td>\n",
       "      <td>3299</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>20054</td>\n",
       "      <td>TYP</td>\n",
       "      <td>3299</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>21441</td>\n",
       "      <td>TYP</td>\n",
       "      <td>3299</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AMT_ID Section                          first_PCRScenarioNo  \\\n",
       "66    15879     PPC  2671 ( PCR Scenario 2671 Mod #D02R01Y2020 )   \n",
       "110   16476     PPC                                         3096   \n",
       "205   18329     PPC                                         2671   \n",
       "206   18329     PRG                                         2671   \n",
       "214   18437     TYP                                         3299   \n",
       "490   20054     TYP                                         3299   \n",
       "688   21441     TYP                                         3299   \n",
       "\n",
       "     count_PCRScenarioNo  \n",
       "66                     2  \n",
       "110                    2  \n",
       "205                    2  \n",
       "206                    2  \n",
       "214                    2  \n",
       "490                    2  \n",
       "688                    2  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp['PCRScenarioNos'] = temp['PCRScenarioNo'].apply(','.join)\n",
    "# temp['PCRScenarioNo_len'] = temp['PCRScenarioNo'].apply(len)\n",
    "temp[temp['count_PCRScenarioNo']> 1]\n",
    "# df_SHOPP_raw_data.drop(columns=['PCRScenarioNo'],inplace=True , errors='ignore')\n",
    "\n",
    "# df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp[['AMT_ID', 'Section','PCRScenarioNo']], \n",
    "#                              how= 'left', left_on = ['AMT_ID','Section'], right_on = ['AMT_ID', 'Section'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "advised-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = df_pav_raw_data.groupby(['AMT_ID', 'Section'])['PCRScenarioNo'].first().reset_index()\n",
    "\n",
    "# df_SHOPP_raw_data.drop(columns=['PCRScenarioNo'],inplace=True , errors='ignore')\n",
    "\n",
    "# df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp[['AMT_ID', 'Section','PCRScenarioNo']], \n",
    "#                              how= 'left', left_on = ['AMT_ID','Section'], right_on = ['AMT_ID', 'Section'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "alternative-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SHOPP_raw_data.drop(columns=['first_PCRScenarioNo','count_PCRScenarioNo'],inplace=True , errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp[['AMT_ID', 'Section','first_PCRScenarioNo','count_PCRScenarioNo']], \n",
    "                             how= 'left', left_on = ['AMT_ID','Section'], right_on = ['AMT_ID', 'Section'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-samoa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-burton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "shaped-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data date for TMS is unique for each project and section. no need to check all \n",
    "temp =df_tms_raw_data.groupby(['AMT_ID','Section',])['Data Date_TMS'].first().reset_index()\n",
    "\n",
    "df_SHOPP_raw_data.drop(columns=['Data Date_TMS'],inplace=True , errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp[['AMT_ID', 'Section','Data Date_TMS']], \n",
    "                             how= 'left', left_on = ['AMT_ID','Section'], right_on = ['AMT_ID', 'Section'])\n",
    "\n",
    "# 'Data Date_Drainage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "roman-thing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data date for drainage is unique for each project and section. no need to check al\n",
    "\n",
    "temp =df_drain_raw_data.groupby(['AMT_ID','Section',])['Data Date_Drainage'].first().reset_index()\n",
    "\n",
    "df_SHOPP_raw_data.drop(columns=['Data Date_Drainage'],inplace=True , errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp[['AMT_ID', 'Section','Data Date_Drainage']], \n",
    "                             how= 'left', left_on = ['AMT_ID','Section'], right_on = ['AMT_ID', 'Section'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-coordinate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "textile-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "satisfactory-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SHOPP_raw_data.drop(columns =['Cca Finish Date', 'Cca Percent Comp'],inplace=True, errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, df_project_detail[['EFIS','Cca Finish Date', 'Cca Percent Comp']], \n",
    "                             how= 'left', left_on = ['EFIS'], right_on = ['EFIS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "informal-skill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5204, 143)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "preliminary-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp = df_perf_raw_data[(df_perf_raw_data['ActID'] == 'H32') & (~df_perf_raw_data['Quantity'].isna())].groupby(['AMT_ID', 'Section']).first().reset_index()\n",
    "\n",
    "def ck_ActID_H32(df):\n",
    "    if (df['ActID'] == 'H32' and pd.notnull(df['Quantity'])):\n",
    "        return 'OK'\n",
    "    else:\n",
    "        return 'NG'\n",
    "\n",
    "temp['ck_ActID_H32'] = temp.apply(ck_ActID_H32, axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #debug: there are multiple activities for each projec tand section. Needs to create a list or a concat string before join with SHOPP raw data\n",
    "\n",
    "df_SHOPP_raw_data.drop(columns =['ck_ActID_H32'],inplace=True, errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp[['AMT_ID','Section','ck_ActID_H32']], \n",
    "                             how= 'left', left_on = ['AMT_ID', 'Section'], right_on = ['AMT_ID','Section'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "cardiovascular-warrior",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5204, 144)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "smooth-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add TMS plan year to df_SHOPP_raw_data\n",
    "\n",
    "temp =df_tms_raw_data.groupby(['AMT_ID','Section',])['RTL Plan Year'].agg(TMS_PlanYear='first', No_TMS_PlanYear='nunique').reset_index()\n",
    "\n",
    "df_SHOPP_raw_data.drop(columns=['TMS_PlanYear', 'No_TMS_PlanYear'],inplace=True , errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp, how= 'left', \n",
    "                             left_on = ['AMT_ID', 'Section'], right_on = ['AMT_ID','Section'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "decreased-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add columns from df_PID_workload\n",
    "df_SHOPP_raw_data.drop(columns=['PID Status'],inplace=True , errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, df_PID_workload[['AMT_ID','PID Status']], \n",
    "                             how = 'left', left_on = 'AMT_ID', right_on='AMT_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "filled-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add Valid PM to df_SHOPP_raw_data\n",
    "\n",
    "#question to be answered: please confirm: confirmed by manpaul and loren\n",
    "# the Section information is missing for any location other than \"Primary Location\",which cause original logic to skip this row\n",
    "# '''The logic is updated such that it will check the PM for entire project, regardless of the section. If any invalid PM exists in a project, it will be flagged.'''\n",
    "\n",
    "temp =df_pm_check.groupby(['AMT_ID'])['Valid PM'].agg(list).reset_index()\n",
    "temp['PM_Check'] = temp['Valid PM'].apply(lambda x: \"Has Invalid PM\" if 'No' in x else 'OK')\n",
    "\n",
    "df_SHOPP_raw_data.drop(['PM_Check'], axis=1, errors='ignore')\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp[['AMT_ID','PM_Check']], \n",
    "                                            how = 'left',\n",
    "                                            left_on = ['AMT_ID'],\n",
    "                                            right_on = ['AMT_ID'])\n",
    "df_SHOPP_raw_data['PM_Check'].fillna('OK', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "meaningful-homework",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OK                4830\n",
       "Has Invalid PM     374\n",
       "Name: PM_Check, dtype: int64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data['PM_Check'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-arthur",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-perspective",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "underlying-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add obsolete project\n",
    "\n",
    "temp =df_project_obselete.groupby(['AMT_ID to obsolete']).first().reset_index()\n",
    "df_SHOPP_raw_data.drop(['AMT_ID to obsolete'], axis=1, errors='ignore')\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp[['AMT_ID to obsolete']], \n",
    "                how = 'left', left_on = 'AMT_ID', right_on = 'AMT_ID to obsolete')\n",
    "\n",
    "df_SHOPP_raw_data['AMT_ID to obsolete'] = df_SHOPP_raw_data['AMT_ID to obsolete'].apply(lambda x: 'Not Obselete' if pd.isnull(x) else 'Obselete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "final-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a column of program_summary_performance_value_sum\n",
    "\n",
    "temp = df_program_summary.groupby(['AMT_ID','Section',])['Performance Value'].sum().reset_index()\n",
    "dict_rename = {'Performance Value':'Performance Value Sum'}\n",
    "temp = temp.rename(dict_rename, axis = 1)\n",
    "\n",
    "\n",
    "#delete column 'Performance Value Sum' if exists\n",
    "# add 'Performance Value Sum' to raw data via merge\n",
    "\n",
    "df_SHOPP_raw_data.drop(columns =['Performance Value Sum'],inplace=True, errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp[['AMT_ID','Section','Performance Value Sum']], \n",
    "                             how= 'left', left_on = ['AMT_ID', 'Section'], right_on = ['AMT_ID', 'Section'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "optional-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add exception type to each project \n",
    "\n",
    "#question to be answered, should we maintain max one exception for each project entry\n",
    "#This logic extend the type of exception strings\n",
    "temp = df_ck_exceptions.groupby(['AMT_ID'])['Type of Exception'].apply(','.join).reset_index()\n",
    "\n",
    "df_SHOPP_raw_data.drop(columns =['Type of Exception'],inplace=True, errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp[['AMT_ID','Type of Exception']], \n",
    "                             how= 'left', left_on = ['AMT_ID'], right_on = ['AMT_ID'])\n",
    "\n",
    "df_SHOPP_raw_data['Type of Exception'].fillna('No Related Exception', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "friendly-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add 'Nickname' into df_SHOPP_raw_data\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, df_project_detail[['EFIS','Nickname']], how ='left', left_on = 'EFIS', right_on = 'EFIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-cooper",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "pressed-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_SHOPP_raw_data['Shopp Tool Cost to use'] = df_SHOPP_raw_data.apply(uf.calc_SHOPP_tool_cost, axis = 1)\n",
    "\n",
    "# df_SHOPP_raw_data[df_SHOPP_raw_data['Shopp Tool Cost to use'].isna()]\n",
    "\n",
    "df_SHOPP_raw_data['Shopp Tool Cost to use'].fillna(0, inplace= True)\n",
    "\n",
    "#Question: how to handle this 7 null values \n",
    "#mara: fill null with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "lucky-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_SHOPP_raw_data['Total Project Cost ($K)'] = df_SHOPP_raw_data.apply(uf.calc_total_project_cost, axis = 1)\n",
    "\n",
    "# df_SHOPP_raw_data['Total Project Cost ($K)'].isna().any()\n",
    "df_SHOPP_raw_data['Total Project Cost ($K)'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "peaceful-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project Cost ($K)\n",
    "\n",
    "\n",
    "# cal ='''\n",
    "# {Fixed [SHOPP ID], [EFIS ],[Date], [Advertised Year], [District]:Max([Total Project Cost ($K)])}\n",
    "# '''\n",
    "\n",
    "#Question: I do not understand this logic, why group SHOPP ID,  EFIS, Advertised Year and District, why get the max\n",
    "#Mara: just get the Total Project Cost ($K) for each SHOPP ID\n",
    "\n",
    "df_SHOPP_raw_data['Project Cost ($K)'] = df_SHOPP_raw_data['Total Project Cost ($K)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "premier-decimal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>EFIS</th>\n",
       "      <th>EFIS_Program</th>\n",
       "      <th>Shopp Tool Cost to use</th>\n",
       "      <th>Long Lead</th>\n",
       "      <th>Total Project Cost ($K)</th>\n",
       "      <th>TYP Total Project Cost ($K)</th>\n",
       "      <th>LL PAED Cost ($K)</th>\n",
       "      <th>Project Cost ($K)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>22171</td>\n",
       "      <td>CCA</td>\n",
       "      <td>419000284.0</td>\n",
       "      <td>419000284.0</td>\n",
       "      <td>4670.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>4670.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3350.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section         EFIS  EFIS_Program  Shopp Tool Cost to use  \\\n",
       "4184   22171     CCA  419000284.0   419000284.0                  4670.0   \n",
       "\n",
       "     Long Lead  Total Project Cost ($K)  TYP Total Project Cost ($K)  \\\n",
       "4184       NaN                   3350.0                       4670.0   \n",
       "\n",
       "      LL PAED Cost ($K)  Project Cost ($K)  \n",
       "4184                0.0             3350.0  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reconcile: the total project cost can not be nan \n",
    "\n",
    "\n",
    "AMT_ID= 22171\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] == AMT_ID][['AMT_ID','Section','EFIS','EFIS_Program','Shopp Tool Cost to use',\n",
    "                                                          'Long Lead','Total Project Cost ($K)','TYP Total Project Cost ($K)','LL PAED Cost ($K)','Project Cost ($K)']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fallen-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12+ np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "developmental-entertainment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dist</th>\n",
       "      <th>County</th>\n",
       "      <th>Route</th>\n",
       "      <th>Post Miles</th>\n",
       "      <th>Location/Description</th>\n",
       "      <th>EA</th>\n",
       "      <th>PPNO</th>\n",
       "      <th>EFIS_Program</th>\n",
       "      <th>Prog Code</th>\n",
       "      <th>FY</th>\n",
       "      <th>FUNDID</th>\n",
       "      <th>RW</th>\n",
       "      <th>Con</th>\n",
       "      <th>PA&amp;ED</th>\n",
       "      <th>PS&amp;E</th>\n",
       "      <th>RW Sup</th>\n",
       "      <th>Con Sup</th>\n",
       "      <th>Total Capital &amp; Support Cost</th>\n",
       "      <th>Performance Value</th>\n",
       "      <th>Performance Measure</th>\n",
       "      <th>Table Names</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "      <th>Programming Pre-Good</th>\n",
       "      <th>Programming Pre-Fair</th>\n",
       "      <th>Programming Pre-Poor</th>\n",
       "      <th>Programming Pre-Qty</th>\n",
       "      <th>Programming Post_Good</th>\n",
       "      <th>Programming Post_Fair</th>\n",
       "      <th>Programming Post_Poor</th>\n",
       "      <th>Programming Post_Qty</th>\n",
       "      <th>Programming Unit</th>\n",
       "      <th>Support Cost</th>\n",
       "      <th>Capital Cost</th>\n",
       "      <th>Begin Post Miles</th>\n",
       "      <th>End Post Miles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>3</td>\n",
       "      <td>Sacramento</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In Placer, Sacramento, and Yolo Counties, on r...</td>\n",
       "      <td>2H57U</td>\n",
       "      <td>6717A</td>\n",
       "      <td>319000045</td>\n",
       "      <td>201.315</td>\n",
       "      <td>2018/19</td>\n",
       "      <td>NH</td>\n",
       "      <td>30</td>\n",
       "      <td>2325</td>\n",
       "      <td>242.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>872</td>\n",
       "      <td>3973</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Field element(s)</td>\n",
       "      <td>2018 SHOPP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>2355</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dist      County Route Post Miles  \\\n",
       "810     3  Sacramento     5        NaN   \n",
       "\n",
       "                                  Location/Description     EA   PPNO  \\\n",
       "810  In Placer, Sacramento, and Yolo Counties, on r...  2H57U  6717A   \n",
       "\n",
       "     EFIS_Program  Prog Code       FY FUNDID  RW   Con  PA&ED   PS&E  RW Sup  \\\n",
       "810     319000045    201.315  2018/19     NH  30  2325  242.0  460.0    44.0   \n",
       "\n",
       "     Con Sup  Total Capital & Support Cost  Performance Value  \\\n",
       "810      872                          3973               38.0   \n",
       "\n",
       "    Performance Measure Table Names  Unnamed: 24  Programming Pre-Good  \\\n",
       "810    Field element(s)  2018 SHOPP          NaN                   NaN   \n",
       "\n",
       "     Programming Pre-Fair  Programming Pre-Poor  Programming Pre-Qty  \\\n",
       "810                   NaN                   NaN                  NaN   \n",
       "\n",
       "     Programming Post_Good  Programming Post_Fair  Programming Post_Poor  \\\n",
       "810                    NaN                    NaN                    NaN   \n",
       "\n",
       "     Programming Post_Qty Programming Unit  Support Cost  Capital Cost  \\\n",
       "810                   NaN              NaN        1618.0          2355   \n",
       "\n",
       "    Begin Post Miles End Post Miles  \n",
       "810              nan            NaN  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_program[df_program['EFIS_Program'] == 319000045]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "exciting-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-chambers",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-hunger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "individual-water",
   "metadata": {},
   "source": [
    "<a id='Issue_Table1'></a>\n",
    "# Issue Table 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-crash",
   "metadata": {},
   "source": [
    "<a id='Will_this_project_be_included_in_the_Project_Book'></a> \n",
    "### Will this project be included in the Project Book?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "northern-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will this project be included in the Project Book?\n",
    "\n",
    "# cal ='''\n",
    "# IF(Isnull([EFIS Programmed Projects]))Then \n",
    "#     If [Ten-Year Plan RD]=9999 Then 'No'\n",
    "#     ELSEIF (Isnull([2020 Candidates])) Then\n",
    "#         If ([Last Year FY POR]>19 and [Last Year FY POR]<25) Then \n",
    "#             If(([Activity (group)]='Reservation') and (Isnull([SHOPP Amendment Date]))) Then 'Yes' \n",
    "#             Else 'No' \n",
    "#             End\n",
    "#         ElseIF ([Last Year FY POR]>24 and [Last Year FY POR]<30) Then\n",
    "#             ( IF([Long Lead]=\"Y\") Then   'Yes'\n",
    "#               ELSEIf((Isnull([SHOPP Amendment Date]) )) Then 'Yes' \n",
    "#               Else 'No' \n",
    "#               End)\n",
    "#         Else 'No'\n",
    "#         End\n",
    "#     Else \"Yes\"\n",
    "#     END\n",
    "# Elseif ([Last Year of Fiscal Year]=0) Then'Yes'\n",
    "# Elseif ([Last Year of Fiscal Year]<20) Then\"No\"\n",
    "# Else 'Yes'\n",
    "# END\n",
    "# '''\n",
    "\n",
    "#Question: Should use hard coded FY limit or use FY offset from current FY\n",
    "#Mara: to confirm\n",
    "def ck_include_in_projectbook(df):\n",
    "    \n",
    "    if pd.isnull(df['EFIS_Program']): #it is not programmed project\n",
    "        if df['Ten-Year Plan RD']==9999:\n",
    "            return 'No'\n",
    "        elif not pd.isnull(df['Candidate Type']): \n",
    "            return 'Yes'\n",
    "        else:\n",
    "            if (df['Last Year FY POR']>(TARGET_FY) and df['Last Year FY POR']<(TARGET_FY + 6)): \n",
    "                if ((df['Activity (group)']=='Reservation') and (pd.isnull(df['SHOPP Amendment Date']))):\n",
    "                    return 'Yes'\n",
    "                else:\n",
    "                    return 'No'\n",
    "            elif  (df['Last Year FY POR']>(TARGET_FY + 5) and df['Last Year FY POR']<(TARGET_FY + 11)):\n",
    "                if df['Long Lead'] == 'Y':\n",
    "                    return 'Yes'\n",
    "                elif pd.isnull(df['SHOPP Amendment Date']):\n",
    "                    return 'Yes'\n",
    "                else:\n",
    "                    return 'No'\n",
    "            else:\n",
    "                return 'No'\n",
    "    elif df['Last Year of Fiscal Year'] == 0: #information missing, 0 used to fill space\n",
    "        return 'Yes'\n",
    "    elif df['Last Year of Fiscal Year'] < TARGET_FY + 1:\n",
    "        return 'No'\n",
    "    else:\n",
    "        return 'Yes'\n",
    "\n",
    "\n",
    "df_SHOPP_raw_data['Will this project be included in the Project Book?'] = df_SHOPP_raw_data.apply(ck_include_in_projectbook, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "passing-german",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>EFIS</th>\n",
       "      <th>EFIS_Program</th>\n",
       "      <th>Ten-Year Plan RD</th>\n",
       "      <th>Section</th>\n",
       "      <th>PCR SHOPP Amendment Date</th>\n",
       "      <th>Requested RTL FY</th>\n",
       "      <th>PCR RTL</th>\n",
       "      <th>AM Tool RTL (Section in Use)</th>\n",
       "      <th>Last Year FY POR</th>\n",
       "      <th>Last Year of Fiscal Year</th>\n",
       "      <th>Activity (group)</th>\n",
       "      <th>SHOPP Amendment Date</th>\n",
       "      <th>Long Lead</th>\n",
       "      <th>Will this project be included in the Project Book?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [AMT_ID, EFIS, EFIS_Program, Ten-Year Plan RD, Section, PCR SHOPP Amendment Date, Requested RTL FY, PCR RTL, AM Tool RTL (Section in Use), Last Year FY POR, Last Year of Fiscal Year, Activity (group), SHOPP Amendment Date, Long Lead, Will this project be included in the Project Book?]\n",
       "Index: []"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ####Manual Check#####\n",
    "\n",
    "AMT_ID= 23064\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] == AMT_ID][['AMT_ID','EFIS','EFIS_Program', 'Ten-Year Plan RD',\n",
    "                                                           'Section','PCR SHOPP Amendment Date','Requested RTL FY','PCR RTL',\n",
    "                                                           'AM Tool RTL (Section in Use)',\n",
    "                                                          'Last Year FY POR',\n",
    "                                                          'Last Year of Fiscal Year',\n",
    "                                                          'Activity (group)',\n",
    "                                                          'SHOPP Amendment Date',\n",
    "                                                          'Long Lead','Will this project be included in the Project Book?']]\n",
    "\n",
    "# df_program[df_program['EFIS'] ==  317000065.0]\n",
    "\n",
    "# ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "endangered-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data['Will this project be included in the Project Book?'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-welding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "educational-spelling",
   "metadata": {},
   "source": [
    "<a id='Does_project_cost_exceed_Minor_Program_limits'></a>\n",
    "### Does project cost exceed Minor Program limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "saving-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does project cost exceed Minor Program limits ($1,250K)?\n",
    "\n",
    "# cal ='''\n",
    "# IF([Planning or Post-Planning]=\"Post-Planning\") Then \"OK\"\n",
    "# ELSEIF([Activity]= \"Relinquishment\") Then \"OK\"\n",
    "# ELSEIF([Activity (group)]=\"Reservation\") Then \n",
    "#     (IF [Project Cost ($K)]>333 Then \"OK\" \n",
    "#     Else 'Please review project cost, it is below Minor Program limits' \n",
    "#     End)\n",
    "# ELSEIF[Project Cost ($K)]>1250 Then \"OK\" \n",
    "# Else 'Please review project cost, it is below Minor Program limits' \n",
    "# END\n",
    "# '''\n",
    "\n",
    "def ck_minor_program_limit(df):\n",
    "    \n",
    "    if df['Ten-Year Plan RD']==9999:\n",
    "        return 'OK'\n",
    "    else:\n",
    "        if(df['Planning or Post-Planning']==\"Post-Planning\"):\n",
    "            return \"OK\"\n",
    "        elif (df['Activity']== \"Relinquishment\"):\n",
    "            return \"OK\"\n",
    "        elif(df['Activity (group)']==\"Reservation\"):\n",
    "            if df['Project Cost ($K)']>333:\n",
    "                return \"OK\" \n",
    "            else:\n",
    "                return 'The reservation project cost (${:.0f}k) is less than Minor Program minimum limits (${}k). AMT_ID: {}'.format(df['Project Cost ($K)'],df['Section'], 333, df['AMT_ID']) \n",
    "        elif df['Project Cost ($K)']>1250:\n",
    "            return \"OK\" \n",
    "        else:\n",
    "            return 'The project cost (${:.0f}k) in the {} section is less than Minor Program minimum limits (${}k). AMT_ID: {}'.format(df['Project Cost ($K)'],df['Section'], 1250, df['AMT_ID']) \n",
    "#             return 'For {} section in project {}: Please review project cost. The cost (${:.0f}k) is less than Minor Program minimum limits  (${}k).'.format(df['Section'],df['AMT_ID'],df['Project Cost ($K)'], 1250) \n",
    "\n",
    "df_SHOPP_raw_data['Does project cost exceed Minor Program limits ($1,250K)?'] = df_SHOPP_raw_data.apply(ck_minor_program_limit, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "phantom-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data['Does project cost exceed Minor Program limits ($1,250K)?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-peace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ranking-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####Manual Check#####\n",
    "\n",
    "# AMT_ID = 19612\n",
    "\n",
    "\n",
    "\n",
    "# df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] == AMT_ID][['AMT_ID','Planning or Post-Planning','Activity','Activity (group)',\n",
    "#                                                             'Project Cost ($K)','Total Project Cost ($K)',\n",
    "#                                                            'Does project cost exceed Minor Program limits ($1,250K)?']]\n",
    "\n",
    "# ############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-elevation",
   "metadata": {},
   "source": [
    "<a id='Is_Major_Damage_or_Mobility_Subcategory_Identified'></a>\n",
    "\n",
    "### Is Major Damage or Mobility Subcategory Identified (Obsoleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "secret-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is Major Damage or Mobility Subcategory Identified?\n",
    "\n",
    "\n",
    "# cal ='''\n",
    "# If([Activity]=\"Mobility\" or [Activity]=\"Major Damage\") Then \"Please identify Major Damage or Mobility Sub-Category\"\n",
    "# Else \"OK\"\n",
    "# END\n",
    "# '''\n",
    "\n",
    "\n",
    "def ck_mobility_major_damange(df):\n",
    "    if df['Activity'] == 'Mobility' or df['Activity'] == 'Major Damage':\n",
    "        return 'For {} section in project {}: Please identify Major Damage or Mobility Sub-Category. The current activity is {}.'.format(df['Section'],df['AMT_ID'],df['Activity'])\n",
    "    else:\n",
    "        return 'OK'\n",
    "\n",
    "df_SHOPP_raw_data['Is Major Damage or Mobility Subcategory Identified?'] = df_SHOPP_raw_data.apply(ck_mobility_major_damange, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "inappropriate-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data['Is Major Damage or Mobility Subcategory Identified?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "dependent-chorus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>22053</td>\n",
       "      <td>Sustainability/Climate Change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID                       Activity\n",
       "4079   22053  Sustainability/Climate Change"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ####Manual Check#####\n",
    "\n",
    "AMT_ID = 22053  \n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] == AMT_ID][['AMT_ID' ,'Activity',]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-bulgaria",
   "metadata": {},
   "source": [
    "<a id='Is_Planned_Project_RTL_in_a_FY_that_can_be_programmed_in_future_SHOPP_cycles'></a>\n",
    "\n",
    "### Is Planned Project RTL in a FY that can be programmed in future SHOPP cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "cellular-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is Planned Project RTL in a FY that can be programmed in future SHOPP cycles?\n",
    "\n",
    "# cal ='''\n",
    "#     IF ([Activity (group)]=\"Reservation\") then \n",
    "#         (IF ([Planning or Post-Planning]=\"Planning\" \n",
    "#             and ISNULL([SHOPP Amendment Date])\n",
    "#             and [Last Year of Fiscal Year]<21) Then \n",
    "#             \"Please review. RTL inconsistent with project status. Project should be programmed or RTL should be 2019/20 or later\" \n",
    "#         Else \"OK\" \n",
    "#         END)\n",
    "#     ELSEIF ([Planning or Post-Planning]=\"Post-Planning\") Then \"OK\"\n",
    "#     Elseif ([Last Year of Fiscal Year]>24)Then \"OK\" \n",
    "#     Elseif(ISnull([2020 Candidates])) Then \"Please review Projected RTL, only planned reservation projects may have a RTL prior to 2024/25\"\n",
    "#     Else \"OK\"\n",
    "#     END\n",
    "# '''\n",
    "\n",
    "\n",
    "def ck_project_programmability(df):\n",
    "    # question to be answered: manpaul: if there is a DDA date, then the project is programmed (post-planning)\n",
    "    # manpaul: if the request RTL FY < 25 and missing  'SHOPP Amendment Date', flag the project\n",
    "    if df['Ten-Year Plan RD']==9999:\n",
    "          return 'OK'\n",
    "    else:\n",
    "        if (df['Activity (group)'] == \"Reservation\"): \n",
    "            if (df['Planning or Post-Planning'] == \"Planning\" \n",
    "                and pd.isnull(df['SHOPP Amendment Date'])\n",
    "                and df['Last Year of Fiscal Year']< CURRENT_FY) : \n",
    "                return \"For {} section in project {}: Please review. RTL inconsistent with project status. For this {} Project, it is not programmed and RTL ({}) is not the current FY ({}) or later\".format(df['Section'],df['AMT_ID'],df['Last Year of Fiscal Year'], df['Activity (group)'], CURRENT_FY) \n",
    "            else: \n",
    "                return \"OK\" \n",
    "        elif  (df['Planning or Post-Planning'] == \"Post-Planning\") : \n",
    "            return \"OK\"\n",
    "        elif  (df['Last Year of Fiscal Year']> TARGET_FY + 5): \n",
    "            return \"OK\" \n",
    "        elif pd.isnull(df['Candidate Type']) or pd.isnull(df['SHOPP Amendment Date']):\n",
    "            return \"For {} section in project {}: Please review Projected RTL. This project is a {} project, which is not a reservation project. It is not programmed and the last year of fiscal year is {}, which not later than {}.\".format(df['Section'],df['AMT_ID'],df['Activity (group)'],df['Last Year of Fiscal Year'], df['Last Year of Fiscal Year']+ 5 )  \n",
    "        else: \n",
    "            return \"OK\"\n",
    "\n",
    "df_SHOPP_raw_data['Is Planned Project RTL in a FY that can be programmed in future SHOPP cycles?'] = df_SHOPP_raw_data.apply(ck_project_programmability, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "flush-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data['Is Planned Project RTL in a FY that can be programmed in future SHOPP cycles?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-committee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-forward",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "taken-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####Manual Check#####\n",
    "\n",
    "# AMT_ID = 22053  #this should be flagged, but not flagged since it is in 'post planning'\n",
    "# # AMT_ID = 14153 #a complicated project with combine action, might require different logic\n",
    "\n",
    "# df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] == AMT_ID][['AMT_ID' ,'EFIS',\n",
    "# 'Candidate Type' ,\n",
    "# 'Activity (group)' ,\n",
    "# 'Planning or Post-Planning' ,\n",
    "# 'SHOPP Amendment Date' ,\n",
    "# 'Last Year of Fiscal Year' ,\n",
    "# 'Is Planned Project RTL in a FY that can be programmed in future SHOPP cycles?' ,]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-impossible",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-timeline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-minneapolis",
   "metadata": {},
   "source": [
    "<a id='Is_the_PID_cycle_consistent_with_the_project_status_and_RTL'></a>\n",
    "\n",
    "### Is the PID cycle consistent with the project status and RTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "employed-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is the PID cycle consistent with the project status and RTL?\n",
    "\n",
    "# cal ='''\n",
    "# IF ([Planning or Post-Planning]=\"Post-Planning\") Then \"OK\"\n",
    "#     ElseIf([Activity (group)]=\"Reservation\") Then \"OK\"\n",
    "#     Elseif [Long Lead]=\"Y\" Then \"OK\"\n",
    "#     ELSEIF  (([Last Year of Fiscal Year]=([PID Cycle]-2000+3) or[Last Year of Fiscal Year]=([PID Cycle]-2000+4))) Then \"OK\"\n",
    "#          Else \"Please review PID cycle according to RTL year\"\n",
    "# END\n",
    "# '''\n",
    "\n",
    "ck_name = 'Is the PID cycle consistent with the project status and RTL?'\n",
    "def ck_PID_cycle(df):\n",
    "    if df['Ten-Year Plan RD']==9999:\n",
    "        return 'OK'\n",
    "    else:\n",
    "        if (df['Planning or Post-Planning'] == \"Post-Planning\") : \n",
    "            return \"OK\"\n",
    "        elif (df['Activity (group)'] == \"Reservation\") : \n",
    "            return \"OK\"\n",
    "        elif  df['Long Lead'] == \"Y\" : \n",
    "            return \"OK\"\n",
    "\n",
    "        elif pd.isnull(df['PID Cycle']): \n",
    "            return 'The PID Cycle year is missing or needs to be updated to correspond to the project RTL year. AMT_ID: {}'.format(df['AMT_ID'])\n",
    "\n",
    "        elif  ((df['Last Year of Fiscal Year'] == (df['PID Cycle']+3) \n",
    "                or df['Last Year of Fiscal Year'] == (df['PID Cycle']+4))) : \n",
    "            return \"OK\"\n",
    "        else: \n",
    "            return 'Please review PID cycle according to RTL year. This project is not programmed. It is not a Reservation project nor a long lead. The Last Year of Fiscal Year is {}, which is not consistant with the PID cycle year ({:.0f}). AMT_ID: {}'.format(df['Last Year of Fiscal Year'], df['PID Cycle'],df['AMT_ID'])\n",
    "\n",
    "        \n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_PID_cycle, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-easter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "patient-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####Manual Check#####\n",
    "\n",
    "# AMT_ID = 22053  #this project should be flagged, but it is designated as 'post planning'\n",
    "# # 13330\n",
    "# # 17498\n",
    "# # 18156\n",
    "\n",
    "\n",
    "# df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] == AMT_ID][['AMT_ID','EFIS','SHOPP Amendment Date','Requested SHOPP Cycle','PID Cycle',\n",
    "# 'Activity (group)' ,\n",
    "# 'Planning or Post-Planning' ,\n",
    "# 'Long Lead' ,\n",
    "# 'Last Year of Fiscal Year' ,'Is the PID cycle consistent with the project status and RTL?' ,]]\n",
    "\n",
    "# ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-restoration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-grant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "inner-church",
   "metadata": {},
   "source": [
    "<a id='Is_PIP_uploaded_(Active_and_Complete_PIDs)'></a>\n",
    "\n",
    "### Is PIP uploaded (Active and Complete PIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "suitable-conducting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is PIP uploaded (Active and Complete PIDs)?\n",
    "\n",
    "\n",
    "# cal ='''\n",
    "# If(Isnull([2020 Candidates])) Then \"OK\"\n",
    "# ELSeIf([PID Status]=\"Active\" or [PID Status]=\"Completed\" and isnull([PIP Uploaded])) Then \n",
    "#     If isnull([PID Uploaded]) then \"PIP needs to be uploaded\" \n",
    "#     Else \"OK\" \n",
    "#     END\n",
    "# Else \"OK\"\n",
    "# End\n",
    "# '''\n",
    "\n",
    "ck_name = 'Is Project Initiation Proposal (PIP) uploaded? Applies to projects with Active and  Complete PIDs.'\n",
    "\n",
    "def ck_PIP_uploaded(df):\n",
    "    \n",
    "    if pd.notnull(df['Candidate Type']): #it is on the candidate list, skip check\n",
    "        return \"OK\"\n",
    "    elif df['PID Status'] == \"Active\" or df['PID Status'] == \"Completed\": \n",
    "        if pd.isnull(df['PID Uploaded']) and pd.isnull(df['PIP Uploaded']) : \n",
    "            return 'Please upload a PIP or PID document. AMT_ID: {}'.format(df['AMT_ID'])\n",
    "        else: \n",
    "            return \"OK\" \n",
    "    else: \n",
    "        return \"OK\"\n",
    "\n",
    "\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_PIP_uploaded, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "union-vision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OK                                                    5202\n",
       "Please upload a PIP or PID document. AMT_ID: 22927       1\n",
       "Please upload a PIP or PID document. AMT_ID: 23281       1\n",
       "Name: Is Project Initiation Proposal (PIP) uploaded? Applies to projects with Active and  Complete PIDs., dtype: int64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data[ck_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "becoming-client",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>EFIS</th>\n",
       "      <th>SHOPP Amendment Date</th>\n",
       "      <th>Requested SHOPP Cycle</th>\n",
       "      <th>PID Cycle</th>\n",
       "      <th>PID Uploaded</th>\n",
       "      <th>PIP Uploaded</th>\n",
       "      <th>PID Status</th>\n",
       "      <th>Candidate Type</th>\n",
       "      <th>Planning or Post-Planning</th>\n",
       "      <th>Long Lead</th>\n",
       "      <th>Last Year of Fiscal Year</th>\n",
       "      <th>Is Project Initiation Proposal (PIP) uploaded? Applies to projects with Active and  Complete PIDs.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>18990</td>\n",
       "      <td>419000234.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>Active</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Planning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID         EFIS SHOPP Amendment Date  Requested SHOPP Cycle  \\\n",
       "2009   18990  419000234.0                  NaN                    NaN   \n",
       "\n",
       "      PID Cycle PID Uploaded PIP Uploaded PID Status Candidate Type  \\\n",
       "2009     2022.0          NaN            Y     Active            NaN   \n",
       "\n",
       "     Planning or Post-Planning Long Lead  Last Year of Fiscal Year  \\\n",
       "2009                  Planning       NaN                      2024   \n",
       "\n",
       "     Is Project Initiation Proposal (PIP) uploaded? Applies to projects with Active and  Complete PIDs.  \n",
       "2009                                                 OK                                                  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####Manual Check#####\n",
    "\n",
    "AMT_ID = 18990\n",
    "\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] == AMT_ID][['AMT_ID','EFIS','SHOPP Amendment Date',\n",
    "                                                          'Requested SHOPP Cycle','PID Cycle',\n",
    "'PID Uploaded','PIP Uploaded','PID Status','Candidate Type',\n",
    "'Planning or Post-Planning' ,\n",
    "'Long Lead' ,\n",
    "'Last Year of Fiscal Year' ,ck_name,]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "alpine-syndication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Y'], dtype=object)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data['PID Uploaded'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "chinese-yukon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Y'], dtype=object)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data['PIP Uploaded'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-southwest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "economic-regression",
   "metadata": {},
   "source": [
    "<a id='Is_District_Director_Approval_Date_in_the_Future'></a>\n",
    "\n",
    "### Is District Director Approval Date in the Future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ahead-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is District Director Approval Date in the Future?\n",
    "\n",
    "# cal ='''\n",
    "# If(DATE([Dist Dir Appr])>Date([Date])) Then \"Date needs to be removed or corrected to actual PID signature date\"\n",
    "# Else \"OK\"\n",
    "# END\n",
    "# '''\n",
    "\n",
    "\n",
    "# question to be answered: there are 2053 projects without DDA date, how to handle missing information\n",
    "\n",
    "def ck_director_approal_date(df):\n",
    "    \n",
    "    if pd.isnull(df['Dist Dir Appr']):\n",
    "        return 'OK'\n",
    "    elif(datetime.strptime(df['Dist Dir Appr'], '%m/%d/%y') > datetime.strptime(TARGETDATE, \"%m-%d-%Y\")): \n",
    "        return 'This project has a future District Director Approval Date ({}) that needs to be removed or corrected. AMT_ID: {}'.format(df['Dist Dir Appr'],df['AMT_ID'])\n",
    "    else: \n",
    "        return \"OK\"\n",
    "\n",
    "df_SHOPP_raw_data['Is District Director Approval Date in the Future?'] = df_SHOPP_raw_data.apply(ck_director_approal_date, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "completed-lancaster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OK    5204\n",
       "Name: Is District Director Approval Date in the Future?, dtype: int64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data['Is District Director Approval Date in the Future?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-vanilla",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "strange-grain",
   "metadata": {},
   "source": [
    "<a id='Is_the_EA_or_Project_ID_repeated_in_the_AM_tool'></a>\n",
    "\n",
    "### Is the EA or Project ID repeated in the AM tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "sharp-stadium",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is the EA or Project ID repeated in the AM tool?\n",
    "\n",
    "\n",
    "#mara: if EA or EFIS is null, does not check it for duplication\n",
    "#mara: for this check, we need to for all SHOPP, Minor and HM, ?where is the dataset\n",
    "\n",
    "# cal ='''\n",
    "# If [Count Unique EFIS]>1 or [Count Unique EA]>1 then \"More than one record in the AM tool has the same EA or same Project ID. Please review.\"\n",
    "# Else \"OK\"\n",
    "# END\n",
    "# '''\n",
    "\n",
    "\n",
    "\n",
    "#how to deal with the HM and Minor bad data quality (EFIS is not numeric)\n",
    "\n",
    "\n",
    "\n",
    "# df_SHOPP_raw_data['Is the EA or Project ID repeated in the AM tool?'] = (((df_SHOPP_raw_data['Unique EA']!='') & (df_SHOPP_raw_data['Unique EA'].duplicated())) \n",
    "#                                                                          | ((~df_SHOPP_raw_data['EFIS'].isna()) & (df_SHOPP_raw_data['EFIS'].duplicated())))\n",
    "\n",
    "# df_SHOPP_raw_data['Is the EA or Project ID repeated in the AM tool?'] = df_SHOPP_raw_data['Is the EA or Project ID repeated in the AM tool?'].apply(lambda x: \"More than one record in the AM tool has the same EA or same Project ID. Please review.\" if x else \"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-expert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-marina",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-account",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "dying-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# skip the check if the EA or EFIS ID is missing\n",
    "\n",
    "df_Minor_raw_data_filtered = df_Minor_raw_data[(df_Minor_raw_data['Status'].isna()) \n",
    "#                                             &(df_Minor_raw_data['EA'] != 'TBD') \n",
    "                                               &(df_Minor_raw_data['EA'] != '')\n",
    "#                                             & (df_Minor_raw_data['EFIS'] != 0)                                              \n",
    "                                            ][['Unique EA','EA','EFIS','AMT_ID','District',]]\n",
    "\n",
    "df_HM_raw_data_filtered = df_HM_raw_data[(df_HM_raw_data['Status'].isna())\n",
    "#                                       &(df_HM_raw_data['EA'] != 'TBD')  \n",
    "                                         &(df_HM_raw_data['EA'] != '') \n",
    "#                                             & (df_HM_raw_data['EFIS'] !='0000000000') \n",
    "#                                             & (df_HM_raw_data['EFIS'] !='TBD0000000')    \n",
    "                                      ][['Unique EA','EFIS','AMT_ID','District',]]\n",
    "\n",
    "df_SHOPP_raw_data_filtered = df_SHOPP_raw_data[df_SHOPP_raw_data['Unique EA'] != ''][['Unique EA','EFIS','AMT_ID','District',]]\n",
    "df_SHOPP_HM_MB = df_SHOPP_raw_data_filtered[['Unique EA','EFIS','AMT_ID','District',]].append(df_Minor_raw_data_filtered, ignore_index=True) \n",
    "df_SHOPP_HM_MB = df_SHOPP_HM_MB.append(df_HM_raw_data_filtered, ignore_index=True) \n",
    "\n",
    "# temp['EFIS'] = temp['EFIS'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "fuzzy-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "duplicate_EA = df_SHOPP_HM_MB.groupby(['Unique EA'])['AMT_ID'].agg(list).reset_index(name = 'AMT_ID List_repeated Unique EA')\n",
    "duplicate_EA['Count_Repeated Unique EA'] = duplicate_EA['AMT_ID List_repeated Unique EA'].apply(lambda x: len(x))\n",
    "duplicate_EA = duplicate_EA[(duplicate_EA['Unique EA'].str.len() > 6) & (duplicate_EA['Count_Repeated Unique EA'] > 1)]\n",
    "\n",
    "duplicate_EA['AMT_ID List_repeated Unique EA'] = duplicate_EA['AMT_ID List_repeated Unique EA'].apply(lambda x: ';'.join(map(str, x)))\n",
    "# duplicate_EA.columns = ['Unique EA','AMT_ID List_repeated UniqueEA'] \n",
    "# duplicate_EA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-ability",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "dirty-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_EFIS = df_SHOPP_HM_MB.groupby('EFIS')['AMT_ID'].agg(list).reset_index(name = 'AMT_ID List_repeated EFIS')\n",
    "duplicate_EFIS['Count_Repeated EFIS'] = duplicate_EFIS['AMT_ID List_repeated EFIS'].apply(lambda x: len(x))\n",
    "duplicate_EFIS = duplicate_EFIS[(duplicate_EFIS['EFIS'] != '') & (duplicate_EFIS['Count_Repeated EFIS'] > 1)]\n",
    "# duplicate_EFIS.columns = ['EFIS','AMT_ID List_repeated EFIS'] \n",
    "duplicate_EFIS['AMT_ID List_repeated EFIS']=duplicate_EFIS['AMT_ID List_repeated EFIS'].apply(lambda x: ';'.join(map(str, x)))\n",
    "# duplicate_EFIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "potential-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SHOPP_raw_data.drop(['Count_Repeated Unique EA','AMT_ID List_repeated Unique EA','Count_Repeated EFIS','AMT_ID List_repeated EFIS'], errors = 'ignore')\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, duplicate_EA, how ='left', left_on = 'Unique EA', right_on ='Unique EA' )\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, duplicate_EFIS, how ='left', left_on = 'EFIS', right_on ='EFIS' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "official-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ck_duplicate_EA_EFIS(df):\n",
    "    if pd.isnull(df['Count_Repeated Unique EA']) and pd.isnull(df['Count_Repeated EFIS']):\n",
    "        return 'OK'\n",
    "    elif (\"Repeated EA\" in df['Type of Exception']) or (\"Repeated EFIS\" in df['Type of Exception']): \n",
    "        return 'OK'\n",
    "    else:\n",
    "        comments = '''For {} section in project {}: More than one record in the AM tool has the same EA and/or same Project ID.'''.format(df['Section'],df['AMT_ID'],)\n",
    "        if df['Count_Repeated Unique EA'] > 1: \n",
    "            comments = comments + ' The IDs with repeated EA ({}) are: {}.'.format(df['Unique EA'], duplicate_EA[duplicate_EA['Unique EA'] == df['Unique EA']]['AMT_ID List_repeated Unique EA'].iloc[0])\n",
    "        \n",
    "        if df['Count_Repeated EFIS']> 1: \n",
    "            comments = comments + ' The IDs with repeated EFIS ({}) are: {}.'.format(df['EFIS'], duplicate_EFIS[duplicate_EFIS['EFIS'] ==df['EFIS']]['AMT_ID List_repeated EFIS'].iloc[0])\n",
    "\n",
    "        return comments\n",
    "#         return 'More than one record in the AM tool has the same EA or same Project ID. Please review.'\n",
    "\n",
    "ck_name = 'Is the EA or Project ID repeated in the AM tool?'\n",
    "\n",
    "df_SHOPP_raw_data[ck_name] =df_SHOPP_raw_data.apply(ck_duplicate_EA_EFIS, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "previous-humidity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OK                                                                                                                                                                                                                               5198\n",
       "For TYP section in project 22266: More than one record in the AM tool has the same EA and/or same Project ID. The IDs with repeated EFIS (1000000047.0) are: 22266;23364.                                                           1\n",
       "For TYP section in project 23345: More than one record in the AM tool has the same EA and/or same Project ID. The IDs with repeated EA (3_2J860) are: 23313;23345. The IDs with repeated EFIS (322000116.0) are: 23313;23345.       1\n",
       "For TYP section in project 23364: More than one record in the AM tool has the same EA and/or same Project ID. The IDs with repeated EFIS (1000000047.0) are: 22266;23364.                                                           1\n",
       "For TYP section in project 23313: More than one record in the AM tool has the same EA and/or same Project ID. The IDs with repeated EA (3_2J860) are: 23313;23345. The IDs with repeated EFIS (322000116.0) are: 23313;23345.       1\n",
       "For PRG section in project 22936: More than one record in the AM tool has the same EA and/or same Project ID. The IDs with repeated EFIS (421000352.0) are: 22936;22945.                                                            1\n",
       "For PRG section in project 22945: More than one record in the AM tool has the same EA and/or same Project ID. The IDs with repeated EFIS (421000352.0) are: 22936;22945.                                                            1\n",
       "Name: Is the EA or Project ID repeated in the AM tool?, dtype: int64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data[ck_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "featured-morning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>EA</th>\n",
       "      <th>EFIS</th>\n",
       "      <th>Unique EA</th>\n",
       "      <th>Count_Repeated Unique EA</th>\n",
       "      <th>Count_Repeated EFIS</th>\n",
       "      <th>Is the EA or Project ID repeated in the AM tool?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>22934</td>\n",
       "      <td>3W750</td>\n",
       "      <td>422000032.0</td>\n",
       "      <td>4_3W750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID     EA         EFIS Unique EA  Count_Repeated Unique EA  \\\n",
       "4814   22934  3W750  422000032.0   4_3W750                       NaN   \n",
       "\n",
       "      Count_Repeated EFIS Is the EA or Project ID repeated in the AM tool?  \n",
       "4814                  NaN                                               OK  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Manual Check#####\n",
    "\n",
    "#reconcile: for 22934, the duplicated EA or EFIS should not be flagged since it is in expcetion.\n",
    "\n",
    "AMT_ID = 22934\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] == AMT_ID][['AMT_ID','EA','EFIS','Unique EA','Count_Repeated Unique EA','Count_Repeated EFIS','Is the EA or Project ID repeated in the AM tool?']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-swing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-funds",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fitted-swing",
   "metadata": {},
   "source": [
    "<a id='Does_project_include_performance_related_to_each_location'></a>\n",
    "\n",
    "### Does project include performance related to each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "compact-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does project include performance related to each location?\n",
    "\n",
    "\n",
    "# cal ='''\n",
    "# If([Will this project be included in the Project Book?]=\"Yes\" and [Multiple Loc]=\"Y\") Then\n",
    "#     IF([Count Location Performance Raw Data]=[Loc Count]) Then \"OK\"\n",
    "#     Else \"Detail the performance for each location listed in the performance tab.\"\n",
    "#     End\n",
    "# Else \"OK\"\n",
    "# END\n",
    "# '''\n",
    "\n",
    "def ck_multiple_location_performance(df):\n",
    "    if(df['Will this project be included in the Project Book?']==\"Yes\" and df['Multiple Loc'] == \"Yes\"):\n",
    "        if df['perf_entry_count'] == df['Loc Count'] : \n",
    "            return \"OK\"\n",
    "        else: \n",
    "            return 'Please update the Performance Tab corresponding to each project location limit to report at least one activity for each of the {} location(s). AMT_ID: {}'.format(df['perf_entry_count'],df['AMT_ID'])\n",
    "        \n",
    "    else: \n",
    "        return \"OK\"\n",
    "ck_name = 'Does project include performance for each location?'\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_multiple_location_performance, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "through-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data[ck_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "beautiful-fever",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>EA</th>\n",
       "      <th>EFIS</th>\n",
       "      <th>Section</th>\n",
       "      <th>Multiple Loc</th>\n",
       "      <th>perf_entry_count</th>\n",
       "      <th>Loc Count</th>\n",
       "      <th>Does project include performance for each location?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>11289</td>\n",
       "      <td>30160</td>\n",
       "      <td>714000024.0</td>\n",
       "      <td>PRG</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Please update the Performance Tab correspondin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AMT_ID     EA         EFIS Section Multiple Loc  perf_entry_count  \\\n",
       "159   11289  30160  714000024.0     PRG          Yes               1.0   \n",
       "\n",
       "     Loc Count Does project include performance for each location?  \n",
       "159          3  Please update the Performance Tab correspondin...   "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Manual Check#####\n",
    "\n",
    "AMT_ID = 11289\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] == AMT_ID][['AMT_ID','EA','EFIS','Section','Multiple Loc','perf_entry_count','Loc Count',\n",
    "                                                          ck_name,\n",
    "                                                          ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "pediatric-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data[(df_perf_raw_data['AMT_ID'] == AMT_ID) & (df_perf_raw_data['Section'] ==STU)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-train",
   "metadata": {},
   "source": [
    "<a id='Is_Performance_tab_Complete'></a>\n",
    "\n",
    "### Is Performance tab Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "clear-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is Performance tab Complete?\n",
    "\n",
    "\n",
    "# cal ='''\n",
    "# If [Ten-Year Plan RD]=9999 then \"OK\"\n",
    "# ElseIf(isnull([Section])) then\n",
    "# \"Please Complete the Performance Tab\"\n",
    "# Elseif({Fixed [SHOPP ID], [Date]: Max([Include in Performance? Numeric])})=1 Then\"OK\"\n",
    "# Else \"Please Complete the Performance Tab\"\n",
    "# END\n",
    "# '''\n",
    "\n",
    "def ck_performance_tab_completed(df):\n",
    "    if df['Ten-Year Plan RD'] == 9999 : \n",
    "        return \"OK\"\n",
    "    elif df['perf_entry_count']>0:\n",
    "        return \"OK\"\n",
    "    else: \n",
    "        return 'Please complete the Performance Tab and include at least one activity for each project location. AMT_ID: {}'.format(df['AMT_ID'])\n",
    "\n",
    "df_SHOPP_raw_data['Is Performance tab Complete?'] = df_SHOPP_raw_data.apply(ck_performance_tab_completed, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "inappropriate-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data['Is Performance tab Complete?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "baking-canadian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Ten-Year Plan RD</th>\n",
       "      <th>perf_entry_count</th>\n",
       "      <th>Is Performance tab Complete?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>21255</td>\n",
       "      <td>CCA</td>\n",
       "      <td>2017</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section  Ten-Year Plan RD  perf_entry_count  \\\n",
       "3473   21255     CCA              2017               1.0   \n",
       "\n",
       "     Is Performance tab Complete?  \n",
       "3473                           OK  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####Manual Check#####\n",
    "\n",
    "AMT_ID = 21255\n",
    "#manpaul: agree with this logic\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] == AMT_ID][['AMT_ID','Section','Ten-Year Plan RD',\n",
    "                                                            'perf_entry_count',\n",
    "                                                           'Is Performance tab Complete?']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "straight-acquisition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District</th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>EA</th>\n",
       "      <th>EFIS</th>\n",
       "      <th>PPNO</th>\n",
       "      <th>Location</th>\n",
       "      <th>County</th>\n",
       "      <th>Route</th>\n",
       "      <th>BackPM</th>\n",
       "      <th>AheadPM</th>\n",
       "      <th>ProjectedRTL FY</th>\n",
       "      <th>Main Activity Category</th>\n",
       "      <th>Section</th>\n",
       "      <th>ActID</th>\n",
       "      <th>Perf Activity Category</th>\n",
       "      <th>Activity Detail</th>\n",
       "      <th>Performance Objective</th>\n",
       "      <th>Unit of Measurement</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Assets in Good Cond</th>\n",
       "      <th>Assets in Fair Cond</th>\n",
       "      <th>Assets in Poor Cond</th>\n",
       "      <th>New Assets Added</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Guidance</th>\n",
       "      <th>Last Saved</th>\n",
       "      <th>Saved By</th>\n",
       "      <th>Post-Good</th>\n",
       "      <th>Post-Fair</th>\n",
       "      <th>Post-Poor</th>\n",
       "      <th>HQ ProgramReview - Agree with District?</th>\n",
       "      <th>HQ Comment</th>\n",
       "      <th>Review Date</th>\n",
       "      <th>PerformanceChange Date After Review</th>\n",
       "      <th>Status</th>\n",
       "      <th>drainage_in_performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57282</th>\n",
       "      <td>8</td>\n",
       "      <td>21255</td>\n",
       "      <td>1E611</td>\n",
       "      <td>818000175.0</td>\n",
       "      <td>3010Q</td>\n",
       "      <td>Primary</td>\n",
       "      <td>RIV</td>\n",
       "      <td>62</td>\n",
       "      <td>81.6</td>\n",
       "      <td>82.2</td>\n",
       "      <td>2018/19</td>\n",
       "      <td>Safety - SI</td>\n",
       "      <td>PPC</td>\n",
       "      <td>E16</td>\n",
       "      <td>Safety, Signs &amp; Lighting</td>\n",
       "      <td>Rumble Strips (201.010, .015)</td>\n",
       "      <td>No Performance Objective in the SHSMP</td>\n",
       "      <td>Linear Feet</td>\n",
       "      <td>9651.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9651.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/03/20 @ 2:11 PM</td>\n",
       "      <td>Matthew Hall</td>\n",
       "      <td>9651.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Active</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57285</th>\n",
       "      <td>8</td>\n",
       "      <td>21255</td>\n",
       "      <td>1E611</td>\n",
       "      <td>818000175.0</td>\n",
       "      <td>3010Q</td>\n",
       "      <td>Primary</td>\n",
       "      <td>RIV</td>\n",
       "      <td>62</td>\n",
       "      <td>81.6</td>\n",
       "      <td>82.2</td>\n",
       "      <td>2018/19</td>\n",
       "      <td>Safety - SI</td>\n",
       "      <td>PPC</td>\n",
       "      <td>E20</td>\n",
       "      <td>Safety, Signs &amp; Lighting</td>\n",
       "      <td>Widen Shoulders (201.010, .015)</td>\n",
       "      <td>No Performance Objective in the SHSMP</td>\n",
       "      <td>Linear Feet</td>\n",
       "      <td>6434.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6434.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/03/20 @ 2:11 PM</td>\n",
       "      <td>Matthew Hall</td>\n",
       "      <td>6434.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Active</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57286</th>\n",
       "      <td>8</td>\n",
       "      <td>21255</td>\n",
       "      <td>1E611</td>\n",
       "      <td>818000175.0</td>\n",
       "      <td>3010Q</td>\n",
       "      <td>Primary</td>\n",
       "      <td>RIV</td>\n",
       "      <td>62</td>\n",
       "      <td>81.6</td>\n",
       "      <td>82.2</td>\n",
       "      <td>2018/19</td>\n",
       "      <td>Safety - SI</td>\n",
       "      <td>PPC</td>\n",
       "      <td>E27</td>\n",
       "      <td>Safety, Signs &amp; Lighting</td>\n",
       "      <td>Safety (SI)</td>\n",
       "      <td>Safety Improvements</td>\n",
       "      <td>Collisions reduced</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/03/20 @ 2:11 PM</td>\n",
       "      <td>Matthew Hall</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Active</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57290</th>\n",
       "      <td>8</td>\n",
       "      <td>21255</td>\n",
       "      <td>1E611</td>\n",
       "      <td>818000175.0</td>\n",
       "      <td>3010Q</td>\n",
       "      <td>Primary</td>\n",
       "      <td>RIV</td>\n",
       "      <td>62</td>\n",
       "      <td>81.6</td>\n",
       "      <td>82.2</td>\n",
       "      <td>2018/19</td>\n",
       "      <td>Safety - SI</td>\n",
       "      <td>PPC</td>\n",
       "      <td>H32</td>\n",
       "      <td>Complete Streets</td>\n",
       "      <td>Is any Location Within the Project Limits Ped/...</td>\n",
       "      <td>No Performance Objective in the SHSMP</td>\n",
       "      <td>Yes/No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/03/20 @ 2:11 PM</td>\n",
       "      <td>Matthew Hall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Active</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       District  AMT_ID     EA         EFIS   PPNO Location County  Route  \\\n",
       "57282         8   21255  1E611  818000175.0  3010Q  Primary    RIV     62   \n",
       "57285         8   21255  1E611  818000175.0  3010Q  Primary    RIV     62   \n",
       "57286         8   21255  1E611  818000175.0  3010Q  Primary    RIV     62   \n",
       "57290         8   21255  1E611  818000175.0  3010Q  Primary    RIV     62   \n",
       "\n",
       "      BackPM AheadPM ProjectedRTL FY Main Activity Category Section ActID  \\\n",
       "57282   81.6    82.2         2018/19            Safety - SI     PPC   E16   \n",
       "57285   81.6    82.2         2018/19            Safety - SI     PPC   E20   \n",
       "57286   81.6    82.2         2018/19            Safety - SI     PPC   E27   \n",
       "57290   81.6    82.2         2018/19            Safety - SI     PPC   H32   \n",
       "\n",
       "         Perf Activity Category  \\\n",
       "57282  Safety, Signs & Lighting   \n",
       "57285  Safety, Signs & Lighting   \n",
       "57286  Safety, Signs & Lighting   \n",
       "57290          Complete Streets   \n",
       "\n",
       "                                         Activity Detail  \\\n",
       "57282                      Rumble Strips (201.010, .015)   \n",
       "57285                    Widen Shoulders (201.010, .015)   \n",
       "57286                                        Safety (SI)   \n",
       "57290  Is any Location Within the Project Limits Ped/...   \n",
       "\n",
       "                       Performance Objective Unit of Measurement Quantity  \\\n",
       "57282  No Performance Objective in the SHSMP         Linear Feet   9651.0   \n",
       "57285  No Performance Objective in the SHSMP         Linear Feet   6434.0   \n",
       "57286                    Safety Improvements  Collisions reduced      8.0   \n",
       "57290  No Performance Objective in the SHSMP              Yes/No      Yes   \n",
       "\n",
       "       Assets in Good Cond  Assets in Fair Cond  Assets in Poor Cond  \\\n",
       "57282                  0.0                  0.0               9651.0   \n",
       "57285                  0.0                  0.0               6434.0   \n",
       "57286                  0.0                  0.0                  8.0   \n",
       "57290                  0.0                  0.0                  0.0   \n",
       "\n",
       "       New Assets Added Comment Guidance          Last Saved      Saved By  \\\n",
       "57282               0.0     NaN      NaN  11/03/20 @ 2:11 PM  Matthew Hall   \n",
       "57285               0.0     NaN      NaN  11/03/20 @ 2:11 PM  Matthew Hall   \n",
       "57286               0.0     NaN      NaN  11/03/20 @ 2:11 PM  Matthew Hall   \n",
       "57290               0.0     NaN      NaN  11/03/20 @ 2:11 PM  Matthew Hall   \n",
       "\n",
       "       Post-Good  Post-Fair  Post-Poor  \\\n",
       "57282     9651.0        NaN        NaN   \n",
       "57285     6434.0        NaN        NaN   \n",
       "57286        8.0        NaN        NaN   \n",
       "57290        NaN        NaN        NaN   \n",
       "\n",
       "      HQ ProgramReview - Agree with District? HQ Comment Review Date  \\\n",
       "57282                                     NaN        NaN         NaN   \n",
       "57285                                     NaN        NaN         NaN   \n",
       "57286                                     NaN        NaN         NaN   \n",
       "57290                                     NaN        NaN         NaN   \n",
       "\n",
       "      PerformanceChange Date After Review  Status  drainage_in_performance  \n",
       "57282                                 NaN  Active                    False  \n",
       "57285                                 NaN  Active                    False  \n",
       "57286                                 NaN  Active                    False  \n",
       "57290                                 NaN  Active                    False  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_perf_raw_data[(df_perf_raw_data['AMT_ID'] == AMT_ID) & (df_perf_raw_data['Section'] == 'PPC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-specific",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "earlier-concord",
   "metadata": {},
   "source": [
    "<a id='Is_at_least_one_performance_activities_related_to_the_Activity_Category_of_planned_project'></a>\n",
    "\n",
    "### Is at least one performance activities related to the Activity Category of planned project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "silent-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is at least one performance activities related to the Activity Category of planned project?\n",
    "\n",
    "# cal ='''\n",
    "# If [Planning or Post-Planning]=\"Post-Planning\" then \"OK\" \n",
    "# Elseif [Section to Use]=[Section Programming Summary] then \n",
    "#      IF { FIXED [SHOPP ID], [Date], [Section Programming Summary]:SUM([Programming Summary Performance Value (No Nulls)])}=0\n",
    "#                     Then \"Please review activities in the performance tab, or the Activity Category of project profile. The performance measure to be reported to CTC is 0.\"\n",
    "#                 Else \"OK\"\n",
    "#                 END\n",
    "# Else \"OK\"\n",
    "#                 END\n",
    "# '''\n",
    "\n",
    "\n",
    "\n",
    "def ck_active_category_performance(df):\n",
    "    \n",
    "    '''\n",
    "    if project is in post-planning, SKIP the check\n",
    "    if in program summary, same project, same section, no performance value entries is found, FLAG\n",
    "    else ok\n",
    "    '''\n",
    "    \n",
    "    if df['Ten-Year Plan RD'] == 9999 : \n",
    "        return \"OK\"\n",
    "    if (\"Complete Street\" in df['Type of Exception']) or (\"Proactive Safety\" in df['Type of Exception']): \n",
    "        #if the check exception has Complete Street, or Proactive Safety, skip the check.\n",
    "        return  \"OK\" \n",
    "    elif df['Planning or Post-Planning'] == \"Post-Planning\" : \n",
    "        #question: manpaul: we should check the project performance, regardless planning or post-planning.\n",
    "        #Loren: we will do this just to fit for purpose to accomodate legacy data\n",
    "        return  \"OK\" \n",
    "\n",
    "    elif pd.isnull(df['Performance Value Sum']) or df['Performance Value Sum'] == 0:\n",
    "        return 'Please update activities or quantities in the Performance Tab to match the main Activity Category of project in TYP section.  Performance reported in the Programming Summary is missing or equal to 0. AMT_ID: {}'.format(df['AMT_ID'])\n",
    "    else: \n",
    "        return \"OK\"\n",
    "\n",
    "ck_name = 'Does the performance tab include one or more activities related to the Activity Category?' \n",
    "    \n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_active_category_performance, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "opponent-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data[ck_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-explosion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "civic-masters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Planning or Post-Planning</th>\n",
       "      <th>Performance Value Sum</th>\n",
       "      <th>Does the performance tab include one or more activities related to the Activity Category?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4880</th>\n",
       "      <td>23004</td>\n",
       "      <td>TYP</td>\n",
       "      <td>Planning</td>\n",
       "      <td>2.0</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section Planning or Post-Planning  Performance Value Sum  \\\n",
       "4880   23004     TYP                  Planning                    2.0   \n",
       "\n",
       "     Does the performance tab include one or more activities related to the Activity Category?  \n",
       "4880                                                 OK                                         "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ####Manual Check#####\n",
    "# 21182\n",
    "# 22715\n",
    "# 22817\n",
    "# 22972\n",
    "\n",
    "AMT_ID = 23004\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] == AMT_ID][['AMT_ID','Section','Planning or Post-Planning','Performance Value Sum',\n",
    "                                                           ck_name]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "seasonal-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_program_summary[(df_program_summary['AMT_ID']==AMT_ID)\n",
    "#                        & (df_program_summary['Section']== 'TYP')][['AMT_ID','EA','Section','Performance Value']]\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "extensive-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_program_summary[(df_program_summary['AMT_ID']==AMT_ID)\n",
    "#                        & (df_program_summary['Section']== 'TYP')\n",
    "#                       ]['Performance Value'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-concentrate",
   "metadata": {},
   "source": [
    "<a id='Is_Long_Lead_Project_Cost_and_RTL_completed_and_consistent'></a>\n",
    "\n",
    "### Is Long Lead Project Cost and RTL completed and consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "institutional-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Are the Long Lead Project Cost and RTL fields complete and consistent?\n",
    "\n",
    "# cal ='''\n",
    "\n",
    "# IF[Long Lead]=\"Y\" and [Ten-Year Plan RD]<>9999 Then\n",
    "# If [Type of Exception]=\"Long Lead schedule\" then \"OK\" \n",
    "# ElseIF [Section to Use]=\"TYP\" then \n",
    "#     If [Last Year of Fiscal Year]-FLOAT(Right([Target RTL FY],2))<4 or isnull ([Last Year of Fiscal Year])\n",
    "#     or isnull([Target RTL FY]) or isnull([LL PAED Cost ($K)]) or isnull ([TYP Total Project Cost ($K)])\n",
    "#     Then \"Please review PA&ED cost, Long-Lead Cost or PA&ED allocation year and/or Long-Lead RTL. PA&ED allocation year must be 4 or more years before RTL\" \n",
    "#     Else \"OK\"\n",
    "#     End\n",
    "# ElseIf [Section to Use]=\"PRG\" and Isnull([SHOPP Amendment Date]) then \n",
    "#     If [Last Year of Fiscal Year]-Float(Right([Requested RTL FY],2))<4  or isnull ([Last Year of Fiscal Year]) \n",
    "#     or isnull([Requested RTL FY])or isnull([PAED ($K)]) or isnull ([Total LL Prog ($K)])\n",
    "#     Then \"Please review PA&ED cost, Long-Lead Cost or PA&ED allocation year and/or Long-Lead RTL. PA&ED allocation year must be 4 or more years before RTL\" \n",
    "#     Else \"OK\"\n",
    "#     End\n",
    "# Else\"OK\"\n",
    "# End\n",
    "# Else\"OK\"\n",
    "# End\n",
    "# '''\n",
    "\n",
    "def ck_longlead(df):\n",
    "    \n",
    "    #the logic has changed a lot based on the meeting with Mara 9-20-2021\n",
    "    \n",
    "    if df['Long Lead'] != \"Y\" or df['Ten-Year Plan RD']==9999 : # check any long lead project\n",
    "        return \"OK\"\n",
    "    else: #it is a long lead project and not 9999\n",
    "        if \"Long Lead schedule\" in df['Type of Exception'] : \n",
    "            return \"OK\" \n",
    "        elif df['Section'] == \"TYP\" :\n",
    "            initial_comments = 'This project({}) is a long lead project in {} Section. '.format(df['AMT_ID'],df['Section'])\n",
    "            comments = initial_comments\n",
    "            if pd.isnull(df['Last Year of Fiscal Year']):\n",
    "                comments = comments + \"The Last Year of Fiscal Year is missing. \"\n",
    "            if pd.isnull(df['Target RTL FY']):\n",
    "                comments = comments + \"The Target RTL Fiscal Year is missing. \"\n",
    "            if df['TYP Total Project Cost ($K)'] == 0:\n",
    "                comments = comments + \"The TYP Total Project Cost ($K) is missing. \"\n",
    "                \n",
    "            if df['Last Year of Fiscal Year']-df['Target RTL FY Number']<4 :\n",
    "                comments = comments + \"The Last Year of Fiscal Year ({}) is less than 4 year from Target RTL Fiscal Year.({}). PA&ED allocation year must be 4 or more years before RTL. \".format(df['Last Year of Fiscal Year'], df['Target RTL FY Number'])\n",
    "            \n",
    "            if df['Const Cost ($K)']== 0 :\n",
    "                comments = comments + \"The LL construction capital cost is missing. \"\n",
    "                \n",
    "            if df['LL PAED Cost ($K)']== 0 :\n",
    "                comments = comments + \"The PA&ED  cost is missing. \"\n",
    "                \n",
    "            if comments == initial_comments: \n",
    "                return \"OK\"\n",
    "            else:\n",
    "                return comments\n",
    "\n",
    "        elif df['Section'] == \"PRG\": \n",
    "\n",
    "            initial_comments = 'This project({}) is in {} Section. '.format(df['AMT_ID'],df['Section'])\n",
    "            comments = initial_comments\n",
    "            if pd.isnull(df['Last Year of Fiscal Year']):\n",
    "                comments = comments + \"The Long Lead RTL FY is missing. \"\n",
    "            elif df['Last Year of Fiscal Year'] - df['Requested RTL FY Number'] < 4 : # DEBUG: this should flag for project 13559\n",
    "                comments = comments + \"The Last Year of Fiscal Year ({}) is less than 4 year from Target RTL Fiscal Year.({}). PA&ED allocation year must be 4 or more years before RTL. \".format(df['Last Year of Fiscal Year'], df['Requested RTL FY Number'])\n",
    "            if pd.isnull(df['Requested RTL FY']):\n",
    "                comments = comments + \"The PAED Allocation FY is missing. \"\n",
    "                \n",
    "            if df['Total LL Prog ($K)'] == 0:\n",
    "                comments = comments + \"The LL RTL FY Total Cost ($K) is missing. \"\n",
    "                \n",
    "            if df['LL CONS Cap ($K)']== 0 :\n",
    "                comments = comments + \"The LL construction capital cost is missing. \"\n",
    "            \n",
    "            if df['PAED ($K)']== 0 :\n",
    "                comments = comments + \"The PA&ED cost is missing. \"\n",
    "                \n",
    "            if comments == initial_comments: \n",
    "                return \"OK\"\n",
    "            else:\n",
    "                return comments\n",
    "            \n",
    "        else:\n",
    "            return \"OK\"\n",
    "\n",
    "        \n",
    "ck_name = 'Are the Long Lead Project Cost and RTL fields complete and consistent?'\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_longlead, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "protecting-implement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OK                                                                                                                                                                                                                   5200\n",
       "This project(22920) is a long lead project in TYP Section. The Last Year of Fiscal Year (2033) is less than 4 year from Target RTL Fiscal Year.(2031). PA&ED allocation year must be 4 or more years before RTL.        1\n",
       "This project(21326) is a long lead project in TYP Section. The PA&ED  cost is missing.                                                                                                                                  1\n",
       "This project(23251) is a long lead project in TYP Section. The Last Year of Fiscal Year (2030) is less than 4 year from Target RTL Fiscal Year.(2027). PA&ED allocation year must be 4 or more years before RTL.        1\n",
       "This project(22919) is a long lead project in TYP Section. The Last Year of Fiscal Year (2034) is less than 4 year from Target RTL Fiscal Year.(2032). PA&ED allocation year must be 4 or more years before RTL.        1\n",
       "Name: Are the Long Lead Project Cost and RTL fields complete and consistent?, dtype: int64"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data[ck_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "close-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data['Active Long Lead'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "likely-veteran",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Active Long Lead</th>\n",
       "      <th>Type of Exception</th>\n",
       "      <th>Ten-Year Plan RD</th>\n",
       "      <th>Total LL Prog ($K)</th>\n",
       "      <th>LL CONS Cap ($K)</th>\n",
       "      <th>Requested RTL FY Number</th>\n",
       "      <th>Const Cost ($K)</th>\n",
       "      <th>Section</th>\n",
       "      <th>LL PAED Cost ($K)</th>\n",
       "      <th>PAED ($K)</th>\n",
       "      <th>Last Year of Fiscal Year</th>\n",
       "      <th>TYP Total Project Cost ($K)</th>\n",
       "      <th>Requested RTL FY</th>\n",
       "      <th>Target RTL FY Number</th>\n",
       "      <th>Are the Long Lead Project Cost and RTL fields complete and consistent?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>11296</td>\n",
       "      <td>PPC</td>\n",
       "      <td>No</td>\n",
       "      <td>Long Lead schedule</td>\n",
       "      <td>2017</td>\n",
       "      <td>96413.0</td>\n",
       "      <td>73200.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>7524.0</td>\n",
       "      <td>PPC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5780.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>10383.0</td>\n",
       "      <td>2017/18</td>\n",
       "      <td>2022</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AMT_ID Section Active Long Lead   Type of Exception  Ten-Year Plan RD  \\\n",
       "161   11296     PPC               No  Long Lead schedule              2017   \n",
       "\n",
       "     Total LL Prog ($K)  LL CONS Cap ($K)  Requested RTL FY Number  \\\n",
       "161             96413.0           73200.0                     2018   \n",
       "\n",
       "     Const Cost ($K) Section  LL PAED Cost ($K)  PAED ($K)  \\\n",
       "161           7524.0     PPC                0.0     5780.0   \n",
       "\n",
       "     Last Year of Fiscal Year  TYP Total Project Cost ($K) Requested RTL FY  \\\n",
       "161                      2018                      10383.0          2017/18   \n",
       "\n",
       "     Target RTL FY Number  \\\n",
       "161                  2022   \n",
       "\n",
       "    Are the Long Lead Project Cost and RTL fields complete and consistent?  \n",
       "161                                                 OK                      "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ####Manual Check#####\n",
    "\n",
    "AMT_ID = 13559\n",
    "# AMT_ID = 21862\n",
    "# AMT_ID = 16268\n",
    "\n",
    "AMT_ID = 11296\n",
    "\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "df_SHOPP_raw_data[(df_SHOPP_raw_data['AMT_ID'] == AMT_ID)][['AMT_ID','Section','Active Long Lead' ,  'Type of Exception',                                      \n",
    "'Ten-Year Plan RD' , 'Total LL Prog ($K)' ,\n",
    "'LL CONS Cap ($K)' ,\n",
    "'Requested RTL FY Number',\n",
    "'Const Cost ($K)' ,\n",
    "'Section' ,\n",
    "'LL PAED Cost ($K)' ,\n",
    "'PAED ($K)' ,\n",
    "'Last Year of Fiscal Year' ,\n",
    "'TYP Total Project Cost ($K)' ,\n",
    "'Requested RTL FY' ,\n",
    "\n",
    "'Target RTL FY Number' ,\n",
    "ck_name\n",
    "                                                            ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "brutal-praise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Active Long Lead</th>\n",
       "      <th>Type of Exception</th>\n",
       "      <th>Ten-Year Plan RD</th>\n",
       "      <th>Total LL Prog ($K)</th>\n",
       "      <th>LL CONS Cap ($K)</th>\n",
       "      <th>Requested RTL FY Number</th>\n",
       "      <th>Const Cost ($K)</th>\n",
       "      <th>Section</th>\n",
       "      <th>LL PAED Cost ($K)</th>\n",
       "      <th>PAED ($K)</th>\n",
       "      <th>Last Year of Fiscal Year</th>\n",
       "      <th>TYP Total Project Cost ($K)</th>\n",
       "      <th>Requested RTL FY</th>\n",
       "      <th>Target RTL FY Number</th>\n",
       "      <th>Are the Long Lead Project Cost and RTL fields complete and consistent?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>19939</td>\n",
       "      <td>PRG</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No Related Exception</td>\n",
       "      <td>2019</td>\n",
       "      <td>22673.0</td>\n",
       "      <td>14724.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>19689.0</td>\n",
       "      <td>PRG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2364.0</td>\n",
       "      <td>2027</td>\n",
       "      <td>26392.0</td>\n",
       "      <td>2022/23</td>\n",
       "      <td>2025</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section Active Long Lead     Type of Exception  Ten-Year Plan RD  \\\n",
       "2711   19939     PRG              Yes  No Related Exception              2019   \n",
       "\n",
       "      Total LL Prog ($K)  LL CONS Cap ($K)  Requested RTL FY Number  \\\n",
       "2711             22673.0           14724.0                     2023   \n",
       "\n",
       "      Const Cost ($K) Section  LL PAED Cost ($K)  PAED ($K)  \\\n",
       "2711          19689.0     PRG                0.0     2364.0   \n",
       "\n",
       "      Last Year of Fiscal Year  TYP Total Project Cost ($K) Requested RTL FY  \\\n",
       "2711                      2027                      26392.0          2022/23   \n",
       "\n",
       "      Target RTL FY Number  \\\n",
       "2711                  2025   \n",
       "\n",
       "     Are the Long Lead Project Cost and RTL fields complete and consistent?  \n",
       "2711                                                 OK                      "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ####Manual Check#####\n",
    "\n",
    "AMT_ID = 13559\n",
    "# AMT_ID = 21862\n",
    "# AMT_ID = 16268\n",
    "\n",
    "AMT_ID = 19939\n",
    "\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "df_SHOPP_raw_data[(df_SHOPP_raw_data['AMT_ID'] == AMT_ID)][['AMT_ID','Section','Active Long Lead' ,  'Type of Exception',                                      \n",
    "'Ten-Year Plan RD' , 'Total LL Prog ($K)' ,\n",
    "'LL CONS Cap ($K)' ,\n",
    "'Requested RTL FY Number',\n",
    "'Const Cost ($K)' ,\n",
    "'Section' ,\n",
    "'LL PAED Cost ($K)' ,\n",
    "'PAED ($K)' ,\n",
    "'Last Year of Fiscal Year' ,\n",
    "'TYP Total Project Cost ($K)' ,\n",
    "'Requested RTL FY' ,\n",
    "\n",
    "'Target RTL FY Number' ,\n",
    "ck_name\n",
    "                                                            ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-president",
   "metadata": {},
   "source": [
    "<a id='Are_all_Project_Locations_(PM)_Valid'></a>\n",
    "\n",
    "### Are all Project Locations (PM) Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "satellite-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Are all Project Locations (PM) Valid?\n",
    "\n",
    "# cal ='''\n",
    "# IF [Count of invalid PM]=0 then \"OK\"\n",
    "# Else \"Please review the project locations. One or more project location in this project is invalid.\"\n",
    "# End\n",
    "# '''\n",
    "\n",
    "\n",
    "def ck_Valid_PM(df):\n",
    "    if df['Ten-Year Plan RD'] == 9999:\n",
    "        return 'OK'\n",
    "    elif df['PM_Check'] != 'Has Invalid PM' :\n",
    "        return 'OK'\n",
    "    else:\n",
    "        return 'One or more project locations, primary and/or secondary, in this project in the {} section are invalid. AMT_ID: {}'.format(df['Section'], df['AMT_ID'])\n",
    "\n",
    "ck_name = 'Are all Project Locations and Postmiles Valid?'\n",
    "\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_Valid_PM, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "successful-collect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OK                                                                                                                        5143\n",
       "One or more project locations, primary and/or secondary, in this project in the CCA section are invalid. AMT_ID: 22410       1\n",
       "One or more project locations, primary and/or secondary, in this project in the PRG section are invalid. AMT_ID: 13529       1\n",
       "One or more project locations, primary and/or secondary, in this project in the TYP section are invalid. AMT_ID: 20233       1\n",
       "One or more project locations, primary and/or secondary, in this project in the CCA section are invalid. AMT_ID: 16038       1\n",
       "                                                                                                                          ... \n",
       "One or more project locations, primary and/or secondary, in this project in the PRG section are invalid. AMT_ID: 21318       1\n",
       "One or more project locations, primary and/or secondary, in this project in the CCA section are invalid. AMT_ID: 13181       1\n",
       "One or more project locations, primary and/or secondary, in this project in the TYP section are invalid. AMT_ID: 21808       1\n",
       "One or more project locations, primary and/or secondary, in this project in the TYP section are invalid. AMT_ID: 20465       1\n",
       "One or more project locations, primary and/or secondary, in this project in the PRG section are invalid. AMT_ID: 21592       1\n",
       "Name: Are all Project Locations and Postmiles Valid?, Length: 62, dtype: int64"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data[ck_name].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "daily-contemporary",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>District</th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>EA</th>\n",
       "      <th>EFIS</th>\n",
       "      <th>Location</th>\n",
       "      <th>Section</th>\n",
       "      <th>County</th>\n",
       "      <th>Route</th>\n",
       "      <th>BackPM</th>\n",
       "      <th>AheadPM</th>\n",
       "      <th>Alignment</th>\n",
       "      <th>Valid PM</th>\n",
       "      <th>Activity Category</th>\n",
       "      <th>Program</th>\n",
       "      <th>BackPMLatitude</th>\n",
       "      <th>BackPMLongitude</th>\n",
       "      <th>BackPMAssemblyDistrict</th>\n",
       "      <th>BackPMCongressDistrict</th>\n",
       "      <th>BackPMSenateDistrict</th>\n",
       "      <th>AheadPMLatitude</th>\n",
       "      <th>AheadPMLongitude</th>\n",
       "      <th>AheadPMAssemblyDistrict</th>\n",
       "      <th>AheadPMCongressDistrict</th>\n",
       "      <th>AheadPMSenateDistrict</th>\n",
       "      <th>AssemblyDistrict(s)</th>\n",
       "      <th>CongressDistrict(s)</th>\n",
       "      <th>SenateDistrict(s)</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>9263</td>\n",
       "      <td>'0P540</td>\n",
       "      <td>'1013000251</td>\n",
       "      <td>Primary</td>\n",
       "      <td>PPC</td>\n",
       "      <td>SJ</td>\n",
       "      <td>5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Right</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bridge</td>\n",
       "      <td>SHOPP</td>\n",
       "      <td>37.677725</td>\n",
       "      <td>-121.343058</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.683522</td>\n",
       "      <td>-121.343104</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>9263</td>\n",
       "      <td>'0P540</td>\n",
       "      <td>'1013000251</td>\n",
       "      <td>Loc 2</td>\n",
       "      <td>-</td>\n",
       "      <td>STA</td>\n",
       "      <td>99</td>\n",
       "      <td>R17.7</td>\n",
       "      <td>R18.1</td>\n",
       "      <td>Right</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bridge</td>\n",
       "      <td>SHOPP</td>\n",
       "      <td>37.655731</td>\n",
       "      <td>-121.025835</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.661689</td>\n",
       "      <td>-121.026193</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    No  District  AMT_ID      EA         EFIS Location Section County  Route  \\\n",
       "68  69        10    9263  '0P540  '1013000251  Primary     PPC     SJ      5   \n",
       "69  70        10    9263  '0P540  '1013000251    Loc 2       -    STA     99   \n",
       "\n",
       "   BackPM AheadPM Alignment Valid PM Activity Category Program  \\\n",
       "68    6.2     6.6     Right      Yes            Bridge   SHOPP   \n",
       "69  R17.7   R18.1     Right      Yes            Bridge   SHOPP   \n",
       "\n",
       "    BackPMLatitude  BackPMLongitude  BackPMAssemblyDistrict  \\\n",
       "68       37.677725      -121.343058                    13.0   \n",
       "69       37.655731      -121.025835                    21.0   \n",
       "\n",
       "    BackPMCongressDistrict  BackPMSenateDistrict  AheadPMLatitude  \\\n",
       "68                    10.0                   5.0        37.683522   \n",
       "69                    10.0                   5.0        37.661689   \n",
       "\n",
       "    AheadPMLongitude  AheadPMAssemblyDistrict  AheadPMCongressDistrict  \\\n",
       "68       -121.343104                     13.0                     10.0   \n",
       "69       -121.026193                     21.0                     10.0   \n",
       "\n",
       "    AheadPMSenateDistrict AssemblyDistrict(s)  CongressDistrict(s)  \\\n",
       "68                    5.0                  13                 10.0   \n",
       "69                    5.0                  21                 10.0   \n",
       "\n",
       "    SenateDistrict(s)  Status  \n",
       "68                5.0  Active  \n",
       "69                5.0  Active  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ####Manual Check#####\n",
    "\n",
    "\n",
    "AMT_ID = 9263\n",
    "\n",
    "df_pm_check[(df_pm_check['AMT_ID'] == AMT_ID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "advance-peripheral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Section In Use</th>\n",
       "      <th>PM_Check</th>\n",
       "      <th>Are all Project Locations and Postmiles Valid?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>9263</td>\n",
       "      <td>PPC</td>\n",
       "      <td>PPC</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AMT_ID Section Section In Use PM_Check  \\\n",
       "61    9263     PPC            PPC       OK   \n",
       "\n",
       "   Are all Project Locations and Postmiles Valid?  \n",
       "61                                             OK  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID']==AMT_ID][['AMT_ID','Section','Section In Use','PM_Check', ck_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "effective-montreal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>District</th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>EA</th>\n",
       "      <th>EFIS</th>\n",
       "      <th>Location</th>\n",
       "      <th>Section</th>\n",
       "      <th>County</th>\n",
       "      <th>Route</th>\n",
       "      <th>BackPM</th>\n",
       "      <th>AheadPM</th>\n",
       "      <th>Alignment</th>\n",
       "      <th>Valid PM</th>\n",
       "      <th>Activity Category</th>\n",
       "      <th>Program</th>\n",
       "      <th>BackPMLatitude</th>\n",
       "      <th>BackPMLongitude</th>\n",
       "      <th>BackPMAssemblyDistrict</th>\n",
       "      <th>BackPMCongressDistrict</th>\n",
       "      <th>BackPMSenateDistrict</th>\n",
       "      <th>AheadPMLatitude</th>\n",
       "      <th>AheadPMLongitude</th>\n",
       "      <th>AheadPMAssemblyDistrict</th>\n",
       "      <th>AheadPMCongressDistrict</th>\n",
       "      <th>AheadPMSenateDistrict</th>\n",
       "      <th>AssemblyDistrict(s)</th>\n",
       "      <th>CongressDistrict(s)</th>\n",
       "      <th>SenateDistrict(s)</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>9263</td>\n",
       "      <td>'0P540</td>\n",
       "      <td>'1013000251</td>\n",
       "      <td>Primary</td>\n",
       "      <td>PPC</td>\n",
       "      <td>SJ</td>\n",
       "      <td>5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Right</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bridge</td>\n",
       "      <td>SHOPP</td>\n",
       "      <td>37.677725</td>\n",
       "      <td>-121.343058</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.683522</td>\n",
       "      <td>-121.343104</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>9263</td>\n",
       "      <td>'0P540</td>\n",
       "      <td>'1013000251</td>\n",
       "      <td>Loc 2</td>\n",
       "      <td>-</td>\n",
       "      <td>STA</td>\n",
       "      <td>99</td>\n",
       "      <td>R17.7</td>\n",
       "      <td>R18.1</td>\n",
       "      <td>Right</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bridge</td>\n",
       "      <td>SHOPP</td>\n",
       "      <td>37.655731</td>\n",
       "      <td>-121.025835</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.661689</td>\n",
       "      <td>-121.026193</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    No  District  AMT_ID      EA         EFIS Location Section County  Route  \\\n",
       "68  69        10    9263  '0P540  '1013000251  Primary     PPC     SJ      5   \n",
       "69  70        10    9263  '0P540  '1013000251    Loc 2       -    STA     99   \n",
       "\n",
       "   BackPM AheadPM Alignment Valid PM Activity Category Program  \\\n",
       "68    6.2     6.6     Right      Yes            Bridge   SHOPP   \n",
       "69  R17.7   R18.1     Right      Yes            Bridge   SHOPP   \n",
       "\n",
       "    BackPMLatitude  BackPMLongitude  BackPMAssemblyDistrict  \\\n",
       "68       37.677725      -121.343058                    13.0   \n",
       "69       37.655731      -121.025835                    21.0   \n",
       "\n",
       "    BackPMCongressDistrict  BackPMSenateDistrict  AheadPMLatitude  \\\n",
       "68                    10.0                   5.0        37.683522   \n",
       "69                    10.0                   5.0        37.661689   \n",
       "\n",
       "    AheadPMLongitude  AheadPMAssemblyDistrict  AheadPMCongressDistrict  \\\n",
       "68       -121.343104                     13.0                     10.0   \n",
       "69       -121.026193                     21.0                     10.0   \n",
       "\n",
       "    AheadPMSenateDistrict AssemblyDistrict(s)  CongressDistrict(s)  \\\n",
       "68                    5.0                  13                 10.0   \n",
       "69                    5.0                  21                 10.0   \n",
       "\n",
       "    SenateDistrict(s)  Status  \n",
       "68                5.0  Active  \n",
       "69                5.0  Active  "
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pm_check[df_pm_check['AMT_ID']==AMT_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-basketball",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "integral-illustration",
   "metadata": {},
   "source": [
    "<a id='Is_Drainage_Worksheet_Complete'></a>\n",
    "\n",
    "### Is Drainage Worksheet Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "greek-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is Drainage Worksheet Complete (2024/25 RTL and after)? \n",
    "\n",
    "#Question: what does this mean ['Include in Worksheet']\n",
    "\n",
    "# cal ='''\n",
    "# If [Include in Worksheet]=\"Yes\" then\n",
    "# If(isnull([Drainage ID])and [Last Year of Fiscal Year]>24 \n",
    "# and [Include in Performance?]=\"Yes\" \n",
    "# and Left([Performance Objective],15)=\"Drainage System\")\n",
    "# Then 'Please complete drainage worksheet'\n",
    "# Else'OK'\n",
    "# END\n",
    "# Else'OK'\n",
    "# END\n",
    "# '''\n",
    "\n",
    "    \n",
    "\n",
    "def ck_drainage_ws_complete(df):\n",
    "   \n",
    "    #check if \"Last Year of Fiscal Year\" is more than 3 years from now, \"OK\" if no, check further if yes.\n",
    "    #check if Performance raw dataset as has an entry with the same ID and STU, \n",
    "    #        and performance objective that starts with \"Drainage system\"\n",
    "    #if no, \"OK\"\n",
    "    #if yes, check if drainage worksheet dataset has an entry with the same ID and STU, FLAG if no, \"OK\" if yes.\n",
    "    \n",
    "    if df['Ten-Year Plan RD'] == 9999:\n",
    "        return 'OK'\n",
    "    if df['Last Year of Fiscal Year'] <= 2024 or df['Last Year of Fiscal Year'] >= TARGET_FY + 11 : # the drainage worksheet is only available after 2022 SHOPP or later\n",
    "        return 'OK'\n",
    "    else:\n",
    "        if not df['drainage_in_performance']:\n",
    "            return 'OK'\n",
    "        else: \n",
    "\n",
    "            if df['No of Drainage Entries'] > 0:\n",
    "                return 'OK'\n",
    "            else:\n",
    "                return 'The Drainage Worksheet is missing or has not been completed for the PRG section of the project.  AMT_ID: {}'.format(df['AMT_ID'])\n",
    "\n",
    "ck_name = 'Is Drainage Worksheet Complete (2024/25 RTL and after)?'          \n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_drainage_ws_complete, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "outstanding-discharge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OK    5204\n",
       "Name: Is Drainage Worksheet Complete (2024/25 RTL and after)?, dtype: int64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data[ck_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "official-korea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>drainage_in_performance</th>\n",
       "      <th>No of Drainage Entries</th>\n",
       "      <th>Last Year of Fiscal Year</th>\n",
       "      <th>Is Drainage Worksheet Complete (2024/25 RTL and after)?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>20234</td>\n",
       "      <td>TYP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2032</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section  drainage_in_performance  No of Drainage Entries  \\\n",
       "2915   20234     TYP                     True                     0.0   \n",
       "\n",
       "      Last Year of Fiscal Year  \\\n",
       "2915                      2032   \n",
       "\n",
       "     Is Drainage Worksheet Complete (2024/25 RTL and after)?  \n",
       "2915                                                 OK       "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ####Manual Check#####\n",
    "\n",
    "\n",
    "AMT_ID = 20234\n",
    "# AMT_ID = 21679\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "df_SHOPP_raw_data[(df_SHOPP_raw_data['AMT_ID'] == AMT_ID)][['AMT_ID','Section',\n",
    "                                                            'drainage_in_performance','No of Drainage Entries',\n",
    "                                                            'Last Year of Fiscal Year',\n",
    "                                                           ck_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "american-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data[(df_perf_raw_data['AMT_ID'] == AMT_ID) & (df_perf_raw_data['Section'] ==STU)][['AMT_ID','Section','Performance Objective']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-saint",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-importance",
   "metadata": {},
   "source": [
    "<a id='Are_all_conditions_selected_for_bridge_replacements'></a>\n",
    "\n",
    "### Are all conditions selected for bridge replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "cardiac-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Are all conditions selected for bridge replacements?\n",
    "\n",
    "\n",
    "# cal ='''\n",
    "# IF [Ten-Year Plan RD]<> 9999 and [Last Year of Fiscal Year]>24 then\n",
    "#     IF [Section Bridge worksheet]=[Section to Use] Then\n",
    "#     IF isnull([Bridge №]) then \"OK\"\n",
    "#         ElseIF [Work Type]=\"Replacement\" Then \n",
    "#             If Isnull ([Conditions Bridge / Tunnel Health Pre]) Or Isnull([Conditions Bridge Gds Mvmt Pre]) or isnull([Conditions Bridge Scour Pre]) or Isnull ([Conditions Bridge Seismic Pre]) \n",
    "# or (ifnull([Bridge Rail Good (lf)],0)+IFNULL([Bridge Rail Fair (lf)],0)+ifnull([Bridge Rail Poor (lf)],0))=0 \n",
    "#             Then \"Please review Bridge Worksheet. Bridge Replacement should select the condition for Health, Scour, Seismic, Goods and Rail\"\n",
    "#             Else \"OK\"\n",
    "#             END\n",
    "# Else \"OK\"\n",
    "#    END\n",
    "# Else \"OK\"\n",
    "# END\n",
    "# Else \"OK\"\n",
    "# END\n",
    "# '''\n",
    "\n",
    "df_SHOPP_raw_data_filtered = df_SHOPP_raw_data[(df_SHOPP_raw_data['Ten-Year Plan RD'] != 9999) \n",
    "                                               & (df_SHOPP_raw_data['Last Year of Fiscal Year'] > 2024)]  # bridge replacement check implemeted in 2022 SHOPP\n",
    "\n",
    "df_brg_raw_data_filtered = df_brg_raw_data[(df_brg_raw_data['WorkType'] == 'Replacement')][[\n",
    "    'AMT_ID','Section','BridgeNo',\n",
    "                'Health Pre',\n",
    "                'Scour_Pre',\n",
    "                'Seismic_Pre', \n",
    "                'GdsMvmt_Pre',\n",
    "                'Rail_Total(lf)']]\n",
    "\n",
    "\n",
    "temp = pd.merge(df_brg_raw_data_filtered, df_SHOPP_raw_data_filtered[['AMT_ID', 'Section']], how='inner', \n",
    "                left_on = ['AMT_ID', 'Section'],\n",
    "                right_on = ['AMT_ID', 'Section'],)\n",
    "\n",
    "def generate_comments(df):\n",
    "    initial_comments = 'For BridgeNo ({}): '.format(df['BridgeNo'])\n",
    "    comments = initial_comments\n",
    "    if pd.isnull(df['Health Pre']): \n",
    "        comments = comments + 'The bridge pre health information is missing. '\n",
    "    if pd.isnull(df['Scour_Pre']): \n",
    "        comments = comments + 'The bridge pre scour information is missing. '        \n",
    "    if pd.isnull(df['Seismic_Pre']): \n",
    "        comments = comments + 'The bridge pre seismic information is missing. '         \n",
    "    if pd.isnull(df['GdsMvmt_Pre']): \n",
    "        comments = comments + 'The bridge pre goods movement information is missing. '        \n",
    "    if pd.isnull(df['Rail_Total(lf)']): \n",
    "        comments = comments + 'The bridge pre total rail quantity is zero. '        \n",
    "    if comments == initial_comments:\n",
    "        return 'OK'\n",
    "    else:\n",
    "        return comments\n",
    "\n",
    "temp['ck_comment_bridge_replacement'] = temp.apply(generate_comments, axis = 1)\n",
    "\n",
    "temp_filtered = temp[temp['ck_comment_bridge_replacement']!= 'OK']\n",
    "#combine comments from mulitple bridges within the same project\n",
    "temp_filtered = temp_filtered.groupby('AMT_ID')['ck_comment_bridge_replacement'].agg(';'.join).reset_index()\n",
    "\n",
    "\n",
    "df_SHOPP_raw_data.drop(['ck_comment_bridge_replacement'], axis=1, errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data,temp_filtered,\n",
    "                             how = 'left',\n",
    "                             left_on = 'AMT_ID', right_on = 'AMT_ID')\n",
    "df_SHOPP_raw_data['Are all conditions selected for bridge replacements?'] = df_SHOPP_raw_data.apply(\n",
    "                                                                    lambda df: \"OK\" if pd.isnull(df['ck_comment_bridge_replacement']) \n",
    "                                                                    else '{} AMT_ID: {}, {} Section.'.format(df['ck_comment_bridge_replacement'],df['AMT_ID'],df['Section']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "skilled-directive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OK    5204\n",
       "Name: Are all conditions selected for bridge replacements?, dtype: int64"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data['Are all conditions selected for bridge replacements?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "humanitarian-hearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Health Pre</th>\n",
       "      <th>Scour_Pre</th>\n",
       "      <th>Seismic_Pre</th>\n",
       "      <th>GdsMvmt_Pre</th>\n",
       "      <th>Rail_Total(lf)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>Good</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Health Pre Scour_Pre Seismic_Pre GdsMvmt_Pre  Rail_Total(lf)\n",
       "3319       Good      Fair        Good        Good             0.0"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ####Manual Check#####\n",
    "\n",
    "AMT_ID = 22816\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "temp = df_brg_raw_data[(df_brg_raw_data['AMT_ID'] == AMT_ID) \n",
    "                & (df_brg_raw_data['Section'] == STU)\n",
    "                & (df_brg_raw_data['WorkType'] == 'Replacement')][[\n",
    "                'Health Pre',\n",
    "                'Scour_Pre',\n",
    "                'Seismic_Pre', \n",
    "                'GdsMvmt_Pre',\n",
    "                'Rail_Total(lf)']]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-representation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "grand-return",
   "metadata": {},
   "source": [
    "<a id='Does_Bridge_Worksheet_need_updates'></a>\n",
    "\n",
    "### Does Bridge Worksheet need updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "flush-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does Bridge Worksheet need updates?\n",
    "\n",
    "\n",
    "# cal ='''\n",
    "# if isnull([SHOPP Amendment Date])then \n",
    "#   IF ([Bridge Health Worksheet check])>0  \n",
    "#   Or ([Bridge Goods Worksheet check])>0 \n",
    "#   or ([Bridge Scour Worksheet check])>0 \n",
    "#   or ([Bridge Seismic Worksheet check])>0 \n",
    "#   or([BridgeRail Worksheet check ])>0 \n",
    "#     Then \"Please review Bridge Worksheet to match March 2020 data\"\n",
    "# Else \"OK\"\n",
    " \n",
    "# End\n",
    "# Else \"OK\"\n",
    "# END\n",
    "# '''\n",
    "\n",
    "\n",
    "#Bridge Health Worksheet check\n",
    "# BridgeWorksheet_Bridge № \t df_brg_raw_data\n",
    "# Bridge # \t df_bridge_inventory\n",
    "\n",
    "\n",
    "# cal ='''\n",
    "# IF [Ten-Year Plan RD]<> 9999 then\n",
    "# IF [Section Bridge worksheet]=[Section to Use] Then\n",
    "# IF isnull([Bridge №]) then 0\n",
    "# ElseIF [Bridge №]= [Bridge #] Then \n",
    "#     If Isnull ([Conditions Bridge / Tunnel Health Pre]) Then 0\n",
    "#     ELSeIF[Conditions Bridge / Tunnel Health Pre]<>[Bridge Health] Or [Deck Areas Exist (sf)]<> [Deck Area, SF] Then 1\n",
    "#     Else 0\n",
    "#     End\n",
    "# Else 0\n",
    "# END\n",
    "# Else 0\n",
    "# End\n",
    "# Else 0\n",
    "# END\n",
    "# '''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ck_bridge_rail_ws(df):\n",
    "    \n",
    "    if (df['Rail_Poor(lf)'] != 0  \n",
    "        and df['Rail_Poor(lf)'] != df['Bridge Rail Upgrade_Poor, LF']):\n",
    "        return 1\n",
    "    elif ((df['Rail_Fair(lf)'] != 0)\n",
    "        and df['Rail_Fair(lf)'] != df['Bridge Rail Upgrade_Fair, LF']):\n",
    "        return 1\n",
    "    elif ((df['Rail_Good(lf)'] != 0) \n",
    "        and df['Rail_Good(lf)'] != df['Bridge Rail Upgrade_Good, LF']):\n",
    "         return 1\n",
    "    else:\n",
    "         return 0\n",
    "\n",
    "\n",
    "def comment_bridge_rail_ws(df):\n",
    "    comment = ''\n",
    "    if (df['Rail_Poor(lf)'] == 0 or df['Rail_Poor(lf)'] == df['Bridge Rail Upgrade_Poor, LF']):\n",
    "        pass\n",
    "    else:\n",
    "        comment += 'Rail_Poor Pre quanity ({}) does not match bridge inventory quantity ({})'.format(\n",
    "            df['Rail_Poor(lf)'] , df['Bridge Rail Upgrade_Poor, LF'])\n",
    "    if (df['Rail_Fair(lf)'] == 0 \n",
    "        or df['Rail_Fair(lf)'] == df['Bridge Rail Upgrade_Fair, LF']):\n",
    "        pass\n",
    "    else:\n",
    "        comment += 'Rail_Fair Pre quanity ({}) does not match bridge inventory quantity ({})'.format(\n",
    "            df['Rail_Fair(lf)'] , df['Bridge Rail Upgrade_Fair, LF'])\n",
    "        \n",
    "    if (df['Rail_Good(lf)'] == 0 \n",
    "        or df['Rail_Good(lf)'] == df['Bridge Rail Upgrade_Good, LF']) :\n",
    "        pass\n",
    "    else:\n",
    "        comment += 'Rail_Good Pre quanity ({}) does not match bridge inventory quantity ({})'.format(\n",
    "            df['Rail_Good(lf)'] , df['Bridge Rail Upgrade_Good, LF'])\n",
    "    return comment\n",
    "\n",
    "#add bridge with mismatch\n",
    "temp = pd.merge(df_brg_raw_data,df_bridge_inventory, how= 'left', left_on = 'BridgeNo', right_on = 'BridgeNo')\n",
    "\n",
    "temp = temp[['AMT_ID', 'Section', 'BridgeNo',\n",
    "    'Health Pre', 'Bridge Health',\n",
    "       'Scour_Pre', 'Bridge Scour',\n",
    "       'Seismic_Pre','Bridge Seismic',\n",
    "       'GdsMvmt_Pre',  'Bridge Goods Movement_Overall',\n",
    "             'Rail_Poor(lf)','Bridge Rail Upgrade_Poor, LF',\n",
    "             'Rail_Fair(lf)','Bridge Rail Upgrade_Fair, LF',\n",
    "            'Rail_Good(lf)', 'Bridge Rail Upgrade_Good, LF',             \n",
    "       'Deck_Exist(sf)', 'Deck Area, SF',  #question to be answered: the logic does not chek deck area, Loren: we leave it to discuss later.\n",
    "            ]]\n",
    "        \n",
    "\n",
    "temp['Bridge Deck Area Mismatch'] = temp.apply(\n",
    "                                        lambda x: (1 if (pd.notnull(x['Deck_Exist(sf)']))\n",
    "#                                                    and (not pd.isnull(x['Deck Area, SF']))\n",
    "                                                   and (x['Deck_Exist(sf)'] != x['Deck Area, SF']) else 0)\n",
    "                                        ,axis = 1)\n",
    "\n",
    "temp['Bridge Health Worksheet Mismatch'] = temp.apply(\n",
    "                                        lambda x: (1 if (pd.notnull(x['Health Pre'])) \n",
    "#                                                    and (not pd.isnull(x['Bridge Health']))\n",
    "                                                   and (x['Health Pre'] != x['Bridge Health'])\n",
    "                                                    else 0)\n",
    "                                        ,axis = 1)\n",
    "temp['Bridge Scour Worksheet Mismatch'] = temp.apply(\n",
    "                                        lambda x: (1 if (pd.notnull(x['Scour_Pre'])) \n",
    "#                                                    and (not pd.isnull(x['Bridge Scour']))\n",
    "                                                   and (x['Scour_Pre'] != x['Bridge Scour'])  else 0)\n",
    "                                        ,axis = 1)\n",
    "\n",
    "temp['Bridge Seismic Worksheet Mismatch'] = temp.apply(\n",
    "                                        lambda x: (1 if (pd.notnull(x['Seismic_Pre'])) \n",
    "#                                                    and (not pd.isnull(x['Bridge Seismic']))\n",
    "                                                   and x['Seismic_Pre'] != x['Bridge Seismic'] else 0)\n",
    "                                        ,axis = 1)\n",
    "temp['Bridge Goods Movement Worksheet Mismatch'] = temp.apply(\n",
    "                                        lambda x: (1 if (pd.notnull(x['GdsMvmt_Pre']))\n",
    "#                                                    and (not pd.isnull(x['Bridge Goods Movement_Overall']))\n",
    "                                                   and (x['GdsMvmt_Pre'] != x['Bridge Goods Movement_Overall'])\n",
    "                                                   else 0 )\n",
    "                                        ,axis = 1)\n",
    "temp['Bridge Rail Worksheet Mismatch'] = temp.apply(\n",
    "                                        ck_bridge_rail_ws\n",
    "                                        ,axis = 1)\n",
    "\n",
    "temp['Bridge Rail Worksheet Comment'] = temp.apply(\n",
    "                                        comment_bridge_rail_ws\n",
    "                                        ,axis = 1)\n",
    "\n",
    "temp['brg_ws_mismatch_counts'] = (\n",
    "    temp['Bridge Deck Area Mismatch']\n",
    "    + temp['Bridge Rail Worksheet Mismatch']\n",
    "     + temp['Bridge Health Worksheet Mismatch']\n",
    "     + temp['Bridge Scour Worksheet Mismatch']\n",
    "     + temp['Bridge Seismic Worksheet Mismatch']\n",
    "     + temp['Bridge Goods Movement Worksheet Mismatch'])\n",
    "\n",
    "\n",
    "        \n",
    "def generate_brg_ws_ck_comment(df):\n",
    "    if df['brg_ws_mismatch_counts'] == 0:\n",
    "        return 'OK'\n",
    "    \n",
    "    initial_comments = 'For {} section in project {}: for bridge No ({}):'.format(df['Section'],df['AMT_ID'], df['BridgeNo'])\n",
    "    comments =  initial_comments\n",
    "    if df['Bridge Deck Area Mismatch'] > 0: \n",
    "        comments = comments + 'Bridge Pre Deck Area ({}) does not match bridge inventory ({})'.format(df['Deck_Exist(sf)'], df['Deck Area, SF'])\n",
    "    if df['Bridge Rail Worksheet Mismatch'] > 0: \n",
    "        comments = comments + '{} '.format(df['Bridge Rail Worksheet Comment'])\n",
    "    if df['Bridge Health Worksheet Mismatch'] > 0: \n",
    "        comments = comments + 'Bridge Pre health quantity ({}) does not match bridge inventory ({})'.format(df['Health Pre'], df['Bridge Health'])\n",
    "    if df['Bridge Scour Worksheet Mismatch'] > 0:\n",
    "        comments = comments + 'Bridge Pre scour quantity ({}) does not match bridge inventory ({})'.format(df['Scour_Pre'] , df['Bridge Scour']) \n",
    "    if df['Bridge Seismic Worksheet Mismatch'] > 0: \n",
    "        comments = comments + 'Bridge Pre seismic quantity ({}) does not match bridge inventory ({})'.format(df['Seismic_Pre'], df['Bridge Seismic'])\n",
    "    if df['Bridge Goods Movement Worksheet Mismatch'] > 0: \n",
    "        comments = comments + 'Bridge Pre Goods Movement quantity ({}) does not match bridge inventory ({})'.format(df['GdsMvmt_Pre'], df['Bridge Goods Movement_Overall'])\n",
    "    \n",
    "    return comments\n",
    "#     if comments == initial_comments: \n",
    "#         return 'OK'\n",
    "#     else:\n",
    "#         return comments\n",
    "\n",
    "    \n",
    "temp['brg_ws_mismatch_comment'] = temp.apply(generate_brg_ws_ck_comment, axis = 1)\n",
    "\n",
    "temp_filtered = temp[temp['brg_ws_mismatch_counts']> 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "confident-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_grouped = temp_filtered.groupby(['AMT_ID','Section'])['brg_ws_mismatch_comment'].apply(';'.join).reset_index(name = 'brg_ws_mismatch_comments')\n",
    "\n",
    "df_SHOPP_raw_data.drop(['brg_ws_mismatch_comments'], axis=1, errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp_grouped[['AMT_ID','Section','brg_ws_mismatch_comments']], \n",
    "                             how ='left', left_on = ['AMT_ID','Section'], right_on = ['AMT_ID','Section'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "honey-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ck_bridge_ws_against_inventory(df):\n",
    "    \n",
    "#Suggestion: loren: only check project in the project book ,in PPC section (has PCR submitted after bridge WS is implemented), after FY 24\n",
    "    \n",
    "#     AMT_ID = df['AMT_ID']\n",
    "#     STU = df['Section']\n",
    "    \n",
    "    if df['Ten-Year Plan RD'] == 9999 or pd.notnull(df['SHOPP Amendment Date']):\n",
    "        return 'OK'\n",
    "\n",
    "    else:\n",
    "        if pd.isnull(df['brg_ws_mismatch_comments']) :\n",
    "            return 'OK'\n",
    "        else:\n",
    "            return df['brg_ws_mismatch_comments']      \n",
    "ck_name = 'Does Bridge Worksheet need updates?'\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_bridge_ws_against_inventory, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "seasonal-colors",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Ten-Year Plan RD</th>\n",
       "      <th>AM Tool RTL (Section in Use)</th>\n",
       "      <th>SHOPP Amendment Date</th>\n",
       "      <th>Will this project be included in the Project Book?</th>\n",
       "      <th>brg_ws_mismatch_comments</th>\n",
       "      <th>Does Bridge Worksheet need updates?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>18944</td>\n",
       "      <td>TYP</td>\n",
       "      <td>2021</td>\n",
       "      <td>2027/28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section  Ten-Year Plan RD AM Tool RTL (Section in Use)  \\\n",
       "1991   18944     TYP              2021                      2027/28   \n",
       "\n",
       "     SHOPP Amendment Date Will this project be included in the Project Book?  \\\n",
       "1991                  NaN                                                Yes   \n",
       "\n",
       "     brg_ws_mismatch_comments Does Bridge Worksheet need updates?  \n",
       "1991                      NaN                                  OK  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ####Manual Check#####\n",
    "\n",
    "AMT_ID = 18944\n",
    "\n",
    "\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section','Ten-Year Plan RD','AM Tool RTL (Section in Use)',\n",
    "                                                         'SHOPP Amendment Date','Will this project be included in the Project Book?',\n",
    "                                                         'brg_ws_mismatch_comments',ck_name]]\n",
    "\n",
    "# temp[(temp['AMT_ID'] ==AMT_ID) & (temp['Section'] == STU)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "deadly-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp[(temp['AMT_ID'] ==AMT_ID) & (temp['Section'] == STU)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "nuclear-header",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_brg_raw_data[(df_brg_raw_data['AMT_ID'] ==AMT_ID) & (df_brg_raw_data['Section'] == STU)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-sculpture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-principle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "everyday-domain",
   "metadata": {},
   "source": [
    "<a id='Does_the_Plan_Year_in_the_Pavement_Worksheet_match_the_Project_RTL'></a>\n",
    "\n",
    "### Does the Plan Year in the Pavement Worksheet match the Project RTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "crude-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does the Plan Year in the Pavement Worksheet match the Project RTL?\n",
    "\n",
    "\n",
    "# cal ='''\n",
    "# If [Include in Worksheet]=\"Yes\" and [Last Year of Fiscal Year]<30 then\n",
    "# If(isnull([Plan Year])) then \"OK\"\n",
    "# ElseIf [Last Year of Fiscal Year]+2000<2016 and [Plan Year]=2016 then \"OK\"\n",
    "# ElseIf([Plan Year]=[Last Year of Fiscal Year]+2000 and [Pavement Section]=[Section to Use])\n",
    "# Then \"OK\"\n",
    "# Else \"Please review Pavement Worksheet Plan Year. It does not match the project RTL.\"\n",
    "# END\n",
    "# ElSe \"OK\"\n",
    "# End\n",
    "# '''\n",
    "\n",
    "\n",
    "def ck_pavement_ws_plan_year_RTL(df):\n",
    "    if df['Ten-Year Plan RD'] == 9999:\n",
    "        return  'OK'\n",
    "    \n",
    "    if df['Last Year of Fiscal Year'] < TARGET_FY + 11 : # we decided to check only the 10-year plan projects   \n",
    "        if(pd.isnull(df['Pavement_PlanYear'])) : \n",
    "            return  \"OK\"\n",
    "        \n",
    "        #TODO: discuss this logic with Mara for multiple pavement plan years\n",
    "        elif df['No_Pavement_PlanYear'] > 1: \n",
    "            return \"Please review Pavement Worksheet Plan Year for all locations. Only one pavement worksheet plan year is allowed for all locations and the plan year needs to match the project fiscal year ({}). AMT_ID: {}\".format(df['Last Year of Fiscal Year'],df['AMT_ID'])\n",
    "        \n",
    "        elif df['Last Year of Fiscal Year']<2016 and df['Pavement_PlanYear'] == 2016: #static number, because the first set of data we have is 2016 APCS data \n",
    "            return  \"OK\"\n",
    "        \n",
    "        elif(df['Last Year of Fiscal Year'] == df['Pavement_PlanYear'] ): \n",
    "            return  \"OK\"\n",
    "        \n",
    "        else: \n",
    "            return 'Please update the pavement worksheet Plan Year to match the Project RTL. The pavement worksheet plan year ({:.0f}) does not match the AM Tool project RTL FY ({}). AMT_ID: {}'.format(df['Pavement_PlanYear'], df['Last Year of Fiscal Year'],df['AMT_ID'])\n",
    "    else: \n",
    "        return \"OK\"\n",
    "\n",
    "df_SHOPP_raw_data['Does the Plan Year in the Pavement Worksheet match the Project RTL?'] = df_SHOPP_raw_data.apply(ck_pavement_ws_plan_year_RTL, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "original-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data['Does the Plan Year in the Pavement Worksheet match the Project RTL?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "accessible-commerce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Last Year of Fiscal Year</th>\n",
       "      <th>Pavement_PlanYear</th>\n",
       "      <th>No_Pavement_PlanYear</th>\n",
       "      <th>Does the Plan Year in the Pavement Worksheet match the Project RTL?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>18495</td>\n",
       "      <td>TYP</td>\n",
       "      <td>2032</td>\n",
       "      <td>2030.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section  Last Year of Fiscal Year  Pavement_PlanYear  \\\n",
       "1742   18495     TYP                      2032             2030.0   \n",
       "\n",
       "      No_Pavement_PlanYear  \\\n",
       "1742                   1.0   \n",
       "\n",
       "     Does the Plan Year in the Pavement Worksheet match the Project RTL?  \n",
       "1742                                                 OK                   "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ####Manual Check#####\n",
    "\n",
    "AMT_ID = 18437 #\n",
    "AMT_ID = 15971\n",
    "AMT_ID= 18495\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] == AMT_ID][['AMT_ID','Section',\n",
    "                                                           'Last Year of Fiscal Year',\n",
    "                                                           'Pavement_PlanYear','No_Pavement_PlanYear',\n",
    "                                                           'Does the Plan Year in the Pavement Worksheet match the Project RTL?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "major-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pav_raw_data[df_pav_raw_data['AMT_ID'] == AMT_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "terminal-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data[df_SHOPP_raw_data['Does the Plan Year in the Pavement Worksheet match the Project RTL?'] != 'OK'][['AMT_ID','Section',\n",
    "#                                                            'Last Year of Fiscal Year',\n",
    "#                                                            'Pavement_PlanYear',\n",
    "#                                                            'Does the Plan Year in the Pavement Worksheet match the Project RTL?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-supervision",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-committee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-directive",
   "metadata": {},
   "source": [
    "<a id='Is_Pavement_Worksheet_Complete'></a>\n",
    "\n",
    "### Is Pavement Worksheet Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "wrong-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is Pavement Worksheet Complete (2024/25 RTL and after)?\n",
    "\n",
    "\n",
    "# cal ='''\n",
    "# If [Include in Worksheet]=\"Yes\" then\n",
    "# If(isnull([Plan Year])and [Last Year of Fiscal Year]>24 and [Last Year of Fiscal Year]<31 \n",
    "#and [Include in Performance?]=\"Yes\" and Left([Performance Objective],8)=\"Pavement\")\n",
    "# Then 'Please complete pavement worksheet'\n",
    "# Else'OK'\n",
    "# END\n",
    "# Else'OK'\n",
    "# END\n",
    "# '''\n",
    "\n",
    "\n",
    "def ck_pav_ws_complete(df):\n",
    "    \n",
    "    #updated logic\n",
    "    # if ['Performance Objective has Pavement'] == 'Yes', \n",
    "    #if last fiscal year is exclusively between 24 and 31, \n",
    "    # and pavement worksheet has a plan year matching last fiscal year, \n",
    "    # and performance worksheet has an entry of same project ID and section, and Performance Objective starting with 'Pavement'\n",
    "    # Question: can we make the logic more specific and reading friendly \n",
    "    # df_perf_raw_data['Performance Objective'] in ['Pavement Class I','Pavement Class II','Pavement Class III']\n",
    "    \n",
    "    if df['Ten-Year Plan RD'] == 9999:\n",
    "        return 'OK'\n",
    "    if (df['Last Year of Fiscal Year']> 2024 and df['Last Year of Fiscal Year']<TARGET_FY + 11 \n",
    "        and df['Performance Objective has Pavement'] == 'Yes'): #2024 static since pavement worksheet is required after 2024.\n",
    "        \n",
    "        \n",
    "        if(pd.isnull(df['Pavement_PlanYear'])) : #if found plan year, means there is an entry in pavement worksheet\n",
    "            return 'The Pavement Worksheet is missing or has not been completed for the {} section of the project. AMT_ID: {}'.format(df['Section'],df['AMT_ID'])\n",
    "\n",
    "#         elif not (df['Last Year of Fiscal Year'] == df['Pavement_PlanYear']):   #this is checked elsewhere.\n",
    "#             return  'Please correct the pavement worksheet. The plan year ({}) in the pavement worksheet in {} Section does not match the last year of fiscal year of the project ({}).'.format(df['Pavement_PlanYear'], df['Section'], df['Last Year of Fiscal Year'])\n",
    "        else: \n",
    "            return 'OK'\n",
    "        \n",
    "    else: \n",
    "        return 'OK'\n",
    "\n",
    "ck_name = 'Is Pavement Worksheet Complete (2024/25 RTL and after)?'\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_pav_ws_complete, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "decent-warning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OK    5204\n",
       "Name: Is Pavement Worksheet Complete (2024/25 RTL and after)?, dtype: int64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data[ck_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "dangerous-cradle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Last Year of Fiscal Year</th>\n",
       "      <th>Pavement_PlanYear</th>\n",
       "      <th>Performance Objective has Pavement</th>\n",
       "      <th>Is Pavement Worksheet Complete (2024/25 RTL and after)?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>20231</td>\n",
       "      <td>TYP</td>\n",
       "      <td>2032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section  Last Year of Fiscal Year  Pavement_PlanYear  \\\n",
       "2912   20231     TYP                      2032                NaN   \n",
       "\n",
       "     Performance Objective has Pavement  \\\n",
       "2912                                Yes   \n",
       "\n",
       "     Is Pavement Worksheet Complete (2024/25 RTL and after)?  \n",
       "2912                                                 OK       "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ####Manual Check#####\n",
    "\n",
    "AMT_ID = 11365\n",
    "AMT_ID = 20231\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section',\n",
    "                                                           'Last Year of Fiscal Year',\n",
    "                                                           'Pavement_PlanYear',\n",
    "                                                           'Performance Objective has Pavement',\n",
    "                                                           ck_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-staff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-internship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "educational-vancouver",
   "metadata": {},
   "source": [
    "<a id='Is_the_Pavement_Work_Limits_Direction_in_the_Pavement_Worksheet_complete'></a>\n",
    "\n",
    "### Is the Pavement Work Limits Direction in the Pavement Worksheet complete (Obselete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "excited-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is the Pavement Work Limits Direction in the Pavement Worksheet complete? \n",
    "\n",
    "\n",
    "# cal ='''\n",
    "# If [Include in Worksheet]=\"Yes\" then\n",
    "# IF isnull([Plan Year]) then \"OK\"\n",
    "# ElseIf (isnull([Direction])) then \"Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.\"\n",
    "# Else \"OK\"\n",
    "# END\n",
    "# ElSe \"OK\"\n",
    "# End\n",
    "# '''\n",
    "\n",
    "\n",
    "def ck_pavement_worklimit_direction(df):\n",
    "    if pd.isnull(df['Pavement_PlanYear']) : \n",
    "        return  \"OK\"\n",
    "    elif (df['Direction_check']=='Direction Info Missing') : \n",
    "        return  \"For {} section in project {}: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.\".format(df['Section'],df['AMT_ID'],)\n",
    "    else: \n",
    "        return \"OK\"\n",
    "\n",
    "df_SHOPP_raw_data['Is the Pavement Work Limits Direction in the Pavement Worksheet complete?'] = df_SHOPP_raw_data.apply(ck_pavement_worklimit_direction, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "psychological-rugby",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OK                                                                                                                                                                                       5182\n",
       "For TYP section in project 20342: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 21806: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 17318: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 21948: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 21949: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 21104: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 20261: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 16377: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 13683: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 21807: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 21947: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 18495: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 20485: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 18052: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 20996: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 20341: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For PRG section in project 16724: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 21805: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 20346: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 21150: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 21803: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "For TYP section in project 20495: Please review Pavement Worksheet Work Limits direction. It is blank and it is probably using a worksheet logic that was not in aligment with PAVEM.       1\n",
       "Name: Is the Pavement Work Limits Direction in the Pavement Worksheet complete?, dtype: int64"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data['Is the Pavement Work Limits Direction in the Pavement Worksheet complete?'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-omega",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "polished-knife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Pavement_PlanYear</th>\n",
       "      <th>Direction_check</th>\n",
       "      <th>Is the Pavement Work Limits Direction in the Pavement Worksheet complete?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>20342</td>\n",
       "      <td>TYP</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>Direction Info Missing</td>\n",
       "      <td>For TYP section in project 20342: Please revie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section  Pavement_PlanYear         Direction_check  \\\n",
       "2988   20342     TYP             2026.0  Direction Info Missing   \n",
       "\n",
       "     Is the Pavement Work Limits Direction in the Pavement Worksheet complete?  \n",
       "2988  For TYP section in project 20342: Please revie...                         "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ####Manual Check#####\n",
    "\n",
    "AMT_ID = 16724\n",
    "AMT_ID = 20342\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section',\n",
    "                                                           'Pavement_PlanYear',\n",
    "                                                           'Direction_check',\n",
    "                                                           'Is the Pavement Work Limits Direction in the Pavement Worksheet complete?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "sunrise-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pav_raw_data[(df_pav_raw_data['AMT_ID'] == AMT_ID ) & (df_pav_raw_data['Section'] == STU)\n",
    "#                  ][['AMT_ID', \n",
    "#        'Section', 'Direction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-letters",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-navigator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "opposed-spring",
   "metadata": {},
   "source": [
    "<a id='Is_TMS_Worksheet_Complete'></a>\n",
    "\n",
    "### Is TMS Worksheet Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "bright-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is TMS Worksheet Complete (2024/25 RTL and after)? \n",
    "\n",
    "\n",
    "# cal ='''\n",
    "# If [Include in Worksheet]=\"Yes\" then\n",
    "# If(isnull([TMS RTL Plan Year])and [Last Year of Fiscal Year]>24 and [Last Year of Fiscal Year]<31 and \n",
    "# [Include in Performance?]=\"Yes\" and [Performance Objective]=\"Transportation Management Systems\")\n",
    "# Then 'Please complete TMS worksheet'\n",
    "# Else'OK'\n",
    "# END\n",
    "# Else'OK'\n",
    "# END\n",
    "# '''\n",
    "\n",
    "# def ck_TMS_ws_complete(df):\n",
    "    \n",
    "#     if(pd.isnull(df['RTL Plan Year'])) : #if found plan year, means there is an entry in TMS worksheet\n",
    "#         return  \"OK\"\n",
    "#     else:\n",
    "#         if(df['Last Year of Fiscal Year']>24 \n",
    "#            and df['Last Year of Fiscal Year']<31 \n",
    "#            and df['Last Year of Fiscal Year'] != df['RTL Plan Year']%100\n",
    "#            and df['Performance Objective has TMS'] == 'Yes'): \n",
    "#             return  'Please complete TMS worksheet'\n",
    "#         else: return 'OK'\n",
    "        \n",
    "def ck_TMS_ws_complete(df):\n",
    "    if df['Ten-Year Plan RD'] == 9999:\n",
    "        return 'OK'\n",
    "#     if(pd.isnull(df['TMS_PlanYear'])) : #if found plan year, means there is an entry in TMS worksheet\n",
    "#         return  \"OK\"\n",
    "    else:\n",
    "        if(df['Last Year of Fiscal Year']>2024 and df['Last Year of Fiscal Year']<TARGET_FY + 11 \n",
    "#            and not df['Last Year of Fiscal Year'] == df['TMS_PlanYear']\n",
    "            and (pd.isnull(df['TMS_PlanYear']))\n",
    "           and df['Performance Objective has TMS'] == 'Yes'): \n",
    "            return  'Please complete the TMS worksheet in the TYP section. AMT_ID: {}'.format(df['AMT_ID'])\n",
    "        else: return 'OK'\n",
    "        \n",
    "        \n",
    "ck_name =  'Is TMS Worksheet Complete (2024/25 RTL and after)?'\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_TMS_ws_complete, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "developmental-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data[ck_name].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-decision",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "complicated-elizabeth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Ten-Year Plan RD</th>\n",
       "      <th>Last Year of Fiscal Year</th>\n",
       "      <th>TMS_PlanYear</th>\n",
       "      <th>Performance Objective has TMS</th>\n",
       "      <th>Is TMS Worksheet Complete (2024/25 RTL and after)?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>19546</td>\n",
       "      <td>TYP</td>\n",
       "      <td>9999</td>\n",
       "      <td>2027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section  Ten-Year Plan RD  Last Year of Fiscal Year  \\\n",
       "2392   19546     TYP              9999                      2027   \n",
       "\n",
       "      TMS_PlanYear Performance Objective has TMS  \\\n",
       "2392           NaN                           Yes   \n",
       "\n",
       "     Is TMS Worksheet Complete (2024/25 RTL and after)?  \n",
       "2392                                                 OK  "
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ####Manual Check#####\n",
    "\n",
    "# AMT_ID = 20078\n",
    "AMT_ID = 16365\n",
    "AMT_ID = 19546\n",
    "\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section','Ten-Year Plan RD',\n",
    "                                                           'Last Year of Fiscal Year',\n",
    "                                                           'TMS_PlanYear','Performance Objective has TMS',\n",
    "                                                           ck_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "wrapped-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tms_raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "incorporate-ghost",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>RTL Plan Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [AMT_ID, Section, RTL Plan Year]\n",
       "Index: []"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tms_raw_data[(df_tms_raw_data['AMT_ID']==AMT_ID) & (df_tms_raw_data['Section'] == STU)][['AMT_ID','Section','RTL Plan Year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-invitation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-edgar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-clearance",
   "metadata": {},
   "source": [
    "<a id='Does_the_RTL_Plan_Year_in_the_TMS_Worksheet_match_the_Project_RTL'></a>\n",
    "\n",
    "### Does the RTL Plan Year in the TMS Worksheet match the Project RTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "controlling-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does the RTL Plan Year in the TMS Worksheet match the Project RTL?\n",
    "\n",
    "\n",
    "# cal ='''\n",
    "# If [Include in Worksheet]=\"Yes\" and [Last Year of Fiscal Year]<30 then\n",
    "# If(isnull([TMS RTL Plan Year])) then \"OK\"\n",
    "# ElseIf [Last Year of Fiscal Year]+2000<2020 and [TMS RTL Plan Year]=2020 then \"OK\"\n",
    "# ElseIf([TMS RTL Plan Year]=[Last Year of Fiscal Year]+2000 and [TMS Section]=[Section to Use])\n",
    "# Then \"OK\"\n",
    "# Else \"Please review TMS Worksheet RTL Plan Year. It does not match the project RTL.\"\n",
    "# END\n",
    "# ElSe \"OK\"\n",
    "# End\n",
    "# '''\n",
    "\n",
    "\n",
    "# def ck_TMS_ws_plan_year_RTL(df):\n",
    "    \n",
    "#     if df['Last Year of Fiscal Year']<30 :    \n",
    "#         if(pd.isnull(df['RTL Plan Year'])) : \n",
    "#             return  \"OK\"\n",
    "#         elif df['Last Year of Fiscal Year']+2000<2020 and df['RTL Plan Year'] == 2020 : \n",
    "#             #question why 2016 for pavement , 2020 for TMS \n",
    "#             #Mara: due to the availablibility of the pavement and TMS data\n",
    "#             return  \"OK\"\n",
    "#         elif(df['RTL Plan Year'] == df['Last Year of Fiscal Year']+2000): \n",
    "#             return  \"OK\"\n",
    "#         else: \n",
    "#             return \"Please review TMS Worksheet RTL Plan Year. It does not match the project RTL.\"\n",
    "#     else: \n",
    "#         return \"OK\"\n",
    "    \n",
    "def ck_TMS_ws_plan_year_RTL(df):\n",
    "    if df['Ten-Year Plan RD'] == 9999:\n",
    "        return  'OK'\n",
    "    if df['Last Year of Fiscal Year'] < TARGET_FY + 11 :    \n",
    "        if(pd.isnull(df['TMS_PlanYear'])) : \n",
    "            return  \"OK\"\n",
    "        elif df['No_TMS_PlanYear'] > 1: \n",
    "            return \"Please review TMS Worksheet Plan Year for all locations. Only one TMS worksheet plan year is allowed for all locations and the plan year needs to match the project fiscal year ({}). AMT_ID: {}\".format(df['Last Year of Fiscal Year'],df['AMT_ID'])\n",
    "            \n",
    "        elif df['Last Year of Fiscal Year']< 2020 and (2020 == df['TMS_PlanYear']) : \n",
    "            #2020 for TMS  due to the availablibility of the pavement and TMS data\n",
    "            return  \"OK\"\n",
    "        elif(df['Last Year of Fiscal Year'] == df['TMS_PlanYear']): \n",
    "            return  \"OK\"\n",
    "        else: \n",
    "            \n",
    "            return 'Please update the TMS Worksheet RTL Plan Year to match the Project RTL.  The TMS Worksheet RTL Plan Year ({:.0f}) does not match the AM Tool project RTL ({}). AMT_ID: {}'.format(df['TMS_PlanYear'], df['Last Year of Fiscal Year'],df['AMT_ID'])\n",
    "    else: \n",
    "        return \"OK\"\n",
    "\n",
    "    \n",
    "ck_name = 'Does the RTL Plan Year in the TMS Worksheet match the Project RTL?'\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_TMS_ws_plan_year_RTL, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "moved-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data['Does the RTL Plan Year in the TMS Worksheet match the Project RTL?'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "confused-civilian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Last Year of Fiscal Year</th>\n",
       "      <th>TMS_PlanYear</th>\n",
       "      <th>Does the RTL Plan Year in the TMS Worksheet match the Project RTL?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>19941</td>\n",
       "      <td>TYP</td>\n",
       "      <td>2032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section  Last Year of Fiscal Year  TMS_PlanYear  \\\n",
       "2713   19941     TYP                      2032           NaN   \n",
       "\n",
       "     Does the RTL Plan Year in the TMS Worksheet match the Project RTL?  \n",
       "2713                                                 OK                  "
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ####Manual Check#####\n",
    "\n",
    "AMT_ID = 19941\n",
    "\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section',\n",
    "                                                           'Last Year of Fiscal Year',\n",
    "                                                           'TMS_PlanYear',\n",
    "                                                           'Does the RTL Plan Year in the TMS Worksheet match the Project RTL?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "retired-oklahoma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Last Year of Fiscal Year</th>\n",
       "      <th>TMS_PlanYear</th>\n",
       "      <th>Does the RTL Plan Year in the TMS Worksheet match the Project RTL?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>18611</td>\n",
       "      <td>TYP</td>\n",
       "      <td>2032</td>\n",
       "      <td>2030.0</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section  Last Year of Fiscal Year  TMS_PlanYear  \\\n",
       "1789   18611     TYP                      2032        2030.0   \n",
       "\n",
       "     Does the RTL Plan Year in the TMS Worksheet match the Project RTL?  \n",
       "1789                                                 OK                  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMT_ID = 18611\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section',\n",
    "                                                           'Last Year of Fiscal Year',\n",
    "                                                           'TMS_PlanYear',\n",
    "                                                           'Does the RTL Plan Year in the TMS Worksheet match the Project RTL?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-check",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "blocked-mattress",
   "metadata": {},
   "source": [
    "<a id='Do_SHOPP_project_data_in_the_AM_Tool_match_CTIPS_data'></a>\n",
    "\n",
    "### Do SHOPP project data in the AM Tool match CTIPS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "maritime-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do SHOPP project data in the AM Tool match CTIPS data (RTL and/or Cost)?\n",
    "\n",
    "\n",
    "# cal ='''\n",
    "# If isnull([TOOL ID to obsolete])then\n",
    "# IF [Type of Exception] = \"Cost or RTL not matching CTIPS\" then \"OK\"\n",
    "# ElseIf([Planning or Post-Planning]=\"Post-Planning\") Then\n",
    "#     If(abs([Shopp Tool Cost to use]-[Total Capital & Support Cost])<.9 and [AM Tool RTL (Section in Use)]=[FY]) then \"OK\"\n",
    "#     Else \"Please check cost and RTL data in the PRG or PPC section. Data is not matching CTIPs data (RTL and Cost)\"\n",
    "#     END\n",
    "# Else \"OK\"\n",
    "# END\n",
    "# Else \"Please Obsolete Proejct in the AM Tool. Project was un-pared, split or combined with another project.\"\n",
    "# END\n",
    "# '''\n",
    "\n",
    "\n",
    "def ck_CTIPS(df):\n",
    "    \n",
    "    if df['Ten-Year Plan RD'] == 9999:\n",
    "        return  'OK'\n",
    "    \n",
    "    if df['AMT_ID to obsolete']== 'Obselete':  \n",
    "        return \"Please Obsolete Proejct in the AM Tool. Project was un-pared, split or combined with another project.\"\n",
    "    \n",
    "    elif df['SHOPP Amendment Date'] == '04/01/23': #Needs attention \n",
    "#         ''' if the shopp amendment date is 04/01/23, check the candidate list, \n",
    "#         if in candidate list, check the cost and RTL against the candidate list (Advertised Year\tProject Cost ($K) )\n",
    "#         '''\n",
    "    \n",
    "        initial_comment = 'For the {} section of project ID({}), '.format(df['Section'], df['AMT_ID'])\n",
    "        comments = initial_comment \n",
    "        if(abs(df['Shopp Tool Cost to use']-df['Project Cost ($K)_Candidate'])>=.9): #if the difference is no less than 900 dollars\n",
    "            comments += 'The AM Tool Total Cost (${:.0f}k) does not match SHOPP Candiate Project Cost (${:.0f}k).'.format(df['Shopp Tool Cost to use'], df['Project Cost ($K)_Candidate'])\n",
    "        if df['AM Tool RTL (Section in Use)'] != df['Advertised Year_Candidate'] : \n",
    "            comments += 'The AM Tool RTL FY ({}) does not match SHOPP Candiate RTL FY ({}).'.format(df['AM Tool RTL (Section in Use)'], df['Advertised Year_Candidate'])\n",
    "\n",
    "        if comments == initial_comment :\n",
    "            return 'OK'\n",
    "        else:\n",
    "            return comments + ' If the project should be in another section, and if a PCR or PCD was approved and the PPC section updated, please notify your liaison for review and entering amendment date. If you have a pending PCR please notify your district liaison to add to the book checks exception.'\n",
    "    else:\n",
    "        if \"Cost or RTL not matching CTIPS\" in df['Type of Exception']: \n",
    "            return  \"OK\"\n",
    "        elif(df['Planning or Post-Planning'] == \"Post-Planning\") :  \n",
    "            initial_comment = 'For the {} section of project ID({}), '.format(df['Section'], df['AMT_ID'])\n",
    "            comments = initial_comment \n",
    "            if(abs(df['Shopp Tool Cost to use']-df['Total Capital & Support Cost'])>=.9): #if the difference is no less than 900 dollars\n",
    "                comments += 'The AM Tool Total Cost (${:.0f}k) does not match CTIPS Total Cost (${:.0f}k).'.format(df['Shopp Tool Cost to use'], df['Total Capital & Support Cost'])\n",
    "            if df['AM Tool RTL (Section in Use)'] != df['FY'] : \n",
    "                comments += 'The AM Tool RTL FY ({}) does not match SHOPP Candiate RTL FY ({}).'.format(df['AM Tool RTL (Section in Use)'], df['FY'])\n",
    "\n",
    "            if comments == initial_comment :\n",
    "                return 'OK'\n",
    "            else:\n",
    "                return comments + ' If the project should be in another section, and if a PCR or PCD was approved and the PPC section updated, please notify your liaison for review and entering amendment date. If you have a pending PCR please notify your district liaison to add to the book checks exception.'\n",
    "        else: \n",
    "            return \"OK\"\n",
    "\n",
    "\n",
    "ck_name = 'Does SHOPP project data in the AM Tool data match CTIPS (RTL and/or Cost)?'\n",
    "\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_CTIPS, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "increasing-genealogy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data[ck_name].value_counts(dropna = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "quantitative-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data[df_SHOPP_raw_data[ck_name] != 'OK'][['AMT_ID','Section','AMT_ID to obsolete','Planning or Post-Planning',\n",
    "#                                                            'Shopp Tool Cost to use','Total Capital & Support Cost',\n",
    "#                                                            'AM Tool RTL (Section in Use)','FY',ck_name]].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "wireless-october",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>SHOPP Amendment Date</th>\n",
       "      <th>Long Lead</th>\n",
       "      <th>AMT_ID to obsolete</th>\n",
       "      <th>Planning or Post-Planning</th>\n",
       "      <th>Shopp Tool Cost to use</th>\n",
       "      <th>Total Capital &amp; Support Cost</th>\n",
       "      <th>AM Tool RTL (Section in Use)</th>\n",
       "      <th>FY</th>\n",
       "      <th>Prog Total Project Cost ($K)</th>\n",
       "      <th>Does SHOPP project data in the AM Tool data match CTIPS (RTL and/or Cost)?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4141</th>\n",
       "      <td>22124</td>\n",
       "      <td>PRG</td>\n",
       "      <td>04/01/23</td>\n",
       "      <td>Y</td>\n",
       "      <td>Not Obselete</td>\n",
       "      <td>Post-Planning</td>\n",
       "      <td>34474.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2027/28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34474.0</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section SHOPP Amendment Date Long Lead AMT_ID to obsolete  \\\n",
       "4141   22124     PRG             04/01/23         Y       Not Obselete   \n",
       "\n",
       "     Planning or Post-Planning  Shopp Tool Cost to use  \\\n",
       "4141             Post-Planning                 34474.0   \n",
       "\n",
       "      Total Capital & Support Cost AM Tool RTL (Section in Use)   FY  \\\n",
       "4141                           NaN                      2027/28  NaN   \n",
       "\n",
       "      Prog Total Project Cost ($K)  \\\n",
       "4141                       34474.0   \n",
       "\n",
       "     Does SHOPP project data in the AM Tool data match CTIPS (RTL and/or Cost)?  \n",
       "4141                                                 OK                          "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ####Manual Check#####\n",
    "\n",
    "AMT_ID = 22124\n",
    "ck_name = 'Does SHOPP project data in the AM Tool data match CTIPS (RTL and/or Cost)?'\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section','SHOPP Amendment Date','Long Lead','AMT_ID to obsolete','Planning or Post-Planning',\n",
    "                                                           'Shopp Tool Cost to use','Total Capital & Support Cost',\n",
    "                                                           'AM Tool RTL (Section in Use)','FY','Prog Total Project Cost ($K)',\n",
    "                                                           ck_name]]\n",
    "                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "appreciated-gender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OK'], dtype=object)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][ck_name].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "matched-special",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Candidate Type</th>\n",
       "      <th>Advertised Year_Candidate</th>\n",
       "      <th>Project Cost ($K)_Candidate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>22124</td>\n",
       "      <td>New</td>\n",
       "      <td>2027/28</td>\n",
       "      <td>34474.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AMT_ID Candidate Type Advertised Year_Candidate  \\\n",
       "54   22124            New                   2027/28   \n",
       "\n",
       "    Project Cost ($K)_Candidate  \n",
       "54                      34474.0  "
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shopp_candidate[df_shopp_candidate['AMT_ID'] ==AMT_ID]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-sunglasses",
   "metadata": {},
   "source": [
    "<a id='Is_PID_completed_and_uploaded_for_current_SHOPP_Candidates'></a>\n",
    "\n",
    "### Is PID completed and uploaded for current SHOPP Candidates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "photographic-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is PID completed and uploaded for current SHOPP Candidates?\n",
    "\n",
    "\n",
    "# cal ='''\n",
    "# If([Planning or Post-Planning]=\"Planning\") and [Will this project be included in the Project Book?]=\"Yes\" Then\n",
    "#     IF [Last Year of Fiscal Year]=25 or [Last Year of Fiscal Year]=26 then\n",
    "#         If  [Section to Use]=\"PRG\" Then \"OK\"\n",
    "#         Else \"For 2022 SHOPP candidates, planned projects with RTL FY 2025/26 and 2026/27, District should complete the PRG section information and upload a completed PID.\"\n",
    "#         END   \n",
    "#     ELSEIF [PA&ED FY]=23  then\n",
    "#         If[Section to Use]=\"PRG\" Then \"OK\"\n",
    "#         Else \"For 2022 Long Lead SHOPP candidates, Long Lead projects with PA&ED FY 2022/23, District should complete the PRG section information and upload a completed PID.\"\n",
    "#         END  \n",
    "# Else \"OK\"\n",
    "# End\n",
    "# Else \"OK\"\n",
    "# End\n",
    "# '''\n",
    "\n",
    "\n",
    "def ck_PID_status(df):\n",
    "    \n",
    "    if(df['Planning or Post-Planning'] == \"Planning\"\n",
    "        and df['Will this project be included in the Project Book?'] == \"Yes\"\n",
    "        and df['Activity (group)'] != 'Reservation') : \n",
    "        if df['Last Year of Fiscal Year'] in [TARGET_FY + 6, TARGET_FY + 7] :  \n",
    "            if  df['Section'] == \"PRG\" : \n",
    "                return  \"OK\"\n",
    "            else: \n",
    "                return \"For {} section in project {}: For {} SHOPP candidates, planned projects with RTL FY {} or {}, District should complete the PRG section information and upload a completed PID.\".format(df['Section'],df['AMT_ID'],TARGET_FY + 3, TARGET_FY + 6, TARGET_FY + 7)\n",
    "\n",
    "        elif df['PA&ED FY Number'] == TARGET_FY + 4: \n",
    "            if df['Section'] == \"PRG\" : \n",
    "                return  \"OK\"\n",
    "            else: \n",
    "                return \"For {} section in project {}: For {} Long Lead SHOPP candidates, Long Lead projects with PA&ED FY {}, District should complete the PRG section information and upload a completed PID.\".format(df['Section'],df['AMT_ID'],TARGET_FY + 3, df['PA&ED FY Number'])\n",
    "\n",
    "        else: \n",
    "            return \"OK\"\n",
    "\n",
    "    else: \n",
    "        return \"OK\"\n",
    "\n",
    "df_SHOPP_raw_data['Is PID completed and uploaded for current SHOPP Candidates?'] = df_SHOPP_raw_data.apply(ck_PID_status, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "integral-settlement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OK                                                                                                                                                                                                4942\n",
       "For TYP section in project 22816: For 2024 Long Lead SHOPP candidates, Long Lead projects with PA&ED FY 2025, District should complete the PRG section information and upload a completed PID.       1\n",
       "For TYP section in project 22780: For 2024 Long Lead SHOPP candidates, Long Lead projects with PA&ED FY 2025, District should complete the PRG section information and upload a completed PID.       1\n",
       "For TYP section in project 23004: For 2024 SHOPP candidates, planned projects with RTL FY 2027 or 2028, District should complete the PRG section information and upload a completed PID.             1\n",
       "For TYP section in project 22967: For 2024 SHOPP candidates, planned projects with RTL FY 2027 or 2028, District should complete the PRG section information and upload a completed PID.             1\n",
       "                                                                                                                                                                                                  ... \n",
       "For TYP section in project 17477: For 2024 SHOPP candidates, planned projects with RTL FY 2027 or 2028, District should complete the PRG section information and upload a completed PID.             1\n",
       "For TYP section in project 22133: For 2024 SHOPP candidates, planned projects with RTL FY 2027 or 2028, District should complete the PRG section information and upload a completed PID.             1\n",
       "For TYP section in project 20065: For 2024 SHOPP candidates, planned projects with RTL FY 2027 or 2028, District should complete the PRG section information and upload a completed PID.             1\n",
       "For TYP section in project 23100: For 2024 SHOPP candidates, planned projects with RTL FY 2027 or 2028, District should complete the PRG section information and upload a completed PID.             1\n",
       "For TYP section in project 20751: For 2024 SHOPP candidates, planned projects with RTL FY 2027 or 2028, District should complete the PRG section information and upload a completed PID.             1\n",
       "Name: Is PID completed and uploaded for current SHOPP Candidates?, Length: 263, dtype: int64"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data['Is PID completed and uploaded for current SHOPP Candidates?'].value_counts(dropna =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-facial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "owned-medline",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Planning or Post-Planning</th>\n",
       "      <th>Will this project be included in the Project Book?</th>\n",
       "      <th>PA&amp;ED FY Number</th>\n",
       "      <th>Is PID completed and uploaded for current SHOPP Candidates?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>20220</td>\n",
       "      <td>TYP</td>\n",
       "      <td>Planning</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section Planning or Post-Planning  \\\n",
       "2902   20220     TYP                  Planning   \n",
       "\n",
       "     Will this project be included in the Project Book?  PA&ED FY Number  \\\n",
       "2902                                                Yes                0   \n",
       "\n",
       "     Is PID completed and uploaded for current SHOPP Candidates?  \n",
       "2902                                                 OK           "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Manual Check#####\n",
    "\n",
    "AMT_ID = 20220\n",
    "\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section',\n",
    "                                                           'Planning or Post-Planning',\n",
    "                                                           'Will this project be included in the Project Book?',\n",
    "                                                           'PA&ED FY Number',\n",
    "                                                           'Is PID completed and uploaded for current SHOPP Candidates?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-theme",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "imported-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data['AMT_ID'].value_counts().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-rotation",
   "metadata": {},
   "source": [
    "<a id='Is_CCE_uploaded'></a>\n",
    "\n",
    "### Is CCE uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "identical-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is CCE uploaded? (5-year POR)\n",
    "\n",
    "# cal ='''\n",
    "# If [Activity (group)]=\"Reservation\" Then \"OK\"\n",
    "# ElseIf([Include 5-year POR?]=\"Yes\" and ISnull ([PID Uploaded])and  Isnull([CCE Uploaded]) and Isnull ([PIP Uploaded])and [Section to Use]=\"TYP\") Then \"CCE needs to be uploaded\"\n",
    "#     Else \"OK\"\n",
    "#     End\n",
    "# '''\n",
    "\n",
    "ck_name = 'Is the Conceptual Cost Estimate (CCE) uploaded? (Applies to all project in the 5-year POR)'\n",
    "\n",
    "def ck_CCE_upload(df):\n",
    "    if df['Activity (group)'] == \"Reservation\" : \n",
    "        return  \"OK\"\n",
    "    elif(df['Include 5-year POR?'] == \"Yes\" \n",
    "         and pd.isnull(df['PID Uploaded'])\n",
    "         and pd.isnull(df['CCE Uploaded']) \n",
    "         and pd.isnull(df['PIP Uploaded'])\n",
    "         and df['Section'] == \"TYP\") :\n",
    "        return 'Please upload the appropriate supporting document (PIP or CCE). AMT_ID: {}'.format(df['AMT_ID'])\n",
    "#         return  \"This project ({}) is in {} section. But none of the PID/PIP/CCE was uploaded. At least one needs to be uploaded.\".format(df['AMT_ID'], df['Section'])\n",
    "    else: \n",
    "        return \"OK\"\n",
    "\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_CCE_upload, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "dimensional-outside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OK    5204\n",
       "Name: Is the Conceptual Cost Estimate (CCE) uploaded? (Applies to all project in the 5-year POR), dtype: int64"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data[ck_name].value_counts(dropna =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "noble-darwin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>PIP Uploaded</th>\n",
       "      <th>CCE Uploaded</th>\n",
       "      <th>PID Uploaded</th>\n",
       "      <th>District</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>20748</td>\n",
       "      <td>Y</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID PIP Uploaded CCE Uploaded PID Uploaded  District\n",
       "3168   20748            Y          Yes          NaN         7"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "###Manual Check#####\n",
    "\n",
    "AMT_ID = 19149\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][[\n",
    "    'AMT_ID','PIP Uploaded','CCE Uploaded','PID Uploaded','District',ck_name]]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID']== 20748][['AMT_ID','PIP Uploaded','CCE Uploaded','PID Uploaded','District']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "timely-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # <a id='LL_not_in_POR'></a>\n",
    "\n",
    "# ### LL not in POR\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def LLinPOR(df):\n",
    "#     if (df['Active Long Lead'] == \"Yes\"\n",
    "#             and df['Last Year of Fiscal Year']< TARGET_FY + 11\n",
    "#             and df['Planning or Post-Planning'] == \"Post-Planning\" \n",
    "#             and df['Include 5-year POR?'] == \"No\"): \n",
    "        \n",
    "#         return \"Check data. This long lead Project is programmed but not in the POR.\"\n",
    "#     else: \n",
    "#         return \"OK\"\n",
    "\n",
    "# df_SHOPP_raw_data['LL not in POR']= df_SHOPP_raw_data.apply(LLinPOR, axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "# ###Manual Check#####\n",
    "\n",
    "# AMT_ID = 19149\n",
    "\n",
    "\n",
    "# STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "# df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section','Last Year of Fiscal Year' ,\n",
    "# 'Active Long Lead' ,\n",
    "# 'Planning or Post-Planning' ,\n",
    "# 'Include 5-year POR?','Ten-Year Plan RD' ,\n",
    "# 'SHOPP Amendment Date' ,\n",
    "# 'Long Lead' ,\n",
    "# 'Last Year FY POR' ,\n",
    "# 'Activity (group)' ,]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-portuguese",
   "metadata": {},
   "source": [
    "<a id='Is_Pavement_limits_repeating_in_the_same_project'></a>\n",
    "\n",
    "## Is Pavement limits repeating in the same project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-skirt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "short-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Include in the Analysis?\n",
    "\n",
    "# cal = \n",
    "# '''\n",
    "# IF [Section In Use]=[Pavement Section] Then\n",
    "# \"Yes\"\n",
    "# Else \"No\"\n",
    "# End\n",
    "\n",
    "# '''\n",
    "\n",
    "# # Is Pavement limits repeating in the same project?\n",
    "\n",
    "# cal = '''\n",
    "# IF [count unique pave limits in same project]>1\n",
    "# Then \"Please review Pavement Worksheet. One or more pavement limits are repeating in this project\"\n",
    "# Else \"OK\"\n",
    "# END\n",
    "# '''\n",
    "\n",
    "# # count unique pave limits in same project\n",
    "\n",
    "# cal = '''\n",
    "# {Fixed [Pavement Section],[Section In Use],[UNIQUE ID PAvement],[Date]:Count ([UNIQUE ID PAvement])}\n",
    "# '''\n",
    "\n",
    "# # UNIQUE ID PAvement\n",
    "\n",
    "# cal = '''\n",
    "# str([ID Pavement])+str(([County Pavement]))+[Work Limits Rout]+ ifnull(BPP,\"\")+str([Beg PM])+ifnull([BPS],\"\")+ifnull([EPP],\"\")+str([End PM])+ifnull([EPS],\"_\")+ifnull([Direction],\"\")+ str(ifnull([Lane],0))+STR([Roadway Class])\n",
    "# '''\n",
    "\n",
    "\n",
    "# def calc_unique_pave_ID(df):\n",
    "    \n",
    "#     return (df['County']\n",
    "#      + '_'+ df['Route']\n",
    "#      + '_'+ (\"\" if pd.isnull(df['BPP']) else df['BPP'])\n",
    "#      + '_'+ str(df['Beg PM'])\n",
    "#      + '_'+ (\"\" if pd.isnull(df['BPS']) else df['BPS'])\n",
    "#      + '_'+ (\"\" if pd.isnull(df['EPP']) else df['EPP'])\n",
    "#      + '_'+ str(df['End PM'])\n",
    "#      + '_'+ (\"\" if pd.isnull(df['EPS']) else df['EPS'])\n",
    "#      + '_'+ (\"\" if pd.isnull(df['Direction']) else df['Direction'])\n",
    "#      + '_'+ str(0 if pd.isnull(df['Lane']) else df['Lane'])\n",
    "#      + '_'+ str(df['RoadwayClass'])\n",
    "#     )\n",
    "\n",
    "\n",
    "\n",
    "df_pav_raw_data['Unique_Pave_Limits'] = df_pav_raw_data.apply(uf.calc_unique_pave_ID, axis = 1)\n",
    "\n",
    "temp = df_pav_raw_data.groupby(['AMT_ID','Section','Unique_Pave_Limits'])['Program'].agg('count').reset_index(name = 'Count of Unique_Pave_Limits')\n",
    "\n",
    "temp_filtered = temp[temp['Count of Unique_Pave_Limits'] > 1]\n",
    "\n",
    "\n",
    "if temp_filtered.empty:\n",
    "    df_SHOPP_raw_data['Is Pavement limits repeating in the same project?'] = 'OK'\n",
    "\n",
    "else:\n",
    "    temp_out = temp_filtered.groupby(['AMT_ID','Section'])['Unique_Pave_Limits'].agg(';'.join)\n",
    "    temp_out = temp_out.reset_index(name = 'Repeated Unique_Pave_Limits')\n",
    "\n",
    "\n",
    "    df_SHOPP_raw_data.drop(columns =['Repeated Unique_Pave_Limits'], inplace=True, errors='ignore')\n",
    "\n",
    "    df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp_out, how= 'left', \n",
    "                                 left_on = ['AMT_ID','Section'],\n",
    "                                 right_on = ['AMT_ID','Section'])\n",
    "\n",
    "    def ck_repeated_pavement(df):\n",
    "        if pd.isnull(df['Repeated Unique_Pave_Limits']):\n",
    "            return 'OK'\n",
    "        else:\n",
    "            return 'Please review Pavement Worksheet for repeating segments ({}) in {} Section. AMT_ID: {}'.format(df['Repeated Unique_Pave_Limits'], df['Section'],df['AMT_ID'])\n",
    "\n",
    "    df_SHOPP_raw_data['Is Pavement limits repeating in the same project?'] = df_SHOPP_raw_data.apply(ck_repeated_pavement, axis = 1)\n",
    "\n",
    "    # df_SHOPP_raw_data['Is Pavement limits repeating in the same project?'].value_counts()\n",
    "\n",
    "\n",
    "    # df_SHOPP_raw_data.drop(columns =['List of Repeated Unique_Pave_Limits','Count of Repeated Unique_Pave_Limits'], inplace=True, errors='ignore')\n",
    "\n",
    "    # df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp_out, how= 'left', \n",
    "    #                              left_on = ['AMT_ID','Section'],\n",
    "    #                              right_on = ['AMT_ID','Section'])\n",
    "\n",
    "    # df_SHOPP_raw_data['Is Pavement limits repeating in the same project?'] = df_SHOPP_raw_data['Count of Repeated Unique_Pave_Limits'].apply(\n",
    "    #                                                                         lambda x: 'OK' if (pd.isnull(x) or x < 2 )\n",
    "    #     else 'Please review Pavement Worksheet. One or more pavement limits are repeating in this project')\n",
    "\n",
    "    # df_out = df_SHOPP_raw_data[df_SHOPP_raw_data['Is Pavement limits repeating in the same project?'] != 'OK'][['District','AMT_ID','Section','List of Repeated Unique_Pave_Limits','Count of Repeated Unique_Pave_Limits']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "altered-intellectual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OK                                                                                                                              5203\n",
       "Please review Pavement Worksheet for repeating segments (ED_'050__R_3.92___6.174__Right_1.0_1) in TYP Section. AMT_ID: 20401       1\n",
       "Name: Is Pavement limits repeating in the same project?, dtype: int64"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data['Is Pavement limits repeating in the same project?'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "public-turtle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Is Pavement limits repeating in the same project?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>22913</td>\n",
       "      <td>TYP</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section Is Pavement limits repeating in the same project?\n",
       "4795   22913     TYP                                                OK"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "###Manual Check#####\n",
    "\n",
    "AMT_ID = 20044\n",
    "AMT_ID= 22913\n",
    "\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section',\n",
    "                                                           'Is Pavement limits repeating in the same project?']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "charged-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp[(temp['AMT_ID'] ==AMT_ID) & (temp['Section'] ==STU)]['Unique_Pave_Limits'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-joining",
   "metadata": {},
   "source": [
    "\n",
    "<a id='Repeated_Bridge_within_the_same_project'></a>\n",
    "\n",
    "## Repeated Bridge within the same project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "unnecessary-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Include in the analysis (section in use only)?\n",
    "\n",
    "# cal = '''\n",
    "# IF [Section In Use]=[Section Bridge worksheet] Then\n",
    "# \"Yes\"\n",
    "# Else \"No\"\n",
    "# End\n",
    "\n",
    "# '''\n",
    "\n",
    "\n",
    "\n",
    "# # Is Bridge # repeating in the same project?\n",
    "# cal = '''\n",
    "# IF [Count Unique bridge same project]>1\n",
    "# Then \"Please review Bridge Worksheet. One or more bridges are repeating in this project\"\n",
    "# Else \"OK\"\n",
    "# END\n",
    "\n",
    "# '''\n",
    "\n",
    "\n",
    "# # Count Unique bridge same project\n",
    "\n",
    "\n",
    "# cal = '''\n",
    "\n",
    "# If [Bridge №]=\"NYA\" then 0 else\n",
    "# {Fixed [Section Bridge worksheet],[Section In Use],[Unique Bridge], [Date]:Count ([Unique Bridge])}\n",
    "# END\n",
    "# '''\n",
    "\n",
    "# # Unique Bridge\n",
    "\n",
    "# cal = '''\n",
    "# Str([ID bridge worksheet])+[Bridge №]+[Section Bridge worksheet]\n",
    "# '''\n",
    "\n",
    "ck_name = 'Is Bridge repeating in the same project?'\n",
    "temp = df_brg_raw_data[df_brg_raw_data['BridgeNo'] != 'NYA']\n",
    "\n",
    "temp_count = temp.groupby(['AMT_ID','Section','BridgeNo'])['Program'].count().reset_index(name = 'Count of BridgeNo')\n",
    "# temp_count.columns = ['AMT_ID','Section','BridgeNo','Count of Duplicated Bridge']\n",
    "temp_count_filtered = temp_count[temp_count['Count of BridgeNo'] > 1]\n",
    "\n",
    "\n",
    "if temp_count_filtered.empty:\n",
    "    df_SHOPP_raw_data[ck_name] = 'OK'\n",
    "\n",
    "else:\n",
    "    temp_count_filtered = temp_count_filtered.groupby(['AMT_ID', 'Section'])['BridgeNo'].agg(lambda x: ';'.join(x)).reset_index(name = 'repeated BirdgeNos')\n",
    "\n",
    "\n",
    "    df_SHOPP_raw_data.drop(columns =['repeated BirdgeNos'], inplace=True, errors='ignore')\n",
    "\n",
    "    df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp_count_filtered[['AMT_ID','Section','repeated BirdgeNos']], how= 'left', \n",
    "                                 left_on = ['AMT_ID', 'Section'], \n",
    "                                 right_on = ['AMT_ID','Section'])\n",
    "\n",
    "    def ck_repeated_bridge(df):\n",
    "        if pd.isnull(df['repeated BirdgeNos']):\n",
    "            return 'OK'\n",
    "        else:\n",
    "            return 'This project has repeating bridges ({}) in {} Section. AMT_ID: {}'.format(df['repeated BirdgeNos'], df['Section'], df['AMT_ID'])\n",
    "\n",
    "    df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_repeated_bridge, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "stuffed-typing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OK    5204\n",
       "Name: Is Bridge repeating in the same project?, dtype: int64"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data['Is Bridge repeating in the same project?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "hungarian-criminal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>repeated BirdgeNos</th>\n",
       "      <th>Is Bridge repeating in the same project?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>20004</td>\n",
       "      <td>PRG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section repeated BirdgeNos  \\\n",
       "2763   20004     PRG                NaN   \n",
       "\n",
       "     Is Bridge repeating in the same project?  \n",
       "2763                                       OK  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Manual Check#####\n",
    "\n",
    "\n",
    "# AMT_ID = 21966\n",
    "AMT_ID = 16157\n",
    "AMT_ID = 18046\n",
    "AMT_ID = 20004\n",
    "\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "# temp[temp['AMT_ID'] == AMT_ID][['AMT_ID','Section','BridgeNo']]\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section','repeated BirdgeNos',\n",
    "'Is Bridge repeating in the same project?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "spoken-basketball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49 0152L    1\n",
       "44 0142R    1\n",
       "49 0153L    1\n",
       "49 0118R    1\n",
       "49 0152R    1\n",
       "49 0118L    1\n",
       "Name: BridgeNo, dtype: int64"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[(temp['AMT_ID'] ==AMT_ID) & (temp['Section'] ==STU)]['BridgeNo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-travel",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<a id='Is_TMS_Asset_repeating_in_the_same_project'></a>\n",
    "\n",
    "## Repeated TMS within the same project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "sensitive-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Is TMS Asset repeating in the same project?\n",
    "\n",
    "# cal = '''\n",
    "# IF [Count unique ID in a same project]>1\n",
    "# Then \"Please review TMS Worksheet. One or more TMS assets are repeating in this project\"\n",
    "# Else \"OK\"\n",
    "# END\n",
    "# '''\n",
    "\n",
    "\n",
    "# # Count unique ID in a same project\n",
    "# cal = '''\n",
    "# If [TMSUnique ID]=\"New\" then 0 else\n",
    "# {Fixed [TMS Section],[Section In Use],[TMS_same_project_unique ID], [Date]:Count ([TMS_same_project_unique ID])}\n",
    "# END\n",
    "# '''\n",
    "\n",
    "# #  TMS_same_project_unique ID\n",
    "\n",
    "# cal = '''Str([SHOPP ID])+[TMSUnique ID]'''\n",
    "\n",
    "ck_name = 'Is TMS Asset repeating in the same project?'\n",
    "\n",
    "\n",
    "#TODO need to create unique TMS ID including column name of \"TMS Structural or Technology\"\n",
    "\n",
    "\n",
    "temp = df_tms_raw_data[df_tms_raw_data.TMSID != 'New']\n",
    "\n",
    "temp_count = temp.groupby(['AMT_ID','Section','TMSID','TMS Structural or Technology'])['Program'].count().reset_index(name = 'Count of TMSID')\n",
    "# temp_count.columns = ['AMT_ID','Section','BridgeNo','Count of Duplicated Bridge']\n",
    "\n",
    "\n",
    "temp_count_filtered = temp_count[temp_count['Count of TMSID'] > 1]\n",
    "\n",
    "if temp_count_filtered.empty:\n",
    "    df_SHOPP_raw_data[ck_name] = 'OK'\n",
    "\n",
    "else:\n",
    "    temp_count_filtered = temp_count_filtered.groupby(['AMT_ID', 'Section'])['TMSID'].agg(lambda x: ';'.join(x)).reset_index(name = 'repeated TMSIDs')\n",
    "\n",
    "    df_SHOPP_raw_data.drop(columns =['repeated TMSIDs'], inplace=True, errors='ignore')\n",
    "\n",
    "    df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp_count_filtered[['AMT_ID','Section','repeated TMSIDs']], how= 'left', \n",
    "                                 left_on = ['AMT_ID', 'Section'], \n",
    "                                 right_on = ['AMT_ID', 'Section'])\n",
    "\n",
    "\n",
    "    def ck_repeated_TMS(df):\n",
    "        if pd.isnull(df['repeated TMSIDs']):\n",
    "            return 'OK'\n",
    "        else:\n",
    "            return 'For {} section in project {}: Please review TMS Worksheet for repeating TMS ({}) in {} Section.'.format(df['Section'],df['AMT_ID'],df['repeated TMSIDs'], df['Section'])\n",
    "\n",
    "    df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_repeated_TMS, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "introductory-former",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OK    5204\n",
       "Name: Is TMS Asset repeating in the same project?, dtype: int64"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data[ck_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "certain-house",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>repeated TMSIDs</th>\n",
       "      <th>Is TMS Asset repeating in the same project?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>18046</td>\n",
       "      <td>TYP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section repeated TMSIDs  \\\n",
       "1527   18046     TYP             NaN   \n",
       "\n",
       "     Is TMS Asset repeating in the same project?  \n",
       "1527                                          OK  "
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "###Manual Check#####\n",
    "\n",
    "\n",
    "# AMT_ID = 21966\n",
    "AMT_ID = 16157\n",
    "AMT_ID = 18046\n",
    "# AMT_ID = 23023\n",
    "\n",
    "\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section','repeated TMSIDs' ,\n",
    "ck_name]]\n",
    "\n",
    "# df_out = df_SHOPP_raw_data[df_SHOPP_raw_data[ck_name]!= 'OK'][['AMT_ID','Section','repeated Culverts']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "vocational-century",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[(temp['AMT_ID'] ==AMT_ID) & (temp['Section'] ==STU)]['TMSID'].value_counts().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-administration",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<a id='Repeated_Culvert_within_the_same_project'></a>\n",
    "\n",
    "## Repeated Culvert within the same project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "sharp-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# #Is Culvert repeating in the same project?\n",
    "\n",
    "# cal = '''\n",
    "# IF [Count unique culverts in same project]>1\n",
    "# Then \"Please review Drainage Worksheet. One or more culverts are repeating in this project\"\n",
    "# Else \"OK\"\n",
    "# END\n",
    "# '''\n",
    "\n",
    "# # Count unique culverts in same project\n",
    "# cal = '''\n",
    "# If[Activity Description]=\"New Culvert\" then 0 else\n",
    "# {Fixed [Section Drainage],[Section In Use],[Unique Culvert+ID], [Date]:Count ([Unique Culvert+ID])}\n",
    "# End\n",
    "# '''\n",
    "\n",
    "# # Unique Culvert+ID\n",
    "\n",
    "# cal ='''\n",
    "# str([Drainage ID])+[SYSNO]+[INETNO]+[OUTETNO]\n",
    "# '''\n",
    "\n",
    "ck_name = 'Is Culvert repeating in the same project?'\n",
    "\n",
    "temp = df_drain_raw_data[df_drain_raw_data['Activity Description'] !=\"New Culvert\"]\n",
    "\n",
    "temp_count = temp.groupby(['AMT_ID','Section','Unique Culvert ID'])['Program'].count().reset_index(name = 'Count of Unique Culvert ID')\n",
    "\n",
    "temp_count_filtered = temp_count[temp_count['Count of Unique Culvert ID'] > 1]\n",
    "\n",
    "\n",
    "if temp_count_filtered.empty:\n",
    "    df_SHOPP_raw_data[ck_name] = 'OK'\n",
    "\n",
    "else:\n",
    "    temp_count_filtered = temp_count_filtered.groupby(['AMT_ID', 'Section'])['Unique Culvert ID'].agg(lambda x: ';'.join(x)).reset_index(name = 'repeated Culverts')\n",
    "\n",
    "    df_SHOPP_raw_data.drop(columns =['repeated Culverts'], inplace=True, errors='ignore')\n",
    "\n",
    "    df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp_count_filtered[['AMT_ID','Section','repeated Culverts']], how= 'left', \n",
    "                                 left_on = ['AMT_ID', 'Section'], \n",
    "                                 right_on = ['AMT_ID', 'Section'])\n",
    "\n",
    "    def ck_repeated_culvert(df):\n",
    "        if pd.isnull(df['repeated Culverts']):\n",
    "            return 'OK'\n",
    "        else:\n",
    "            return 'This project has repeating culverts ({}) in the {} Section. AMT_ID: {}'.format(df['repeated Culverts'], df['Section'], df['AMT_ID']) \n",
    "\n",
    "    df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_repeated_culvert, axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "joint-insert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OK                                                                                                                                                                                                                                                                                                                                                       5203\n",
       "This project has repeating culverts (570150000867_570150000867002_570150000867001;570150000867_570150000867004_570150000867002;570150000867_570150000867006_570150000867004;570150000867_570150000867008_570150000867006;570150000867_570150000867010_570150000867008;570154000835_570154000835003_570154000835001) in the PRG Section. AMT_ID: 18973       1\n",
       "Name: Is Culvert repeating in the same project?, dtype: int64"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data[ck_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "oriented-perception",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>repeated Culverts</th>\n",
       "      <th>Is Culvert repeating in the same project?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4677</th>\n",
       "      <td>22780</td>\n",
       "      <td>TYP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section repeated Culverts  \\\n",
       "4677   22780     TYP               NaN   \n",
       "\n",
       "     Is Culvert repeating in the same project?  \n",
       "4677                                        OK  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "###Manual Check#####\n",
    "\n",
    "\n",
    "AMT_ID = 21966\n",
    "AMT_ID = 22780\n",
    "\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section','repeated Culverts' ,\n",
    "ck_name]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-antibody",
   "metadata": {},
   "source": [
    "## Check duplicate asset within project book and flag only programmed projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "interior-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_SHOPP_raw_data_filtered = df_SHOPP_raw_data[\n",
    "    (df_SHOPP_raw_data['Will this project be included in the Project Book?']=='Yes')\n",
    "    ][['AMT_ID', 'Section','District','EA' ,'Nickname','Advertised Year','Last Year of Fiscal Year','Planning or Post-Planning','Project Cost ($K)','Type of Exception']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "accepted-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_AMT_ID_Section(df):\n",
    "    return 'Section ' + df['Section'] + ' of ' + str(df['AMT_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "aerial-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filtered_comments(df, comment_name, exception):\n",
    "    if pd.isnull(df[comment_name]):\n",
    "        return 'OK'\n",
    "    else:\n",
    "        if df['Planning or Post-Planning'] != 'Planning': #only flag the project that is in planning\n",
    "            return 'OK'\n",
    "        elif exception in df['Type of Exception']: # if it is in exception, do not flag\n",
    "            return 'OK'\n",
    "        else:\n",
    "            return df[comment_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "stuck-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is the bridge repeated in the Project Book?\n",
    "\n",
    "# cal ='''\n",
    "# If isnull([Bridge #]) then \"OK\"\n",
    "# ElseIf [Will this project be included in the Project Book?]=\"Yes\" and  [Include in Performance?]=\"Yes\" and [Section to Use]=[Section Bridge worksheet] then\n",
    "#   IF {Fixed Date, [Will this project be included in the Project Book?], [Bridge #],[Include in Performance?]: COUNTD([ID bridge worksheet])}>1\n",
    "# Then \"This bridge is repeating in your Ten-Year Plan. Please review\"\n",
    "# Else \"OK\"\n",
    "# End\n",
    "# Else \"OK\"\n",
    "# End\n",
    "# '''\n",
    "\n",
    "\n",
    "# get a list of duplicate Bridges with a list of projects  \n",
    "\n",
    "ck_name = 'Is a bridge in a planned project repeated in another project in the Project Book?'\n",
    "comment_col_name = 'Comment for Duplicated Bridge'\n",
    "\n",
    "\n",
    "temp = pd.merge(df_brg_raw_data[['AMT_ID', 'Section','BridgeNo']], df_SHOPP_raw_data_filtered, how='inner', \n",
    "                left_on = ['AMT_ID', 'Section'],\n",
    "                right_on = ['AMT_ID', 'Section'],)\n",
    "\n",
    "# temp_filtered = temp[(temp['Type of Exception'] != 'Repeated Bridge') & (temp['BridgeNo'] != 'NYA')]\n",
    "temp_filtered = temp[(temp['BridgeNo'] != 'NYA')]\n",
    "\n",
    "unique_bridge_group = temp_filtered.groupby(['BridgeNo'])['AMT_ID'].nunique().reset_index(\n",
    "    name = 'Count of AMT_IDs for Same BridgeNo')\n",
    "\n",
    "duplicate_bridge = unique_bridge_group[unique_bridge_group['Count of AMT_IDs for Same BridgeNo']> 1]\n",
    "\n",
    "\n",
    "if duplicate_bridge.empty:\n",
    "    df_SHOPP_raw_data[ck_name] = 'OK'\n",
    "\n",
    "else:\n",
    "    duplicate_bridge_out = pd.merge(duplicate_bridge, temp_filtered, how='left', \n",
    "                    left_on = ['BridgeNo'],\n",
    "                    right_on = ['BridgeNo'],)\n",
    "\n",
    "    duplicate_bridge_out['AMT_ID+Section'] = duplicate_bridge_out.apply(combined_AMT_ID_Section, axis = 1)\n",
    "\n",
    "\n",
    "    temp = duplicate_bridge_out.groupby(['BridgeNo'])['AMT_ID+Section'].apply(','.join).reset_index()\n",
    "\n",
    "    temp[comment_col_name] = temp.apply(lambda df: 'Bridge ({}) is repeated in: {}'.format(df['BridgeNo'], df['AMT_ID+Section'] ), axis = 1)\n",
    "\n",
    "    duplicate_bridge_2 = pd.merge(temp, temp_filtered, how='left', \n",
    "                    left_on = ['BridgeNo'],\n",
    "                    right_on = ['BridgeNo'],)\n",
    "\n",
    "\n",
    "    #cumulate duplicate asset table\n",
    "    duplicate_bridge_3  = duplicate_bridge_2[['BridgeNo','AMT_ID',\n",
    "           'Section', 'District', 'EA','Last Year of Fiscal Year', 'Type of Exception']]\n",
    "\n",
    "    dict_rename = {\n",
    "    'BridgeNo' : 'Asset_ID'\n",
    "                          }\n",
    "    duplicate_bridge_3= duplicate_bridge_3.rename(dict_rename, axis = 1)\n",
    "    \n",
    "    duplicate_bridge_3['Asset_Type'] = 'Bridge'\n",
    "    df_duplicated_asset = duplicate_bridge_3\n",
    "    \n",
    "\n",
    "    \n",
    "    duplicate_bridge_out= duplicate_bridge_2.groupby(['AMT_ID', 'Section'])[comment_col_name].apply(';'.join).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "    df_SHOPP_raw_data.drop(columns=[comment_col_name],inplace=True , errors='ignore')\n",
    "\n",
    "    df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, duplicate_bridge_out, how = 'left', \n",
    "                      left_on = ['AMT_ID','Section'], \n",
    "                      right_on = ['AMT_ID','Section'])\n",
    "\n",
    "\n",
    "    df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(lambda df: 'OK' if pd.isnull(df[comment_col_name]) else '{} Please review and reconcile with the HQ Program.'.format(df[comment_col_name]), axis = 1)\n",
    "    \n",
    "    df_SHOPP_raw_data[ck_name] =  df_SHOPP_raw_data.apply(create_filtered_comments, args=(comment_col_name,'Repeated Bridge'), axis = 1) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-farming",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "least-amount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Is a bridge in a planned project repeated in another project in the Project Book?</th>\n",
       "      <th>Comment for Duplicated Bridge</th>\n",
       "      <th>Type of Exception</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4939</th>\n",
       "      <td>23072</td>\n",
       "      <td>PRG</td>\n",
       "      <td>OK</td>\n",
       "      <td>Bridge (33 0427R) is repeated in: Section PRG ...</td>\n",
       "      <td>Repeated Bridge,Repeated EA,Repeated EFIS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section  \\\n",
       "4939   23072     PRG   \n",
       "\n",
       "     Is a bridge in a planned project repeated in another project in the Project Book?  \\\n",
       "4939                                                 OK                                  \n",
       "\n",
       "                          Comment for Duplicated Bridge  \\\n",
       "4939  Bridge (33 0427R) is repeated in: Section PRG ...   \n",
       "\n",
       "                              Type of Exception  \n",
       "4939  Repeated Bridge,Repeated EA,Repeated EFIS  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMT_ID = 23072\n",
    "# AMT_ID = 23073\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section',ck_name, comment_col_name, 'Type of Exception']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "interpreted-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_out = duplicate_bridge_out\n",
    "# filename = 'duplicate_bridges_all'\n",
    "\n",
    "# df_out.to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "# shutil.copy('.\\output\\{}.csv'.format(filename), 'C:\\inetpub\\wwwroot\\DataLake\\ProjectBookCheck\\{}.csv'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "successful-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is the Culvert repeated in the Project Book?\n",
    "# cal = '''\n",
    "# If isnull([SYSNO]) or [ActID Drainage]=\"C13\" then \"OK\"\n",
    "# ElseIf [Will this project be included in the Project Book?]=\"Yes\" and  [Include in Performance?]=\"Yes\" and [Section to Use]=[Section Drainage] then\n",
    "#   IF {Fixed Date, [Will this project be included in the Project Book?], [Unique Culvert ID],[Include in Performance?]: COUNTD([Drainage ID])}>1\n",
    "# Then \"This Culvert element is repeating in your Ten-Year Plan. Please review\"\n",
    "# Else \"OK\"\n",
    "# End\n",
    "# Else \"OK\"\n",
    "# End\n",
    "# '''\n",
    "\n",
    "\n",
    "# get a list of duplicate culverts with a list of projects  \n",
    "\n",
    "ck_name = 'Is a culvert in a planned project repeated in another project in the Project Book?'\n",
    "comment_col_name = 'Comment for Duplicated Culvert'\n",
    "\n",
    "temp = pd.merge(df_drain_raw_data[['AMT_ID', 'Section','SYSNO','INETNO','OUTETNO','Activity Description','Unique Culvert ID','ActID']], df_SHOPP_raw_data_filtered, how='inner', \n",
    "                left_on = ['AMT_ID', 'Section'],\n",
    "                right_on = ['AMT_ID', 'Section'],)\n",
    "\n",
    "\n",
    "temp_filtered = temp[(temp['ActID'] != 'C13') & (~temp['SYSNO'].isna())]\n",
    "\n",
    "\n",
    "unique_culvert_group = temp_filtered.groupby(['Unique Culvert ID'])['AMT_ID'].nunique().reset_index(\n",
    "    name = 'Count of AMT_IDs for Same Culvert ID')\n",
    "\n",
    "# unique_bridge_group['Count of AMT_IDs for Same BridgeNo'] = unique_bridge_group['AMT_ID list for same BridgeNo'].apply(lambda x: len(x))\n",
    "\n",
    "duplicate_culvert= unique_culvert_group [unique_culvert_group ['Count of AMT_IDs for Same Culvert ID']> 1]\n",
    "\n",
    "if duplicate_culvert.empty:\n",
    "    df_SHOPP_raw_data[ck_name] = 'OK'\n",
    "\n",
    "else:\n",
    "\n",
    "    duplicate_culvert_out = pd.merge(duplicate_culvert, temp_filtered, how='left', \n",
    "                    left_on = ['Unique Culvert ID'],\n",
    "                    right_on = ['Unique Culvert ID'],)\n",
    "\n",
    "    duplicate_culvert_out['AMT_ID+Section'] = duplicate_culvert_out.apply(combined_AMT_ID_Section, axis = 1)\n",
    "\n",
    "    temp_1 = duplicate_culvert_out.groupby(['Unique Culvert ID'])['AMT_ID+Section'].apply(','.join).reset_index()\n",
    "\n",
    "    temp_1[comment_col_name] = temp_1.apply(lambda df: 'Culvert ({}) is repeated in: {}'.format(df['Unique Culvert ID'], df['AMT_ID+Section'] ), axis = 1)\n",
    "\n",
    "    temp_2 = pd.merge(temp_1, temp_filtered, how='left', \n",
    "                    left_on = ['Unique Culvert ID'],\n",
    "                    right_on = ['Unique Culvert ID'],)\n",
    "\n",
    "    #cumulate duplicate asset table\n",
    "    temp_3  = temp_2[['Unique Culvert ID','AMT_ID',\n",
    "           'Section', 'District', 'EA','Last Year of Fiscal Year', 'Type of Exception']]\n",
    "\n",
    "    dict_rename = {\n",
    "    'Unique Culvert ID' : 'Asset_ID'\n",
    "                          }\n",
    "    temp_3= temp_3.rename(dict_rename, axis = 1)\n",
    "    \n",
    "    temp_3['Asset_Type'] = 'Culvert'\n",
    "    df_duplicated_asset =  pd.concat([df_duplicated_asset,  temp_3], axis = 0)\n",
    "    \n",
    "\n",
    "    temp_out= temp_2.groupby(['AMT_ID', 'Section'])[comment_col_name].apply(';'.join).reset_index()\n",
    "\n",
    "    df_SHOPP_raw_data.drop(columns=[comment_col_name],inplace=True , errors='ignore')\n",
    "\n",
    "    df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp_out, how = 'left', \n",
    "                      left_on = ['AMT_ID','Section'], \n",
    "                      right_on = ['AMT_ID','Section'])\n",
    "\n",
    "    df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(lambda df: 'OK' if pd.isnull(df[comment_col_name]) else '{} Please review and reconcile with the HQ Program.'.format(df[comment_col_name]), axis = 1)\n",
    "    df_SHOPP_raw_data[ck_name] =  df_SHOPP_raw_data.apply(create_filtered_comments, args=(comment_col_name,'Repeated Culvert'), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "empty-vertical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Is a culvert in a planned project repeated in another project in the Project Book?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4939</th>\n",
       "      <td>23072</td>\n",
       "      <td>PRG</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section  \\\n",
       "4939   23072     PRG   \n",
       "\n",
       "     Is a culvert in a planned project repeated in another project in the Project Book?  \n",
       "4939                                                 OK                                  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "###Manual Check#####\n",
    "\n",
    "AMT_ID = 21966\n",
    "AMT_ID = 23072\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section',ck_name,]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-omega",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-burner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-daughter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-hospital",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-healthcare",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "stable-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is the TMS repeated in the Project Book?\n",
    "\n",
    "# cal ='''\n",
    "# If isnull([TMSUnique ID]) or [TMSUnique ID]=\"New\" then \"OK\"\n",
    "# ElseIf [Will this project be included in the Project Book?]=\"Yes\" and [Section to Use]=[TMS Section] then\n",
    "#   IF {Fixed Date, [Will this project be included in the Project Book?], [TMSUnique ID], [Include in Performance?]: COUNTD([SHOPP ID])}>1\n",
    "# Then \"This TMS element is repeating in your Ten-Year Plan. Please review\"\n",
    "# Else \"OK\"\n",
    "# End\n",
    "# Else \"OK\"\n",
    "# End\n",
    "# '''\n",
    "\n",
    "# get a list of duplicate TMS with a list of projects  \n",
    "ck_name = 'Is a TMS in a planned project repeated in another project in the Project Book?'\n",
    "comment_col_name = 'Comment for Duplicated TMS'\n",
    "\n",
    "temp = pd.merge(df_tms_raw_data[['TMSID','AMT_ID', 'Section','TMS Structural or Technology']], df_SHOPP_raw_data_filtered, how='inner', \n",
    "                left_on = ['AMT_ID', 'Section'],\n",
    "                right_on = ['AMT_ID', 'Section'],)\n",
    "\n",
    "\n",
    "temp_filtered = temp[(temp['TMSID'] != 'New') & (~temp['TMSID'].isna())]\n",
    "\n",
    "unique_TMS_group = temp_filtered.groupby(['TMSID','TMS Structural or Technology'])['AMT_ID'].nunique().reset_index(\n",
    "    name = 'Count of AMT_IDs for Same TMS ID')\n",
    "\n",
    "# unique_bridge_group['Count of AMT_IDs for Same BridgeNo'] = unique_bridge_group['AMT_ID list for same BridgeNo'].apply(lambda x: len(x))\n",
    "\n",
    "duplicate_TMS= unique_TMS_group[unique_TMS_group['Count of AMT_IDs for Same TMS ID']> 1]\n",
    "\n",
    "#cumulate duplicate asset table\n",
    "# duplicate_culvert['Asset_Type'] = 'TMS'\n",
    "# df_duplicated_asset =  pd.concat([df_duplicated_asset, duplicate_culvert], axis = 0)\n",
    "# df_duplicated_asset =  pd.concat([df_duplicated_asset, duplicated_TMS[]], axis = 0)\n",
    "\n",
    "\n",
    "if duplicate_TMS.empty:\n",
    "    df_SHOPP_raw_data[ck_name] = 'OK'\n",
    "\n",
    "else:\n",
    "    duplicate_TMS_out = pd.merge(duplicate_TMS, temp_filtered, how='left', \n",
    "                    left_on = ['TMSID'],\n",
    "                    right_on = ['TMSID'],)\n",
    "\n",
    "    duplicate_TMS_out['AMT_ID+Section'] = duplicate_TMS_out.apply(combined_AMT_ID_Section, axis = 1)\n",
    "\n",
    "    temp_1 = duplicate_TMS_out.groupby(['TMSID'])['AMT_ID+Section'].apply(','.join).reset_index()\n",
    "\n",
    "    temp_1[comment_col_name] = temp_1.apply(lambda df: 'TMS ({}) is repeated in: {}'.format(df['TMSID'], df['AMT_ID+Section'] ), axis = 1)\n",
    "\n",
    "    temp_2 = pd.merge(temp_1, temp_filtered, how='left', \n",
    "                    left_on = ['TMSID'],\n",
    "                    right_on = ['TMSID'],)\n",
    "\n",
    "    #cumulate duplicate asset table\n",
    "    temp_3  = temp_2[['TMSID','AMT_ID',\n",
    "           'Section', 'District', 'EA','Last Year of Fiscal Year', 'Type of Exception']]\n",
    "\n",
    "    dict_rename = {\n",
    "    'TMSID' : 'Asset_ID'\n",
    "                          }\n",
    "    temp_3= temp_3.rename(dict_rename, axis = 1)\n",
    "    \n",
    "    temp_3['Asset_Type'] = 'TMS'\n",
    "    df_duplicated_asset =  pd.concat([df_duplicated_asset,  temp_3], axis = 0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    temp_out= temp_2.groupby(['AMT_ID', 'Section'])[comment_col_name].apply(';'.join).reset_index()\n",
    "\n",
    "\n",
    "    df_SHOPP_raw_data.drop(columns=[comment_col_name],inplace=True , errors='ignore')\n",
    "\n",
    "    df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp_out, how = 'left', \n",
    "                      left_on = ['AMT_ID','Section'], \n",
    "                      right_on = ['AMT_ID','Section'])\n",
    "\n",
    "\n",
    "\n",
    "    df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(lambda df: 'OK' if pd.isnull(df[comment_col_name]) else '{} Please review and reconcile with the HQ Program. AMT_ID: {}'.format(df[comment_col_name], df['AMT_ID']), axis = 1)\n",
    "    df_SHOPP_raw_data[ck_name] =  df_SHOPP_raw_data.apply(create_filtered_comments, args=(comment_col_name,'Repeated TMS'), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "fatty-wheel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Is a TMS in a planned project repeated in another project in the Project Book?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>18046</td>\n",
       "      <td>TYP</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section  \\\n",
       "1527   18046     TYP   \n",
       "\n",
       "     Is a TMS in a planned project repeated in another project in the Project Book?  \n",
       "1527                                                 OK                              "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "###Manual Check#####\n",
    "\n",
    "\n",
    "AMT_ID = 21966\n",
    "AMT_ID = 18046\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section',ck_name ,]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-string",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-draft",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "bridal-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is the Pavement Segment repeated in the Project Book?\n",
    "ck_name = 'Is a pavement segment in a planned project repeated in another project in the Project Book?'\n",
    "comment_col_name = 'Comment for Duplicated Pavement'\n",
    "\n",
    "temp = pd.merge(df_pav_raw_data[['Unique_Pave_Limits','AMT_ID', 'Section']], df_SHOPP_raw_data_filtered, how='inner', \n",
    "                left_on = ['AMT_ID', 'Section'],\n",
    "                right_on = ['AMT_ID', 'Section'],)\n",
    "\n",
    "temp_filtered = temp[(~temp['Unique_Pave_Limits'].isna())]\n",
    "\n",
    "unique_pavement_group = temp_filtered.groupby(['Unique_Pave_Limits'])['AMT_ID'].nunique().reset_index(\n",
    "    name = 'Count of AMT_IDs for Same Pavement Segment')\n",
    "\n",
    "# unique_bridge_group['Count of AMT_IDs for Same BridgeNo'] = unique_bridge_group['AMT_ID list for same BridgeNo'].apply(lambda x: len(x))\n",
    "\n",
    "duplicate_pavement= unique_pavement_group[unique_pavement_group['Count of AMT_IDs for Same Pavement Segment']> 1]\n",
    "\n",
    "if duplicate_pavement.empty:\n",
    "    df_SHOPP_raw_data[ck_name] = 'OK'\n",
    "\n",
    "else:\n",
    "\n",
    "    duplicate_pavement_out = pd.merge(duplicate_pavement, temp_filtered, how='left', \n",
    "                    left_on = ['Unique_Pave_Limits'],\n",
    "                    right_on = ['Unique_Pave_Limits'],)\n",
    "\n",
    "    duplicate_pavement_out['AMT_ID+Section'] = duplicate_pavement_out.apply(combined_AMT_ID_Section, axis = 1)\n",
    "\n",
    "    temp_1 = duplicate_pavement_out.groupby(['Unique_Pave_Limits'])['AMT_ID+Section'].apply(','.join).reset_index()\n",
    "\n",
    "    temp_1[comment_col_name] = temp_1.apply(lambda df: 'Pavement Segment ({}) is repeated in: {}'.format(df['Unique_Pave_Limits'], df['AMT_ID+Section'] ), axis = 1)\n",
    "\n",
    "    temp_2 = pd.merge(temp_1, temp_filtered, how='left', \n",
    "                    left_on = ['Unique_Pave_Limits'],\n",
    "                    right_on = ['Unique_Pave_Limits'],)\n",
    "    \n",
    "    #cumulate duplicate asset table\n",
    "    temp_3  = temp_2[['Unique_Pave_Limits','AMT_ID',\n",
    "           'Section', 'District', 'EA','Last Year of Fiscal Year', 'Type of Exception']]\n",
    "\n",
    "    dict_rename = {\n",
    "    'Unique_Pave_Limits' : 'Asset_ID'\n",
    "                          }\n",
    "    temp_3= temp_3.rename(dict_rename, axis = 1)\n",
    "    \n",
    "    temp_3['Asset_Type'] = 'Pavement'\n",
    "    df_duplicated_asset =  pd.concat([df_duplicated_asset,  temp_3], axis = 0)\n",
    "    \n",
    "    \n",
    "\n",
    "    temp_out= temp_2.groupby(['AMT_ID', 'Section'])[comment_col_name].apply(';'.join).reset_index()\n",
    "\n",
    "\n",
    "    df_SHOPP_raw_data.drop(columns=[comment_col_name],inplace=True , errors='ignore')\n",
    "\n",
    "    df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp_out, how = 'left', \n",
    "                      left_on = ['AMT_ID','Section'], \n",
    "                      right_on = ['AMT_ID','Section'])\n",
    "\n",
    "    \n",
    "    df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(lambda df: 'OK' if pd.isnull(df[comment_col_name]) else 'For {} section in project {}: {}'.format(df['Section'],df['AMT_ID'], df[comment_col_name]), axis = 1)\n",
    "    \n",
    "    df_SHOPP_raw_data[ck_name] =  df_SHOPP_raw_data.apply(create_filtered_comments, args=(comment_col_name,'Repeated Pavement'), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "saved-belize",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AMT_ID', 'Project Book', 'PID Uploaded', 'PIP Uploaded',\n",
       "       'CCE Uploaded', 'Multiple Loc', 'Loc Count', 'Ten-Year Plan RD',\n",
       "       'District', 'County TYP',\n",
       "       ...\n",
       "       'Is TMS Asset repeating in the same project?', 'repeated Culverts',\n",
       "       'Is Culvert repeating in the same project?',\n",
       "       'Comment for Duplicated Bridge',\n",
       "       'Is a bridge in a planned project repeated in another project in the Project Book?',\n",
       "       'Comment for Duplicated Culvert',\n",
       "       'Is a culvert in a planned project repeated in another project in the Project Book?',\n",
       "       'Comment for Duplicated TMS',\n",
       "       'Is a TMS in a planned project repeated in another project in the Project Book?',\n",
       "       'Is a pavement segment in a planned project repeated in another project in the Project Book?'],\n",
       "      dtype='object', length=200)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "mobile-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data['AMT_ID'].value_counts().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "stock-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ###Manual Check#####\n",
    "# ck_name = 'Is a pavement segment in a planned project repeated in another project in the Project Book?'\n",
    "# comment_col_name = 'Comment for Duplicated Pavement'\n",
    "# AMT_ID = 22983\n",
    "# # AMT_ID = 20476\n",
    "\n",
    "\n",
    "# STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "# df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section',\n",
    "#                                                         ck_name\n",
    "#                                                         ]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-clone",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "charming-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Is the Pavement Worksheet using updated inventory and condition data (2019 APCS) for planned projects?'\n",
    "\n",
    "#Attention: update this check every time APCS data changes\n",
    "\n",
    "def ck_Pav_APCS(df):\n",
    "    if (df['Planning or Post-Planning']== \"Post-Planning\" \n",
    "        or df['Ten-Year Plan RD'] == 9999 \n",
    "        or pd.isnull(df['Pavement_PlanYear'])\n",
    "        or df['Last Year of Fiscal Year'] > TARGET_FY + 10 # last Year of FY greater than 2031 for SHSMP 2021\n",
    "        ): \n",
    "        return 'OK'\n",
    "    else: \n",
    "        if df['count_PCRScenarioNo'] != 1:\n",
    "            return 'Only one pavement APCR scenario is allowed per project and it needs to match the 2019 APCS data (APCR scenario #3299). Please update the pavement worksheet. AMT_ID: {}'.format(df['AMT_ID'])\n",
    "        elif df['first_PCRScenarioNo'] == '3299':  \n",
    "            #only allow one scenario per project and current valid scenario is 3299\n",
    "            return 'OK'\n",
    "        else: \n",
    "            return 'Please update the pavement worksheet to use 2019 APCS data (APCR scenario #3299). AMT_ID: {}'.format(df['AMT_ID'])\n",
    "    \n",
    "ck_name = 'Is the Pavement Worksheet using updated inventory and condition data (2019 APCS) for planned projects?'\n",
    "\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_Pav_APCS, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "enhanced-maria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Planning or Post-Planning</th>\n",
       "      <th>Ten-Year Plan RD</th>\n",
       "      <th>first_PCRScenarioNo</th>\n",
       "      <th>Pavement_PlanYear</th>\n",
       "      <th>Is the Pavement Worksheet using updated inventory and condition data (2019 APCS) for planned projects?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>21966</td>\n",
       "      <td>TYP</td>\n",
       "      <td>Planning</td>\n",
       "      <td>2021</td>\n",
       "      <td>3299</td>\n",
       "      <td>2029.0</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section Planning or Post-Planning  Ten-Year Plan RD  \\\n",
       "4003   21966     TYP                  Planning              2021   \n",
       "\n",
       "     first_PCRScenarioNo  Pavement_PlanYear  \\\n",
       "4003                3299             2029.0   \n",
       "\n",
       "     Is the Pavement Worksheet using updated inventory and condition data (2019 APCS) for planned projects?  \n",
       "4003                                                 OK                                                      "
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "###Manual Check#####\n",
    "\n",
    "\n",
    "AMT_ID = 21966\n",
    "# AMT_ID = 20476\n",
    "\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section','Planning or Post-Planning' ,\n",
    "'Ten-Year Plan RD' ,\n",
    "'first_PCRScenarioNo' ,\n",
    "'Pavement_PlanYear' ,\n",
    "'Is the Pavement Worksheet using updated inventory and condition data (2019 APCS) for planned projects?']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-quantum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-sheet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "scheduled-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Is the Drainage Worksheet using updated inventory and condition data (Sept 2021 or later) for planned projects?'\n",
    "\n",
    "#Attention: update this check every time we change SHSMP plan \n",
    "\n",
    "def ck_drain_data(df):\n",
    "    if (df['Planning or Post-Planning']== \"Post-Planning\" \n",
    "        or  df['Ten-Year Plan RD'] == 9999 \n",
    "        or df['No of Drainage Entries'] == 0\n",
    "        or df['Last Year of Fiscal Year'] > TARGET_FY + 10): # last Year of FY greater than 2031 for SHSMP 2021 \n",
    "        return 'OK'\n",
    "    else: \n",
    "        if datetime.strptime(df['Data Date_Drainage'], \"%m-%d-%Y\")  > datetime.strptime('09-01-2021', \"%m-%d-%Y\"):  \n",
    "            return 'OK'\n",
    "        else: \n",
    "            return 'Please update the drainage worksheet to use the current CIP data (09-01-2021 or later). AMT_ID: {}'.format(df['AMT_ID'])\n",
    "\n",
    "ck_name = 'Is the Drainage Worksheet using updated inventory and condition data (Sept 2021 or later) for planned projects?'\n",
    "\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_drain_data, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "loving-automation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Planning or Post-Planning</th>\n",
       "      <th>Ten-Year Plan RD</th>\n",
       "      <th>No of Drainage Entries</th>\n",
       "      <th>Data Date_Drainage</th>\n",
       "      <th>Is the Drainage Worksheet using updated inventory and condition data (Sept 2021 or later) for planned projects?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>20830</td>\n",
       "      <td>TYP</td>\n",
       "      <td>Planning</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section Planning or Post-Planning  Ten-Year Plan RD  \\\n",
       "3212   20830     TYP                  Planning              2019   \n",
       "\n",
       "      No of Drainage Entries Data Date_Drainage  \\\n",
       "3212                     0.0                NaN   \n",
       "\n",
       "     Is the Drainage Worksheet using updated inventory and condition data (Sept 2021 or later) for planned projects?  \n",
       "3212                                                 OK                                                               "
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Manual Check#####\n",
    "\n",
    "\n",
    "AMT_ID = 20830\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section','Planning or Post-Planning','Ten-Year Plan RD','No of Drainage Entries','Data Date_Drainage',\n",
    "'Is the Drainage Worksheet using updated inventory and condition data (Sept 2021 or later) for planned projects?'\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-cover",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "pacific-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Is the TMS Worksheet using updated inventory and condition data (June 2021 or later) for planned projects?'\n",
    "\n",
    "#Attention: update this check every time we change SHSMP plan \n",
    "\n",
    "def ck_TMS_data(df):\n",
    "    if (df['Planning or Post-Planning']== \"Post-Planning\" \n",
    "        or  df['Ten-Year Plan RD'] == 9999 \n",
    "        or pd.isnull(df['TMS_PlanYear'])\n",
    "         or df['Last Year of Fiscal Year'] > TARGET_FY + 10 # last Year of FY greater than 2031 for SHSMP 2021 \n",
    "       ): \n",
    "        return 'OK'\n",
    "    else: \n",
    "        if datetime.strptime(df['Data Date_TMS'], \"%m-%d-%Y\")  > datetime.strptime('06-01-2021', \"%m-%d-%Y\"):  \n",
    "            return 'OK'\n",
    "        else: \n",
    "            return 'Please update the TMS worksheet to use the current TMS inventory and condition data (06-01-2021 or later). AMT_ID: {}'.format(df['AMT_ID'])\n",
    "\n",
    "        \n",
    "ck_name = 'Is the TMS Worksheet using updated inventory and condition data (June 2021 or later) for planned projects?'\n",
    "\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_TMS_data, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "accepting-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###Manual Check#####\n",
    "\n",
    "\n",
    "# AMT_ID = 14058\n",
    "\n",
    "# STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "# df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section','Data Date_TMS' ,\n",
    "# 'Planning or Post-Planning' ,\n",
    "# 'Ten-Year Plan RD' ,\n",
    "# 'TMS_PlanYear'\n",
    "# ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-stephen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "continued-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ck_project_in_PID_WP(df):\n",
    "    if (df['Planning or Post-Planning']== \"Post-Planning\" \n",
    "        or  df['Ten-Year Plan RD'] == 9999 \n",
    "        or df['Activity (group)'] == \"Reservation\"): \n",
    "        return 'OK'\n",
    "    elif df['Long Lead'] != 'Y':# it is not a long lead\n",
    "        if (df['Last Year of Fiscal Year'] in [TARGET_FY + 6, TARGET_FY + 7] \n",
    "            and pd.isnull(df['PID Status'])):\n",
    "            return 'This project is in year 6 or 7 and must be added to the PID workplan.  Please work with the PID Unit to resolve. AMT_ID: {}'.format(df['AMT_ID'])\n",
    "        else: \n",
    "            return 'OK'\n",
    "    else: # it is a long lead\n",
    "        if df['PA&ED FY Number'] == TARGET_FY + 4 and pd.isnull(df['PID Status']):\n",
    "            return 'This long lead project has PA&ED allocation in year 4 and must be in the PID workplan. Please work with the PID Unit to resolve. AMT_ID: {}'.format(df['AMT_ID'])\n",
    "        else: \n",
    "            return 'OK'\n",
    "        \n",
    "        \n",
    "ck_name = 'Is this project in the Project Book but not in the PID Workplan?'\n",
    "\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_project_in_PID_WP, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "final-latitude",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Data Date_TMS</th>\n",
       "      <th>Planning or Post-Planning</th>\n",
       "      <th>Ten-Year Plan RD</th>\n",
       "      <th>TMS_PlanYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>20830</td>\n",
       "      <td>TYP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Planning</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section Data Date_TMS Planning or Post-Planning  \\\n",
       "3212   20830     TYP           NaN                  Planning   \n",
       "\n",
       "      Ten-Year Plan RD  TMS_PlanYear  \n",
       "3212              2019           NaN  "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Manual Check#####\n",
    "\n",
    "\n",
    "AMT_ID = 20830\n",
    "\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section','Data Date_TMS' ,\n",
    "'Planning or Post-Planning' ,\n",
    "'Ten-Year Plan RD' ,\n",
    "'TMS_PlanYear'\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-authorization",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "ahead-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ck_project_in_PID_WP_2(df):\n",
    "    if pd.isnull(df['PID Status']):\n",
    "        #it is not in the PID workplan, do not check\n",
    "        return 'OK'\n",
    "    elif df['Will this project be included in the Project Book?'] == 'No':\n",
    "        #it is in the PID workplan, but it is not in the project book, flag right away\n",
    "        return 'This project is in the PID workplan and must be added to year 6 or 7 in the Project Book. AMT_ID: {}'.format(df['AMT_ID'])\n",
    "    else:\n",
    "\n",
    "        #it is in the PID workplan and the project book\n",
    "        if (df['Planning or Post-Planning']== \"Post-Planning\"   #it is already programmed, not need to check further\n",
    "            or df['Activity (group)'] == \"Reservation\"  #it is a reservation project, it can be any fiscal year\n",
    "            or df['Last Year of Fiscal Year'] in [TARGET_FY + 6, TARGET_FY + 7] ## for non-reservation project, it has to be within 6/7 fiscal year of the 10 year plan\n",
    "            or (df['PA&ED FY Number'] == TARGET_FY + 4)): #if it is a long lead, the PA&ED FY needs to be the 4th year of the 10 year plan\n",
    "            return 'OK'\n",
    "        else: # \n",
    "            return 'This project is in the PID workplan and it is not in year 6 or 7. Please work with PID group to resolve this conflict. AMT_ID: {}'.format(df['AMT_ID'])\n",
    "        \n",
    "        \n",
    "ck_name = 'Is this project in the PID Workplan but not in the Project Book?'\n",
    "\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_project_in_PID_WP_2, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "dramatic-blond",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>PID Status</th>\n",
       "      <th>Last Year of Fiscal Year</th>\n",
       "      <th>Planning or Post-Planning</th>\n",
       "      <th>PA&amp;ED FY Number</th>\n",
       "      <th>Will this project be included in the Project Book?</th>\n",
       "      <th>Is this project in the PID Workplan but not in the Project Book?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4701</th>\n",
       "      <td>22809</td>\n",
       "      <td>TYP</td>\n",
       "      <td>Proposed</td>\n",
       "      <td>2031</td>\n",
       "      <td>Planning</td>\n",
       "      <td>2025</td>\n",
       "      <td>Yes</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section PID Status  Last Year of Fiscal Year  \\\n",
       "4701   22809     TYP   Proposed                      2031   \n",
       "\n",
       "     Planning or Post-Planning  PA&ED FY Number  \\\n",
       "4701                  Planning             2025   \n",
       "\n",
       "     Will this project be included in the Project Book?  \\\n",
       "4701                                                Yes   \n",
       "\n",
       "     Is this project in the PID Workplan but not in the Project Book?  \n",
       "4701                                                 OK                "
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Manual Check#####\n",
    "\n",
    "\n",
    "AMT_ID = 20830\n",
    "AMT_ID = 22887\n",
    "AMT_ID = 22809\n",
    "\n",
    "\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section','PID Status' ,'Last Year of Fiscal Year' ,\n",
    "'Planning or Post-Planning' ,'PA&ED FY Number' ,'Will this project be included in the Project Book?' ,\n",
    "ck_name]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-black",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-classic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "active-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ck_ped_bike_accessible(df):\n",
    "    if (df['Planning or Post-Planning']== \"Post-Planning\" \n",
    "        or  df['Ten-Year Plan RD']  == 9999 \n",
    "        or df['ck_ActID_H32'] == 'OK'\n",
    "       ):  \n",
    "        return 'OK'\n",
    "    else: \n",
    "        return 'Please add activity H32 (Is any Location Within the Project Limits Ped/Bike Accessible?) to the Performance Tab for the primary location with appropriate response. AMT_ID: {}'.format(df['AMT_ID'])\n",
    "        \n",
    "ck_name = 'For all planned projects, does the Performance Tab indicate If any location within the project limits Ped/Bike accessible?'\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_ped_bike_accessible, axis = 1)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-level",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "closed-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Does the CCA date in the AM Tool match PRSM?'\n",
    "\n",
    "def ck_CCA_date(df):\n",
    "    if (df['Section'] == \"CCA\") and (df['CCA Date Miilestone (M600)'] != df['Cca Finish Date']):\n",
    "        return 'For {} section in project {}: The CCA date does not match PRSM data. Please correct in AMTool or PRSM.'.format(df['Section'],df['AMT_ID'],)\n",
    "    else:\n",
    "        return 'OK'\n",
    "\n",
    "ck_name = 'Does the CCA date in the AM Tool match PRSM?'\n",
    "\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_CCA_date, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "second-terrain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Cca Finish Date</th>\n",
       "      <th>CCA Date Miilestone (M600)</th>\n",
       "      <th>Does the CCA date in the AM Tool match PRSM?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9182</td>\n",
       "      <td>CCA</td>\n",
       "      <td>10-09-2020</td>\n",
       "      <td>10-09-2020</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AMT_ID Section Cca Finish Date CCA Date Miilestone (M600)  \\\n",
       "19    9182     CCA      10-09-2020                 10-09-2020   \n",
       "\n",
       "   Does the CCA date in the AM Tool match PRSM?  \n",
       "19                                           OK  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Manual Check#####\n",
    "\n",
    "AMT_ID = 20830\n",
    "AMT_ID = 9182\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section','Cca Finish Date' ,\n",
    "'CCA Date Miilestone (M600)','Does the CCA date in the AM Tool match PRSM?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-pacific",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "animated-fleet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data['Cca Percent Comp'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "permanent-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Does the CCA section including performance need to be completed?  (Applies to projects with CCA date on or after July 1, 2020)'\n",
    "\n",
    "def ck_CCA_complete(df):\n",
    "    if pd.isnull(df['Cca Finish Date']):\n",
    "        return 'OK'\n",
    "    \n",
    "    if df['Cca Percent Comp'] == 100:\n",
    "        if (datetime.strptime(df['Cca Finish Date'], \"%m-%d-%Y\")  > datetime.strptime('06-30-2020' , \"%m-%d-%Y\")\n",
    "            and datetime.strptime(df['Cca Finish Date'], \"%m-%d-%Y\") < datetime.strptime(TARGETDATE, \"%m-%d-%Y\")\n",
    "           ):\n",
    "            if df['Section'] == \"CCA\" and df['perf_entry_count']>0:\n",
    "                return 'OK'\n",
    "            else: \n",
    "                return 'Please complete the CCA band or the Performance Tab or both. AMT_ID: {}'.format(df['AMT_ID'])\n",
    "        else:\n",
    "            return 'OK'\n",
    "    elif df['Section'] == \"CCA\":\n",
    "        return 'Please remove CCA Date. According to PRSM CCA is not Complete. AMT_ID: {}'.format(df['AMT_ID'])\n",
    "    else:\n",
    "        return 'OK'\n",
    "\n",
    "    \n",
    "ck_name = 'Does the CCA section including performance need to be completed?  (Applies to projects with CCA date on or after July 1, 2020)'\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_CCA_complete, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "individual-denial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>Cca Finish Date</th>\n",
       "      <th>perf_entry_count</th>\n",
       "      <th>Does the CCA section including performance need to be completed?  (Applies to projects with CCA date on or after July 1, 2020)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>13529</td>\n",
       "      <td>PRG</td>\n",
       "      <td>08-17-2021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Please complete the CCA band or the Performanc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AMT_ID Section Cca Finish Date  perf_entry_count  \\\n",
       "364   13529     PRG      08-17-2021               1.0   \n",
       "\n",
       "    Does the CCA section including performance need to be completed?  (Applies to projects with CCA date on or after July 1, 2020)  \n",
       "364  Please complete the CCA band or the Performanc...                                                                              "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "###Manual Check#####\n",
    "\n",
    "\n",
    "AMT_ID = 20830\n",
    "# AMT_ID = 17266\n",
    "\n",
    "AMT_ID = 13529\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section','Cca Finish Date' ,'perf_entry_count',\n",
    "                                                         ck_name\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-tattoo",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "sixth-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Does the primary asset performance match CTIPS?  (Applies to projects with RTL 25/26 and later)'\n",
    "\n",
    "ck_name = 'Does the primary asset performance match CTIPS?  (Applies to projects with RTL 25/26 and later)'\n",
    "\n",
    "df_SHOPP_raw_data[ck_name] = 'OK'   #df_SHOPP_raw_data.apply(ck_add_PPC_amendment_date, axis = 1) \n",
    "# TODO discuss this with mara later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "level-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data.shape\n",
    "\n",
    "df_SHOPP_raw_data_copy = df_SHOPP_raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "narrative-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SHOPP_raw_data = df_SHOPP_raw_data_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-advantage",
   "metadata": {},
   "source": [
    "<a id='InteralChecks'></a>\n",
    "## Internal Checks\n",
    "* Does amendment date needs to be removed?\n",
    "* Need to add Resource in the PID workplan?\n",
    "* PRG section needs amendment date?\n",
    "* PPC section needs amendment date?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "nonprofit-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does amendment date needs to be removed?\n",
    "\n",
    "def ck_remove_PRG_amendment_date(df):\n",
    "    if pd.notnull(df['Candidate Type']): #it is on the candidate list, skip check\n",
    "        return 'OK'\n",
    "    if pd.isnull(df['EFIS_Program']) and pd.notnull(df['SHOPP Amendment Date']):\n",
    "        return 'For project {}: Please remove the SHOPP amendment date in PRG section'.format(df['AMT_ID'],)\n",
    "    else:\n",
    "        return 'OK'\n",
    "    \n",
    "ck_name = 'Does amendment date needs to be removed?'\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_remove_PRG_amendment_date, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "bulgarian-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ###Manual Check#####\n",
    "\n",
    "\n",
    "# AMT_ID = 20830\n",
    "# AMT_ID = 16439\n",
    "\n",
    "\n",
    "\n",
    "# STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "# df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section','Cca Finish Date' ,'perf_entry_count',\n",
    "# 'Does the CCA section including performance need to be completed?  (Applies to projects with CCA date on or after July 1, 2020)'\n",
    "# ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "dangerous-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to add Resource in the PID workplan?\n",
    "\n",
    "def ck_PID_resource_date(df):\n",
    "    if pd.notnull(df['EFIS_Program']) and pd.isnull(df['Resourced In PID WP']):\n",
    "        return 'For project {}: Please enter the resourced PID workplan.'.format(df['AMT_ID'],)\n",
    "    else:\n",
    "        return 'OK'\n",
    "    \n",
    "ck_name = 'Need to add resource in the PID workplan?'\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_PID_resource_date, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "bulgarian-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRG section needs amendment date?\n",
    "\n",
    "def ck_add_PRG_amendment_date(df):\n",
    "    if pd.notnull(df['EFIS_Program']) and pd.isnull(df['SHOPP Amendment Date']):\n",
    "        return 'For project {}: Please add the SHOPP amendment date in PRG section'.format(df['AMT_ID'],)\n",
    "    else:\n",
    "        return 'OK'\n",
    "    \n",
    "ck_name = 'PRG section needs amendment date?'\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_add_PRG_amendment_date, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "unnecessary-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPC section needs amendment date?\n",
    "\n",
    "#district should not fill the PPC section if the project is not programmed with future amendment date in PRG section\n",
    "\n",
    "def ck_add_PPC_amendment_date(df):\n",
    "    if (df['PCR Total Cost ($K)'] == df['Total Capital & Support Cost'] \n",
    "        and df['PCR RTL'] ==  df['FY'] \n",
    "       and pd.isnull(df['PCR SHOPP Amendment Date'])\n",
    "       ):\n",
    "        return 'For project {}: Please review the PPC section and add the SHOPP amendment date.'.format(df['AMT_ID'],)\n",
    "    else:\n",
    "        return 'OK'\n",
    "    \n",
    "ck_name = 'PPC section needs amendment date?'\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_add_PPC_amendment_date, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "neutral-niger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>FY</th>\n",
       "      <th>PCR RTL</th>\n",
       "      <th>Total Capital &amp; Support Cost</th>\n",
       "      <th>PCR SHOPP Amendment Date</th>\n",
       "      <th>PCR Total Cost ($K)</th>\n",
       "      <th>PPC section needs amendment date?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>19336</td>\n",
       "      <td>PRG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025/26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26500.0</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section   FY  PCR RTL  Total Capital & Support Cost  \\\n",
       "2249   19336     PRG  NaN  2025/26                           NaN   \n",
       "\n",
       "     PCR SHOPP Amendment Date  PCR Total Cost ($K)  \\\n",
       "2249                      NaN              26500.0   \n",
       "\n",
       "     PPC section needs amendment date?  \n",
       "2249                                OK  "
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Manual Check#####\n",
    "\n",
    "AMT_ID = 19336\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section','FY' ,'PCR RTL' ,\n",
    "'Total Capital & Support Cost' ,'PCR SHOPP Amendment Date' ,'PCR Total Cost ($K)','PPC section needs amendment date?'                                             \n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-facing",
   "metadata": {},
   "source": [
    "<a id='NewChecks'></a>\n",
    "## New checks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "adjustable-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check comments about ActID of E55 and E58\n",
    "#if ActID == E55 and E58 and the comments include: 'HQ added the activity and District needs to review it.', mark the project\n",
    "\n",
    "def filter_target_comment(df, target_comment):\n",
    "    if target_comment in str(df['Comment']):\n",
    "        return target_comment\n",
    "    else: \n",
    "        return 'OK'\n",
    "\n",
    "target_comment = 'HQ added the activity and District needs to review it.'\n",
    "df_perf_raw_data['Activity Has Safety Comment?'] = df_perf_raw_data.apply(filter_target_comment, args = [target_comment], axis = 1)\n",
    "\n",
    "temp = df_perf_raw_data[df_perf_raw_data['ActID'].isin(['E55','E58'])]\n",
    "\n",
    "\n",
    "temp1 = temp.groupby(['AMT_ID', 'Section'])['Activity Has Safety Comment?'].agg(list).reset_index()\n",
    "\n",
    "#bookmark\n",
    "def ck_Safety_Comments(df):\n",
    "    if 'HQ added the activity and District needs to review it.' in df['Activity Has Safety Comment?']:\n",
    "        return 'HQ added the activity and District needs to review it.'\n",
    "    else:\n",
    "        return 'OK'\n",
    "    \n",
    "temp1['Check Safety Comment'] = temp1.apply(ck_Safety_Comments,axis = 1)\n",
    "\n",
    "\n",
    "df_SHOPP_raw_data.drop(['Check Safety Comment'],  axis='columns', inplace=True, errors='ignore')\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp1[['AMT_ID', 'Section', 'Check Safety Comment']], \n",
    "                             how = 'left', left_on = ['AMT_ID', 'Section', ], right_on = ['AMT_ID', 'Section'])\n",
    "\n",
    "\n",
    "#TODO\n",
    "#remove the check comments for TYP=9999\n",
    "df_SHOPP_raw_data['Check Safety Comment'] = df_SHOPP_raw_data.apply(\n",
    "    lambda df: 'OK' if df['Ten-Year Plan RD'] == 9999 else df['Check Safety Comment'], axis = 1)\n",
    "\n",
    "df_SHOPP_raw_data['Check Safety Comment'].fillna('OK', inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-trade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "ordered-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The attached projects have TMS IDs that do not match the new data we are uploading the AM tool.\n",
    "# For projects in the 5-year POR, Please create a data check that check if project in the list attaches is using the 11/30/2021 data for the TMS worksheet .\n",
    "ck_name = 'TMS data update needed for the project?'\n",
    "\n",
    "def ck_TMS_dataupdate(df):\n",
    "    if (df['Include 5-year POR?'] == 'Yes' \n",
    "        and df['AMT_ID'] in df_TMS_Datachange['AMT_ID'].values \n",
    "        and datetime.strptime(df['Data Date_TMS'], \"%m-%d-%Y\") < datetime.strptime(TMS_Data_Date, \"%m-%d-%Y\")\n",
    "        ):\n",
    "        return 'Please update the TMS worksheet to use the current TMS inventory and condition data ({}). AMT_ID: {}'.format(df['AMT_ID'], TMS_Data_Date)\n",
    "\n",
    "    return 'OK'    \n",
    "\n",
    "df_SHOPP_raw_data[ck_name] = df_SHOPP_raw_data.apply(ck_TMS_dataupdate, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "sunrise-analyst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-30-2021\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ID</th>\n",
       "      <th>Section</th>\n",
       "      <th>FY</th>\n",
       "      <th>Data Date_TMS</th>\n",
       "      <th>Include 5-year POR?</th>\n",
       "      <th>TMS data update needed for the project?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>20248</td>\n",
       "      <td>TYP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06-30-2021</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Please update the TMS worksheet to use the cur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AMT_ID Section   FY Data Date_TMS Include 5-year POR?  \\\n",
       "2924   20248     TYP  NaN    06-30-2021                 Yes   \n",
       "\n",
       "                TMS data update needed for the project?  \n",
       "2924  Please update the TMS worksheet to use the cur...  "
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Manual Check#####\n",
    "\n",
    "# df_SHOPP_raw_data[(df_SHOPP_raw_data['Include 5-year POR?'] == 'Yes') & (df_SHOPP_raw_data['AMT_ID'].isin(df_TMS_Datachange['AMT_ID'].values))]\n",
    "\n",
    "AMT_ID = 20248\n",
    "\n",
    "STU = df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID]['Section'].iloc[0]\n",
    "print(TMS_Data_Date)\n",
    "df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] ==AMT_ID][['AMT_ID','Section','FY' ,'Data Date_TMS','Include 5-year POR?',ck_name                                            \n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-workstation",
   "metadata": {},
   "source": [
    "\n",
    "<a id='Check_Flag'></a>\n",
    "\n",
    "## Check Flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "turkish-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ck_cols = ['Does project cost exceed Minor Program limits ($1,250K)?',\n",
    "#             'Is Major Damage or Mobility Subcategory Identified?',\n",
    "            'Is Planned Project RTL in a FY that can be programmed in future SHOPP cycles?',\n",
    "            'Is the PID cycle consistent with the project status and RTL?',\n",
    "            'Is Project Initiation Proposal (PIP) uploaded? Applies to projects with Active and  Complete PIDs.',\n",
    "            'Is the Conceptual Cost Estimate (CCE) uploaded? (Applies to all project in the 5-year POR)',\n",
    "            'Are the Long Lead Project Cost and RTL fields complete and consistent?',\n",
    "            'Is District Director Approval Date in the Future?',\n",
    "            'Is the EA or Project ID repeated in the AM tool?',\n",
    "            'Does project include performance for each location?',\n",
    "            'Is Performance tab Complete?',\n",
    "            'Does the performance tab include one or more activities related to the Activity Category?',\n",
    "            'Are all Project Locations and Postmiles Valid?',\n",
    "            'Is Drainage Worksheet Complete (2024/25 RTL and after)?',\n",
    "            'Is Pavement Worksheet Complete (2024/25 RTL and after)?',\n",
    "            'Is TMS Worksheet Complete (2024/25 RTL and after)?', \n",
    "                                    \n",
    "            'Are all conditions selected for bridge replacements?',\n",
    "            'Does Bridge Worksheet need updates?',\n",
    "            'Does the Plan Year in the Pavement Worksheet match the Project RTL?',\n",
    "#             'Is the Pavement Work Limits Direction in the Pavement Worksheet complete?',\n",
    "            'Does the RTL Plan Year in the TMS Worksheet match the Project RTL?',\n",
    "            'Does SHOPP project data in the AM Tool data match CTIPS (RTL and/or Cost)?',\n",
    "#             'Is PID completed and uploaded for current SHOPP Candidates?',\n",
    "\n",
    "#             'LL not in POR', obseleted\n",
    "\n",
    "            'Is Pavement limits repeating in the same project?',\n",
    "            'Is Bridge repeating in the same project?',\n",
    "            'Is TMS Asset repeating in the same project?',\n",
    "           'Is Culvert repeating in the same project?',\n",
    "            \n",
    "            #modified checks\n",
    "            'Is a pavement segment in a planned project repeated in another project in the Project Book?',\n",
    "            'Is a bridge in a planned project repeated in another project in the Project Book?',\n",
    "            'Is a TMS in a planned project repeated in another project in the Project Book?',\n",
    "            'Is a culvert in a planned project repeated in another project in the Project Book?',\n",
    "           \n",
    "           \n",
    "            'Is the Pavement Worksheet using updated inventory and condition data (2019 APCS) for planned projects?',\n",
    "            'Is the Drainage Worksheet using updated inventory and condition data (Sept 2021 or later) for planned projects?',\n",
    "            'Is the TMS Worksheet using updated inventory and condition data (June 2021 or later) for planned projects?',\n",
    "            'Is this project in the Project Book but not in the PID Workplan?',\n",
    "            'Is this project in the PID Workplan but not in the Project Book?',\n",
    "            'For all planned projects, does the Performance Tab indicate If any location within the project limits Ped/Bike accessible?',\n",
    "           \n",
    "           #new checks\n",
    "           'Check Safety Comment', #added in 12-2021\n",
    "           'TMS data update needed for the project?',\n",
    "           \n",
    "           'Does the CCA date in the AM Tool match PRSM?',\n",
    "            'Does the CCA section including performance need to be completed?  (Applies to projects with CCA date on or after July 1, 2020)',\n",
    "            #TODO:\n",
    "           # 'Does the primary asset performance match CTIPS?  (Applies to projects with RTL 25/26 and later)',\n",
    "        \n",
    "          ]\n",
    "\n",
    "#filter out the projects without check flags\n",
    "def calc_flag(df, cols):\n",
    "    cnt = 0\n",
    "    for c in cols:\n",
    "        if df[c] !='OK': \n",
    "            cnt += 1\n",
    "    if cnt > 0: \n",
    "        return 'Flagged for Data Check'\n",
    "    else:\n",
    "        return 'Pass Data Check'\n",
    "\n",
    "df_SHOPP_raw_data['DataCheckFlag'] = df_SHOPP_raw_data.apply(calc_flag, args=(ck_cols,), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "external-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AMT_ID = 20004\n",
    "# # AMT_ID = 13667\n",
    "# temo_cols =  ck_cols+ ['DataCheckFlag']\n",
    "\n",
    "# df_SHOPP_raw_data[df_SHOPP_raw_data['AMT_ID'] == AMT_ID ][temo_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "assigned-browse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5204, 216)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SHOPP_raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-astrology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dominican-winning",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<a id='Project_missing_AMT_ID'></a>\n",
    "\n",
    "### Project missing AMT_ID (SHOPP ID) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "guilty-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp = pd.merge(df_program, df_SHOPP_raw_data[['EFIS']],\n",
    "               how ='left', left_on= 'EFIS_Program', right_on='EFIS')\n",
    "\n",
    "temp['FY_Program'] = temp['FY'].str[-2:].astype(int)+2000\n",
    "\n",
    "temp['Check Description'] = 'Does the District need to create a SHOPP ID in the AM Tool?'\n",
    "\n",
    "def ck_missing_EFIS(df):\n",
    "    if pd.isnull(df['EFIS']): \n",
    "        return 'Please create a SHOPP Project Record in AMT for Project ID ({}), including appropriate activities in the performance tab.'.format(df['EFIS_Program']) \n",
    "    else:\n",
    "        return 'OK' \n",
    "    \n",
    "    \n",
    "temp['Check Summary'] = temp.apply(ck_missing_EFIS, axis = 1)\n",
    "\n",
    "\n",
    "out_cols = ['Dist', 'EA','County','EFIS_Program', 'FY_Program', 'Check Description', 'Check Summary']\n",
    "\n",
    "project_missing_AMT_ID = temp[(temp['FY_Program']> 2019) & (temp['EFIS'].isna())][out_cols] # please change the logic for hard code all project with after RTL 18/19 and programmed should be in the tool. We missed this project in Q4\n",
    "\n",
    "project_missing_AMT_ID.columns = ['District', 'EA', 'County', 'EFIS', 'Last Year of Fiscal Year', 'Check Description', 'Check Summary']\n",
    "\n",
    "dict_rename = {\n",
    "    'Dist':'District',\n",
    "    'EFIS_Program':'EFIS', \n",
    "    'FY_Program': 'Last Year of Fiscal Year', \n",
    "}\n",
    "\n",
    "# bookmark\n",
    "\n",
    "project_missing_AMT_ID = project_missing_AMT_ID.rename(dict_rename, axis = 1)\n",
    "\n",
    "project_missing_AMT_ID['Will this project be included in the Project Book?'] = 'Yes'\n",
    "project_missing_AMT_ID['Planning or Post-Planning'] = 'Planning'\n",
    "project_missing_AMT_ID['Section'] = 'TYP'\n",
    "project_missing_AMT_ID['AMT_ID'] = 0\n",
    "project_missing_AMT_ID['Data_Date']= TARGETDATE\n",
    "project_missing_AMT_ID['Data_HourMinute'] = DATA_HHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "ultimate-elevation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ###Manual Check#####\n",
    "\n",
    "# EFIS_Program = 1021000191\n",
    "\n",
    "\n",
    "# temp[temp['EFIS_Program'] ==EFIS_Program][['EFIS','EFIS_Program','Dist', 'EA','County', 'FY_Program', 'Check Description', 'Check Summary']]\n",
    "\n",
    "# # temp[(temp['FY_Program']> TARGET_FY + 1) & (temp['EFIS'].isna())][out_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "atomic-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_missing_AMT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-storm",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-harrison",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "front-might",
   "metadata": {},
   "source": [
    "<a id='Export_Table1'></a>\n",
    "# Export Check Summary and Project Missing SHOPP ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "color-container",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "file_export_log = open(LOG_FILE, \"a\")  # append mode\n",
    "file_export_log.write(\"#####{}, time(HHMM):{} \\n\".format(TARGETDATE, DATA_HHMM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "registered-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SHOPP_raw_data['Data_HourMinute'] = DATA_HHMM\n",
    "df_SHOPP_raw_data['Data_Date'] = TARGETDATE\n",
    "\n",
    "# df_SHOPP_raw_data['Data_TimeStamp'] = Data_TimeStamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "robust-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export all projects with all checks in matrix\n",
    "out_cols = ['AMT_ID','Section', \n",
    "            'District',\n",
    "            'County',\n",
    "            'EA','EFIS',\n",
    "            'Planning or Post-Planning',\n",
    "            'Last Year of Fiscal Year',\n",
    "            'AM Tool RTL (Section in Use)',\n",
    "            'Advertised Year',\n",
    "            'Project Cost ($K)', \n",
    "            'Will this project be included in the Project Book?',\n",
    "            'DataCheckFlag',\n",
    "            'Ten-Year Plan RD',\n",
    "            \n",
    "            #internal check columns\n",
    "            'Does amendment date needs to be removed?',\n",
    "            'Need to add resource in the PID workplan?',\n",
    "            'PRG section needs amendment date?',\n",
    "            'PPC section needs amendment date?',\n",
    "            \n",
    "            'Data_Date',\n",
    "            'Data_HourMinute',\n",
    "#             'Data_TimeStamp',\n",
    "                    ]\n",
    "\n",
    "out_cols.extend(ck_cols)\n",
    "\n",
    "\n",
    "filename = 'projectbook_datachecks_matrix'\n",
    "\n",
    "try: \n",
    "    df_SHOPP_raw_data[out_cols].to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "    shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename))\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "global-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data['AMT_ID'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "angry-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(ck_cols) - len(set(ck_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "split-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#table 1\n",
    "\n",
    "df_melted = pd.melt(df_SHOPP_raw_data, \n",
    "                    id_vars=['AMT_ID'], \n",
    "                    value_vars=ck_cols, var_name = 'Check Description')\n",
    "\n",
    "df_melted.columns = ['AMT_ID','Check Description','Check Summary']\n",
    "df_melted_filtered = df_melted[df_melted['Check Summary']!= 'OK']\n",
    "\n",
    "\n",
    "df_out = pd.merge(df_melted_filtered, df_SHOPP_raw_data[['AMT_ID','Section', \n",
    "            'District',\n",
    "            'County',\n",
    "            'EA','EFIS',\n",
    "            'Planning or Post-Planning',\n",
    "            'Advertised Year',\n",
    "            'AM Tool RTL (Section in Use)', \n",
    "            'Project Cost ($K)', \n",
    "            'Will this project be included in the Project Book?',\n",
    "            'Data_Date',                                             \n",
    "            'Data_HourMinute',\n",
    "#             'Data_TimeStamp',                                           \n",
    "            ]],\n",
    "        how = 'left', left_on = 'AMT_ID', right_on = 'AMT_ID')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "vanilla-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine check tables\n",
    "df_out =  pd.concat([df_out, project_missing_AMT_ID], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "exterior-catering",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 687it [00:00, 12051.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'Extract' does not exist in extract projectbook_datachecks_punchlist.hyper, creating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing projectbook_datachecks_punchlist.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "## Export to csv\n",
    "filename = 'projectbook_datachecks_punchlist'\n",
    "try: \n",
    "    df_out.to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "    shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename))\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "\n",
    "\n",
    "\n",
    "#table 1\n",
    "\n",
    "hyper_name = 'projectbook_datachecks_punchlist.hyper'\n",
    "\n",
    "try: \n",
    "    uf.publish_datasource(df_out, hyper_name)\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}'.format(hyper_name)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}'.format(hyper_name)))\n",
    "\n",
    "\n",
    "#table 1a\n",
    "filename = 'projectlist_tobecreatedinAMT'\n",
    "\n",
    "try: \n",
    "    project_missing_AMT_ID.to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "    shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename))\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "liberal-perth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['12-22-2021'], dtype=object)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_out['Data_Date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "hindu-launch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([818], dtype=int64)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_out['Data_HourMinute'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-provincial",
   "metadata": {},
   "source": [
    "<a id='Export_internal_check_summary'></a>\n",
    "\n",
    "### export internal check summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "solar-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export internal check summary\n",
    "out_cols = ['AMT_ID','Section', \n",
    "            'District',\n",
    "            'County',\n",
    "            'EA_',\n",
    "            \n",
    "            #internal check columns\n",
    "'Does amendment date needs to be removed?',\n",
    "'Need to add resource in the PID workplan?',\n",
    "'PRG section needs amendment date?',\n",
    "'PPC section needs amendment date?',\n",
    "            'Data_Date',\n",
    "            'Data_HourMinute',\n",
    "#             'Data_TimeStamp',\n",
    "                    ]\n",
    "\n",
    "filename = 'HQ_TAM_actionitems'\n",
    "\n",
    "try: \n",
    "    df_SHOPP_raw_data[out_cols].to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "    shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_OUTPUT_FOLDER,filename))\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_OUTPUT_FOLDER, filename)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_OUTPUT_FOLDER, filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-plenty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "north-freeze",
   "metadata": {},
   "source": [
    "<a id='Export_ProjectBook'></a>\n",
    "\n",
    "# Export Project Book\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "metropolitan-springer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 1026it [00:00, 10259.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'Extract' does not exist in extract projectbook_draft.hyper, creating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 1927it [00:00, 10304.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing projectbook_draft.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "out_cols = ['Data_Date',\n",
    "            'AMT_ID',\n",
    "            'District',\n",
    "            'County Name',\n",
    "            'Route',\n",
    "            'Begin Postmile',\n",
    "            'End Postmile',\n",
    "\n",
    "            'Activity',\n",
    "            'Planning or Post-Planning',\n",
    "            'Advertised Year',\n",
    "            'Total Project Cost ($K)',\n",
    "            'SB-1 Priority',\n",
    "            'EFIS',\n",
    "            'EA_',\n",
    "            'MPO/RTPA',\n",
    "            'Section',\n",
    "            'Active Long Lead',\n",
    "\n",
    "            'Nickname',\n",
    "            'Data_HourMinute',\n",
    "#             'Data_TimeStamp',\n",
    "           ]\n",
    "\n",
    "df_projectbook_filtered = df_SHOPP_raw_data[df_SHOPP_raw_data['Will this project be included in the Project Book?']=='Yes'][out_cols]\n",
    "\n",
    "\n",
    "filename = 'projectbook_draft'\n",
    "\n",
    "try: \n",
    "    df_projectbook_filtered.to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "    shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename))\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "\n",
    "\n",
    "hyper_name = 'projectbook_draft.hyper'\n",
    "\n",
    "try: \n",
    "    uf.publish_datasource(df_projectbook_filtered, hyper_name)\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}'.format(hyper_name)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}'.format(hyper_name)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-salmon",
   "metadata": {},
   "source": [
    "\n",
    "## Export Project Book With Detailed Info For Internal Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "joint-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_projectbook_filtered = df_SHOPP_raw_data[df_SHOPP_raw_data['Will this project be included in the Project Book?']=='Yes'][out_cols]\n",
    "\n",
    "temp = df_pm_check[df_pm_check['Location']=='Primary'][[\n",
    "    'AMT_ID','Section','BackPMLatitude', 'BackPMLongitude',\n",
    "       'BackPMAssemblyDistrict', 'BackPMCongressDistrict',\n",
    "       'BackPMSenateDistrict']]\n",
    "\n",
    "df_projectbook_internal = pd.merge(df_projectbook_filtered, temp, \n",
    "                                   how='left', left_on = ['AMT_ID','Section'], right_on = ['AMT_ID','Section'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "rocky-whale",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_projectbook_filtered['AMT_ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "furnished-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_activity(df):\n",
    "    group_dict = {\n",
    "        'Bridge':'Bridge',\n",
    "        'Bridge - Deck':'Bridge',\n",
    "        'Bridge - Health':'Bridge',\n",
    "        'Proactive Safety':'Proactive Safety',\n",
    "        'Safety - Collision Reduction':'Proactive Safety',\n",
    "        'Reactive Safety':'Reactive Safety',\n",
    "        'Safety - Monitoring':'Reactive Safety',\n",
    "        'Safety - SI':'Reactive Safety',\n",
    "        'Sustainability/Climate Change':'Sustainability',\n",
    "        'Facilities':'Facilities',\n",
    "        'Facilities - Office Buildings':'Facilities',\n",
    "        'Advance Mitigation/Mitigation':'Advance Mitigation',        \n",
    "    }\n",
    "    if df['Activity'] in group_dict.keys():\n",
    "        return group_dict[df['Activity']]\n",
    "    else:\n",
    "        return df['Activity']\n",
    "df_projectbook_internal['Activity_InternalProjectBook'] = df_projectbook_internal.apply(group_activity, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "cloudy-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cols = ['Data_Date', 'AMT_ID', 'District', 'County Name', 'Route',\n",
    "       'Begin Postmile', 'End Postmile', 'Activity_InternalProjectBook',\n",
    "       'Planning or Post-Planning', 'Advertised Year',\n",
    "       'Total Project Cost ($K)', 'SB-1 Priority', 'EFIS', 'EA_', 'MPO/RTPA',\n",
    "       'Section', 'Active Long Lead', 'Nickname', 'BackPMLatitude',\n",
    "       'BackPMLongitude', 'BackPMAssemblyDistrict', 'BackPMCongressDistrict',\n",
    "       'BackPMSenateDistrict','Data_HourMinute',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "lightweight-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df_projectbook_internal[out_cols]\n",
    "filename = 'projectbook_internal'\n",
    "\n",
    "try: \n",
    "    df_out.to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "    shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_OUTPUT_FOLDER,filename))\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_OUTPUT_FOLDER, filename)))\n",
    "    \n",
    "except:\n",
    "#     print('failed')\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_OUTPUT_FOLDER, filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "threatened-arctic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "increasing-grill",
   "metadata": {},
   "source": [
    "<a id='Export_repated_EA_EFIS'></a>\n",
    "\n",
    "### Export repeated EA and EFIS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "iraqi-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "duplicate_EA['Data_Date'] = TARGETDATE\n",
    "duplicate_EA['Data_HourMinute'] = DATA_HHMM\n",
    "\n",
    "temp1 = pd.merge(duplicate_EA, df_SHOPP_HM_MB[['Unique EA','District']].drop_duplicates(), how = 'left', left_on = 'Unique EA', right_on = 'Unique EA')\n",
    "temp1 = temp1.sort_values(by = ['District','Unique EA'])[['District','Unique EA','AMT_ID List_repeated Unique EA']]\n",
    "# temp1.shape\n",
    "\n",
    "df_out = temp1\n",
    "filename = 'repeated_EA'\n",
    "\n",
    "try: \n",
    "    df_out.to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "    shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_OUTPUT_FOLDER,filename))\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_OUTPUT_FOLDER, filename)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_OUTPUT_FOLDER, filename)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "freelance-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = pd.merge(duplicate_EFIS, df_SHOPP_HM_MB[['EFIS','District']].drop_duplicates(), how = 'left', left_on = 'EFIS', right_on = 'EFIS')\n",
    "temp1 = temp1.sort_values(by = ['District','EFIS'])[['District','EFIS','AMT_ID List_repeated EFIS']]\n",
    "\n",
    "\n",
    "# duplicate_EFIS.to_csv('.\\output\\info_p3t2_duplicate_EFIS.csv')\n",
    "\n",
    "df_out = temp1\n",
    "filename = 'repeated_EFIS'\n",
    "\n",
    "try: \n",
    "    df_out.to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "    shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_OUTPUT_FOLDER,filename))\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_OUTPUT_FOLDER, filename)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_OUTPUT_FOLDER, filename)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-republican",
   "metadata": {},
   "source": [
    "<a id='Export_repeated_assets'></a>\n",
    "\n",
    "### Export repeated assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "competitive-siemens",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 42it [00:00, 13994.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'Extract' does not exist in extract repeated_assets.hyper, creating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing repeated_assets.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "df_duplicated_asset['Data_HourMinute'] = DATA_HHMM \n",
    "df_duplicated_asset['Data_Date'] = TARGETDATE\n",
    "\n",
    "out_col =['Asset_Type','Asset_ID', 'AMT_ID', 'Section', 'District', 'EA',\n",
    "       'Last Year of Fiscal Year', 'Type of Exception','Data_Date','Data_HourMinute' ]\n",
    "\n",
    "filename = 'repeatedassets_inprojectbook'\n",
    "df_out = df_duplicated_asset[out_col]\n",
    "\n",
    "\n",
    "try: \n",
    "    df_out.to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "    shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename))\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "\n",
    "\n",
    "hyper_name = 'repeated_assets.hyper'\n",
    "\n",
    "try: \n",
    "    uf.publish_datasource(df_out, hyper_name)\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}'.format(hyper_name)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}'.format(hyper_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-patrick",
   "metadata": {},
   "source": [
    "<a id='Export_KeyDates'></a>\n",
    "\n",
    "### Export Key Dates for Project Book Check Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "painful-overview",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 1it [00:00, 1009.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing KeyDates.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "df_out = df_GlobalParameters[['PID Workplan Data Date', 'QMRS Data Date', 'CTC Meeting Date',]]\n",
    "\n",
    "hyper_name = 'KeyDates.hyper'\n",
    "\n",
    "try: \n",
    "    uf.publish_datasource(df_out, hyper_name)\n",
    "    file_export_log.write(\"Succeeded: {} \\n\".format('{}'.format(hyper_name)))\n",
    "except:\n",
    "    file_export_log.write(\"Failed: {} \\n\".format('{}'.format(hyper_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-check",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "interested-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_export_log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-contents",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-vatican",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "resistant-isaac",
   "metadata": {},
   "source": [
    "\n",
    "<a id='FinalCleanUp'></a>\n",
    "## Final Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "understanding-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#clean up tableau publishing log file\n",
    "\n",
    "import os\n",
    "import glob\n",
    "# get a recursive list of file paths that matches pattern\n",
    "fileList = glob.glob('./*.log')\n",
    "# Iterate over the list of filepaths & remove each file.\n",
    "for filePath in fileList:\n",
    "    try:\n",
    "        os.remove(filePath)\n",
    "    except OSError:\n",
    "        print(\"Error while deleting file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "durable-sponsorship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed : 69.23368906974792 seconds\n"
     ]
    }
   ],
   "source": [
    "end_time =  time.time()\n",
    "elapsed = end_time - start_time\n",
    "print('time elapsed : {} seconds'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "better-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in df_SHOPP_raw_data.columns:\n",
    "#     print (\"'{}',\".format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-colony",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-socket",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-separate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
