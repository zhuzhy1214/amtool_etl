{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "foreign-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-rouge",
   "metadata": {},
   "source": [
    "# Update Notes: \n",
    "\n",
    "### V2: \n",
    "do not filter performance data for active section. <br>\n",
    "do not round for 5 year target percentage calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-roots",
   "metadata": {},
   "source": [
    "## TODO\n",
    "needs to change the FY related number to dynamic number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-diagnosis",
   "metadata": {},
   "source": [
    "# Tip for quick search\n",
    "\n",
    "* Needs attention: the place where needs update or better logic\n",
    "* question to be answered: the place where things are still not clear\n",
    "* Manual Check: Unit test where you can drill in to find the data that leads to the check results for a specific project and specific check\n",
    "* TODO: things needs to be done\n",
    "* bookmark: stop point from last visit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-excess",
   "metadata": {},
   "source": [
    "# Admin Notes:\n",
    "\n",
    "\n",
    "1. The AMTool dataset is archived daily as csv files and used for the project book check. \n",
    "The csv files are located at: \n",
    "r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\DataLake'\n",
    "\n",
    "2. The excel input files are checked daily and archived with datestamp whenever it is modified.\n",
    "The continuously updated excel input files are located at: r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\excel'\n",
    "The excel input file are archived at: r'\\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Tableau Dashboards\\Data_MiscInput'\n",
    "To recover the archived excel file used in project book check for a target date, select the excel file with latest datestamp but is still earlier than the target date.\n",
    "\n",
    "3. The check summary export action is logged daily. It can be used for daily monitoring. \n",
    "The file export log is located at: \\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal\\log\n",
    "\n",
    "4. The published data are at:\n",
    "\n",
    "    * csv files for district asset manager: http://svgcshopp.dot.ca.gov/DataLake/ProjectBookCheck/\n",
    "    * csv files for HQ AM: \\\\ct.dot.ca.gov\\dfshq\\DIROFC\\Asset Management\\4e Project Book\\Projectbook_WorkingFolder\\output_internal\n",
    "    * tableau workbook with live data source: https://tableau.dot.ca.gov/#/site/AssetManagement/workbooks/1815/views\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-confidentiality",
   "metadata": {},
   "source": [
    "<a id='TableOfContents'></a>\n",
    "\n",
    "# Table Of Contents\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "### [Global Constants](#GlobalConstants)\n",
    "\n",
    "\n",
    "### [Load and cleanup source data](#Read_Data)\n",
    "\n",
    "* [Counties](#Counties)\n",
    "* [Programming_Summary](#Programming_Summary)\n",
    "* [ProgrammingList](#ProgrammingList)\n",
    "* [SHOPP_Raw_Data](#SHOPP_Raw_Data)\n",
    "* [TenYrShopp_Perf_RawData](#TenYrShopp_Perf_RawData)\n",
    "\n",
    "\n",
    "## Add fields to SHOPP raw data (calculate and join)\n",
    "* [Calculated Fields](#AddDataColumns)\n",
    "* [Join Tables](#DataJoining)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## [Export Projectbook Check Sumary Key Dates](#Export_KeyDates)\n",
    "\n",
    "\n",
    "\n",
    "## [Final Clean Up](#FinalCleanUp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-mozambique",
   "metadata": {},
   "source": [
    "# Import common modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fundamental-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "\n",
    "# import requests\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "small-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "second-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "intellectual-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show dataframe without skip column\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acquired-istanbul",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using the Extract API 2.0, please save the output as .hyper format\n"
     ]
    }
   ],
   "source": [
    "# from config_datasource import *\n",
    "from projectbookcheck_utilityfunction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-aspect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "piano-celebrity",
   "metadata": {},
   "source": [
    "# Data clean process\n",
    "\n",
    "* funding amount: remove dollar sign, \n",
    "* fill missing value, string, numerical, \n",
    "* remove leading single quote for string value\n",
    "* strip off leading and trailing space \n",
    "\n",
    "* regulate column names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-theory",
   "metadata": {},
   "source": [
    "<a id='GlobalConstants'></a>\n",
    "## Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "experienced-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sorted-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETDATE = datetime.today().strftime(\"%m-%d-%Y\")\n",
    "CURRENT_FY = fiscalyear (datetime.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suitable-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_export_log = open(LOG_FILE, \"a\")  # append mode\n",
    "# file_export_log.write(\"#####{} \\n\".format(TARGETDATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-ready",
   "metadata": {},
   "source": [
    "<a id='Read_Data'></a>\n",
    "\n",
    "# Read Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "artificial-handy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s151589\\Anaconda3\\envs\\dataprep\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (36,38) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "if DATA_SOURCE_TYPE == 'csv':\n",
    "    filename = 'TenYrShopp_RawData_'\n",
    "    df_SHOPP_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE))\n",
    "\n",
    "    filename = 'TenYrShopp_PerfM_Raw_Data_'\n",
    "    df_perf_raw_data = pd.read_csv(r'{}\\{}{}.csv'.format(DATALAKE_FOLDER, filename, TARGETDATE))\n",
    "\n",
    "else:\n",
    "    print('skip getting csv data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-cheese",
   "metadata": {},
   "source": [
    "Done with TenYrShopp_RawData_ in -13.425710678100586\n",
    "Done with TenYrShopp_PerfM_Raw_Data_ in -96.45661997795105\n",
    "Done with Rawdata_Pavement_Worksheet_ in -8.857773303985596\n",
    "Done with Rawdata_Drainage_Worksheet_ in -43.5689959526062\n",
    "Done with Rawdata_Bridge_Worksheet_ in -7.964364290237427\n",
    "Done with Rawdata_TMS_Worksheet_ in -9.304267168045044\n",
    "Done with Project_Postmile_Check_ in -12.754770517349243\n",
    "Done with Programming_Summary_ in -15.230461597442627\n",
    "Done with HM_Project_Details_Raw_Data_ in -7.1786627769470215\n",
    "Done with Minor_Project_Details_Raw_Data_ in -7.667008399963379\n",
    "total time: -222.40863466262817"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-heart",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "special-steering",
   "metadata": {},
   "source": [
    "<a id='SHOPP_Raw_Data'></a>\n",
    "## SHOPP Raw Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "complex-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SHOPP_raw_data.name = 'df_SHOPP_raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "molecular-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns \n",
    "dict_rename_rawdata = {\n",
    "                       'County':'County TYP',\n",
    "                       'Route': 'Route TYP',\n",
    "                       'BackPM':'BackPM TYP',\n",
    "                       'AheadPM':'AheadPM TYP',\n",
    "                       'ID': 'AMT_ID',\n",
    "                       'Ten-Year Plan': 'Ten-Year Plan RD',\n",
    "                       'County.1' : 'County PRG',\n",
    "                       'Route.1' : 'Route PRG',\n",
    "                       'BackPM.1':'BackPM PRG',\n",
    "                       'AheadPM.1' : 'AheadPM PRG',\n",
    "                       'County.2' : 'County PCR',\n",
    "                       'Route.2' : 'Route PCR',\n",
    "                       'BackPM.2':'BackPM PCR',\n",
    "                       'AheadPM.2' : 'AheadPM PCR',\n",
    "                       'Activity Category': 'Activity'\n",
    "                      }\n",
    "\n",
    "df_SHOPP_raw_data = df_SHOPP_raw_data.rename(dict_rename_rawdata, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "manufactured-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove leading puncture for target columns\n",
    "cols_strip = ['District','Route TYP','EA','EFIS','Route PRG','PPNO','Route PCR']\n",
    "for c in cols_strip :\n",
    "    df_SHOPP_raw_data[c] = df_SHOPP_raw_data[c].str.strip(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "piano-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_columns = [\n",
    "    'RW Cost ($K)',\n",
    "    'Const Cost ($K)',\n",
    "    'Support Cost ($)',\n",
    "    'TYP Total Project Cost ($K)',\n",
    "    'PAED ($K)',\n",
    "    'PSE ($K)',\n",
    "    'R/W ($K)',\n",
    "    'CONS ($K)',\n",
    "    'Prog Support Cost ($)',\n",
    "    'Prog RW Cost ($K)',\n",
    "    'Prog Const Cost ($K)',\n",
    "    'Prog Total Project Cost ($K)',\n",
    "    'PCR R/W Cap ($K)',\n",
    "    'PCR Const Cap ($K)',\n",
    "    'PCR Support Cost ($K)',\n",
    "    'PCR Total Cost ($K)',\n",
    "    'Project Cost In Use',\n",
    "    'Total LL Prog ($K)',\n",
    "    'LL PAED Cost ($K)',\n",
    "    'LL CONS Cap ($K)',\n",
    "    'PA&ED Cost',\n",
    "    'LL Adl RW ($K)',\n",
    "    'LL PSE ($K)',\n",
    "    'PAED ($K)',  \n",
    "    'LL CONS ($K)',\n",
    "    'LL RW Cap ($K)',\n",
    "               ]\n",
    "\n",
    "for c in cost_columns:\n",
    "    df_SHOPP_raw_data[c] = df_SHOPP_raw_data[c].apply(curreny_to_float)\n",
    "    df_SHOPP_raw_data[c].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "thrown-protein",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data clean \n",
    "#data type regulation\n",
    "#string/text data regulation\n",
    "\n",
    "df_SHOPP_raw_data['District'] =df_SHOPP_raw_data['District'].astype(int)\n",
    "\n",
    "df_SHOPP_raw_data['EFIS'] = pd.to_numeric(df_SHOPP_raw_data['EFIS'], errors='coerce')\n",
    "\n",
    "df_SHOPP_raw_data['Route PCR'] = df_SHOPP_raw_data['Route PCR'].astype(str)\n",
    "\n",
    "#data trimming\n",
    "#row trimming\n",
    "df_SHOPP_raw_data= df_SHOPP_raw_data[df_SHOPP_raw_data['District'] != 56]\n",
    "\n",
    "#column trimming\n",
    "df_SHOPP_raw_data.drop(['District Priority', 'PIR Performance Report'],\n",
    "  axis='columns', inplace=True, errors='ignore')\n",
    "\n",
    "\n",
    "#Question to be answered:\n",
    "#for EA Raw Data, the missing data is not null , but ''. Should we handle the missing data uniformly for string data?\n",
    "\n",
    "#TODO:\n",
    "#fill missing data\n",
    "#data quality check (checksum,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "valued-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SHOPP_raw_data['CCA Date Miilestone (M600)'] = df_SHOPP_raw_data['CCA Date Miilestone (M600)'].apply(regulate_timestamp_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "framed-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-belief",
   "metadata": {},
   "source": [
    "<a id='TenYrShopp_Perf_RawData'></a>\n",
    "## TenYrShopp_Perf_RawData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "psychological-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "dict_rename_perf_rawdata = {\n",
    "                           'ID': 'AMT_ID',\n",
    "              }\n",
    "\n",
    "df_perf_raw_data = df_perf_raw_data.rename(dict_rename_perf_rawdata, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "found-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_strip = ['EA','EFIS','PPNO']\n",
    "for c in cols_strip :\n",
    "    df_perf_raw_data[c] = df_perf_raw_data[c].str.strip(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sustainable-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data clean \n",
    "#data type regulation\n",
    "\n",
    "df_perf_raw_data['Quantity'] = df_perf_raw_data['Quantity'].fillna(0)\n",
    "df_perf_raw_data['Assets in Good Cond'] = df_perf_raw_data['Assets in Good Cond'].fillna(0)\n",
    "df_perf_raw_data['Assets in Fair Cond'] = df_perf_raw_data['Assets in Fair Cond'].fillna(0)\n",
    "df_perf_raw_data['Assets in Poor Cond'] = df_perf_raw_data['Assets in Poor Cond'].fillna(0)\n",
    "df_perf_raw_data['New Assets Added'] = df_perf_raw_data['New Assets Added'].fillna(0)\n",
    "\n",
    "df_perf_raw_data['EFIS'] = pd.to_numeric(df_perf_raw_data['EFIS'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dedicated-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data trimming\n",
    "#row\n",
    "df_perf_raw_data= df_perf_raw_data[df_perf_raw_data['District'] != 56]\n",
    "#column\n",
    "df_perf_raw_data.drop(['PID Cycle', 'TYP','ProjectedSHOPP Cycle','RequestedRTL FY','DistrictPriority'],\n",
    "  axis='columns', inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sapphire-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data.name = 'df_perf_raw_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-seafood",
   "metadata": {},
   "source": [
    "<a id='FinanceTargetsAndUnitCost'></a>\n",
    "## FinanceTargetsAndUnitCost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "incorrect-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finance Targets\n",
    "\n",
    "filename = 'Targets and Unit cost.xlsx'\n",
    "\n",
    "shts = ['Targets and Unit Cost', 'Finance Targets']\n",
    "\n",
    "dict_df = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename), sheet_name = shts) \n",
    "\n",
    "df_finance_targets_uc = dict_df['Targets and Unit Cost']\n",
    "df_finance_targets = dict_df['Finance Targets']\n",
    "\n",
    "df_finance_targets.name = 'df_finance_targets'\n",
    "df_finance_targets_uc.name = 'df_finance_targets_uc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "racial-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#rename columns\n",
    "# dict_rename= {\n",
    "#                'Objective':'Performance Objective', \n",
    "#     'Unit': 'Unit of Measure',\n",
    "#     'New Performance Target': 'New Target',\n",
    "#     'Fair to Good': 'F2G Target',\n",
    "#     'Poor to Good': 'P2G Target',\n",
    "#               }\n",
    "\n",
    "# df_finance_targets_uc = df_finance_targets_uc.rename(dict_rename, axis = 1)\n",
    "\n",
    "\n",
    "# df_factflow_financetarget = df_perf_raw_prog_county.merge(df_finance_targets, how = 'left', \n",
    "#                   left_on = 'District', \n",
    "#                   right_on = 'District Targets')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-healthcare",
   "metadata": {},
   "source": [
    "<a id='ProgrammingList'></a>\n",
    "## Programming List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "completed-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "shts = ['2010 SHOPP',\n",
    "        '2012 SHOPP',\n",
    "        '2014 SHOPP',\n",
    "        '2016 SHOPP',\n",
    "        '2018 SHOPP',\n",
    "        '2020 SHOPP',\n",
    "        'Long Lead'\n",
    "        ]\n",
    "\n",
    "filename = 'Programming_list.xlsx'\n",
    "\n",
    "df_dict = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename), sheet_name =shts) \n",
    "\n",
    "\n",
    "df_program = pd.DataFrame()\n",
    "\n",
    "for k, v in df_dict.items():\n",
    "#     print(type(v))\n",
    "#     print(k)\n",
    "    v['Table Names'] = k\n",
    "#     print(v.columns)\n",
    "    df_program = df_program.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "optional-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "dict_rename_program = {\n",
    "#                         'EA':'EA', \n",
    "                        'EFIS':'EFIS_Program', \n",
    "#                         'PPNO':'PPNO Programming', \n",
    "                        'Total Capital & Support':'Total Capital & Support Cost',\n",
    "#                         'Route': 'Route Programming',\n",
    "              }\n",
    "\n",
    "df_program = df_program.rename(dict_rename_program, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "thick-drunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s151589\\Anaconda3\\envs\\dataprep\\lib\\site-packages\\pandas\\core\\frame.py:4459: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n"
     ]
    }
   ],
   "source": [
    "#data clean \n",
    "#data type regulation\n",
    "# df_program['Dist'] = df_program['Dist'].astype(int)\n",
    "# df_program['EFIS'] = pd.to_numeric(df_program['EFIS'], errors='coerce')\n",
    "\n",
    "fillna_columns = ['Con Sup','RW Sup','PA&ED','PS&E', 'PA&ED', 'RW', 'Con']\n",
    "\n",
    "df_program[fillna_columns].fillna(0, inplace=True)\n",
    "df_program['Route'].fillna('Various', inplace=True)\n",
    "\n",
    "df_program['Support Cost'] = df_program['Con Sup']+df_program['RW Sup']+df_program['PA&ED']+df_program['PS&E']\n",
    "df_program['Capital Cost'] = df_program['Con']+df_program['RW']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "vulnerable-twelve",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "#data transformation\n",
    "\n",
    "# df_program.dropna(subset = ['EFIS_Program'], inplace = True)\n",
    "df_program['FY'] = df_program['FY'].apply(FY_cleanup)\n",
    "\n",
    "df_program['Begin Post Miles'] = df_program['Post Miles'].apply(lambda x: str(x).split('/')[0])\n",
    "df_program['End Post Miles'] = df_program['Post Miles'].apply(lambda x: str(x).split('/')[0] if '/' in str(x) else np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "settled-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data trimming\n",
    "df_program.drop(['PM1BF', 'PM1B', 'PM1AF','PM1A',], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "suburban-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_program.name = 'df_program'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "coastal-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data sanity check\n",
    "#check duplicates\n",
    "#check null\n",
    "#check data type\n",
    "\n",
    "if df_program['EFIS_Program'].value_counts(dropna = False).max() > 1:\n",
    "    Print('Duplicate EFIS ID found, please check the source data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-piano",
   "metadata": {},
   "source": [
    "<a id='HOV_Degradation'></a>\n",
    "## HOV Degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "christian-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'HOV Degradation.xlsx'\n",
    "\n",
    "df_HOV_degradataion = pd.read_excel(r'{}\\{}'.format(PROJECTBOOKCHECK_INPUT_FOLDER, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-sponsorship",
   "metadata": {},
   "source": [
    "# Add columns to raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "rubber-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SHOPP_raw_data['Data_TimeStamp'] = TARGETDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "martial-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is reservation project?\n",
    "reservation_list=[\n",
    "    'Major Damage - Emergency Opening',\n",
    "    'Major Damage - Permanent Restoration',\n",
    "    'Reactive Safety',\n",
    "    'Safety - Monitoring',\n",
    "    'Safety - SI',\n",
    "    'Relinquishment',\n",
    "    'Bridge - Deck',\n",
    "    ]\n",
    "\n",
    "def ck_is_reservation(df):\n",
    "    if df['Activity'] in reservation_list:\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return 'No'\n",
    "        \n",
    "col_name =  'Reservation Project?'\n",
    "df_SHOPP_raw_data[col_name] = df_SHOPP_raw_data.apply(ck_is_reservation, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-rugby",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "everyday-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'FY','Total Capital & Support Cost' to raw data\n",
    "df_SHOPP_raw_data.drop(columns =['EFIS_Program','FY','Total Capital & Support Cost','Capital Cost', 'Support Cost'], inplace=True, errors = 'ignore')\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, df_program[['EFIS_Program','FY','Total Capital & Support Cost','Capital Cost', 'Support Cost' ]], \n",
    "                             how = 'left', left_on = 'EFIS', right_on='EFIS_Program')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "attempted-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add col 'Include 5-year POR?'\n",
    "df_SHOPP_raw_data['Section'] = df_SHOPP_raw_data.apply(cal_section_in_use, axis=1)     \n",
    "\n",
    "df_SHOPP_raw_data['AM Tool RTL (Section in Use)'] = df_SHOPP_raw_data.apply(calc_SIU_RTL, axis=1)\n",
    "\n",
    "df_SHOPP_raw_data['AM Tool RTL (Section in Use)'].fillna('00', inplace = True)\n",
    "\n",
    "df_SHOPP_raw_data['Activity (group)'] = df_SHOPP_raw_data['Activity'].apply(calc_activity_group)\n",
    "\n",
    "df_SHOPP_raw_data['Last Year FY POR'] = df_SHOPP_raw_data['AM Tool RTL (Section in Use)'].str[-2:].astype(int)+2000\n",
    "\n",
    "\n",
    "def calc_include_5year_POR(df):\n",
    "    if df['Ten-Year Plan RD'] == 9999:\n",
    "        return  'No'\n",
    "    elif(df['Last Year FY POR']>TARGET_FY and df['Last Year FY POR']<TARGET_FY + 6) :   \n",
    "        if df['Activity (group)'] == 'Reservation' and pd.isnull(df['SHOPP Amendment Date']): \n",
    "            return  'Yes' \n",
    "        else: \n",
    "            return 'No' \n",
    "    elif (df['Last Year FY POR']>TARGET_FY + 5 and df['Last Year FY POR']<TARGET_FY + 11) : \n",
    "        if(df['Long Lead'] == \"Y\") and (df['Section'] == \"PRG\")  :\n",
    "             return  'Yes'\n",
    "        elif pd.isnull(df['SHOPP Amendment Date']): \n",
    "             return  'Yes' \n",
    "        else: \n",
    "            return 'No' \n",
    "    else: \n",
    "        return 'No'\n",
    "\n",
    "df_SHOPP_raw_data['Include 5-year POR?'] = df_SHOPP_raw_data.apply(calc_include_5year_POR, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "mathematical-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_paed_allocation(df):\n",
    "    if pd.notnull(df['SHOPP Amendment Date']) or df['Include 5-year POR?'] == 'No' or df['Reservation Project?'] == 'Yes':\n",
    "        return 0\n",
    "    else:\n",
    "        if pd.isnull(df['PA&ED Cost']):\n",
    "            return 0\n",
    "        else:\n",
    "            return float(df['PA&ED Cost'])\n",
    "\n",
    "df_SHOPP_raw_data['PA&ED Allocation'] =  df_SHOPP_raw_data.apply(calc_paed_allocation, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "invisible-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_paed_allocation_year(df):\n",
    "    if df['Long Lead'] != 'Y':\n",
    "        return np.nan\n",
    "    elif pd.notnull(df['SHOPP Amendment Date']):\n",
    "        return np.nan\n",
    "    elif df['Section In Use'] =='TYP':\n",
    "        return df['Target RTL FY']\n",
    "    else:\n",
    "        return df['Requested RTL FY']\n",
    "    \n",
    "df_SHOPP_raw_data['PA&ED allocation Year'] = df_SHOPP_raw_data.apply(calc_paed_allocation_year, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "manual-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_por_paed_year(df):\n",
    "    if pd.isnull(df['PA&ED allocation Year'] ):\n",
    "        return np.nan\n",
    "    \n",
    "    int_FY = int(df['PA&ED allocation Year'][-2:])\n",
    "    if int_FY < 27: \n",
    "        return 'LL PA&ED'\n",
    "    else:\n",
    "        return df['PA&ED allocation Year']\n",
    "df_SHOPP_raw_data['POR PA&ED Year'] = df_SHOPP_raw_data.apply(calc_por_paed_year, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "careful-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_projectcost_POR_RTL(df):\n",
    "    if df['Reservation Project?'] == 'Yes':\n",
    "        return 0\n",
    "    elif df['Include 5-year POR?'] =='Yes':\n",
    "        return df['Project Cost In Use'] - df['PA&ED Cost']\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df_SHOPP_raw_data['Project Cost in RTL Year of POR'] = df_SHOPP_raw_data.apply(calc_projectcost_POR_RTL, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "alert-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_support_cost(df):\n",
    "    if pd.isnull(df['Long Lead']): #if it is not an active long lead project\n",
    "        if df['Section']=='TYP':\n",
    "            return df['Support Cost ($)'] \n",
    "        elif df['Section']=='PRG':\n",
    "            return df['Prog Support Cost ($)']\n",
    "        elif df['Section']=='PPC':\n",
    "            return df['PCR Support Cost ($K)']\n",
    "        elif df['Section']=='CCA': # it is in CCA now\n",
    "            if pd.isnull(df['PCR SHOPP Amendment Date']):   #no information in PPC section to be used\n",
    "                return df['Prog Support Cost ($)']\n",
    "            else: #use the PPC section information \n",
    "                return df['PCR Support Cost ($K)']\n",
    "        \n",
    "    else: #for a long lead project\n",
    "        if df['Section']=='TYP':\n",
    "            return df['Support Cost ($)'] + df['LL PAED Cost ($K)']\n",
    "        elif df['Section']=='PRG':\n",
    "            return df['LL Adl RW ($K)'] + df['LL PSE ($K)'] + df['PAED ($K)'] + df['LL CONS ($K)']\n",
    "        elif df['Section']=='PPC': \n",
    "            return df['PCR Support Cost ($K)']\n",
    "        elif df['Section']=='CCA': #no information in PPC section to be used\n",
    "            if pd.isnull(df['PCR SHOPP Amendment Date']):\n",
    "                return df['LL Adl RW ($K)'] + df['LL PSE ($K)'] + df['PAED ($K)'] + df['LL CONS ($K)']\n",
    "            else:\n",
    "                return df['PCR Support Cost ($K)']   \n",
    "\n",
    "                \n",
    "def calc_capital_cost(df):\n",
    "    if pd.isnull(df['Long Lead']): #if it is not an active long lead project\n",
    "        if df['Section']=='TYP':\n",
    "            return df['RW Cost ($K)'] + df['Const Cost ($K)']\n",
    "        elif df['Section']=='PRG':\n",
    "            return df['Prog RW Cost ($K)'] + df['Prog Const Cost ($K)']\n",
    "        elif df['Section']=='PPC':\n",
    "            return df['PCR R/W Cap ($K)'] + df['PCR Const Cap ($K)']\n",
    "        elif df['Section']=='CCA': # it is in CCA now\n",
    "            if pd.isnull(df['PCR SHOPP Amendment Date']):   #no information in PPC section to be used\n",
    "                return df['Prog RW Cost ($K)'] + df['Prog Const Cost ($K)']\n",
    "            else: #use the PPC section information \n",
    "                return df['PCR R/W Cap ($K)'] + df['PCR Const Cap ($K)']\n",
    "        \n",
    "    else: #for a long lead project\n",
    "        if df['Section']=='TYP':\n",
    "            return df['RW Cost ($K)'] + df['Const Cost ($K)']\n",
    "        elif df['Section']=='PRG':\n",
    "            return df['LL RW Cap ($K)'] + df['LL CONS Cap ($K)']\n",
    "        elif df['Section']=='PPC': \n",
    "            return df['PCR R/W Cap ($K)'] + df['PCR Const Cap ($K)']\n",
    "        elif df['Section']=='CCA': #no information in PPC section to be used\n",
    "            if pd.isnull(df['PCR SHOPP Amendment Date']):\n",
    "                return df['LL RW Cap ($K)'] + df['LL CONS Cap ($K)']\n",
    "            else:\n",
    "                return df['PCR R/W Cap ($K)'] + df['PCR Const Cap ($K)']\n",
    "\n",
    "col_name =  'Support Cost ($K)'\n",
    "df_SHOPP_raw_data[col_name] = df_SHOPP_raw_data.apply(calc_support_cost, axis = 1)\n",
    "\n",
    "col_name =  'Capital Cost ($K)'\n",
    "df_SHOPP_raw_data[col_name] = df_SHOPP_raw_data.apply(calc_capital_cost, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abstract-deposit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "federal-component",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_support_capital_ratio(df):\n",
    "    if df['Capital Cost ($K)'] != 0: \n",
    "        return round(df['Support Cost ($K)']/df['Capital Cost ($K)'],3)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df_SHOPP_raw_data['Support Capital Ratio'] = df_SHOPP_raw_data.apply(calc_support_capital_ratio, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "covered-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_SHOPP_raw_data['Support Capital Ratio'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "furnished-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate column: HOV Degradation Project?\n",
    "\n",
    "temp = df_perf_raw_data[df_perf_raw_data['Activity Detail'] == 'HOV Degradation Mitigation'].groupby(['AMT_ID', 'Section']).agg('first').reset_index()\n",
    "\n",
    "temp['HOV Degradation Project?'] = 'Yes'\n",
    "\n",
    "df_SHOPP_raw_data = pd.merge(df_SHOPP_raw_data, temp[['AMT_ID', 'Section','HOV Degradation Project?']], \n",
    "                             how = 'left', left_on = ['AMT_ID', 'Section'], right_on=['AMT_ID', 'Section'])\n",
    "\n",
    "df_SHOPP_raw_data['HOV Degradation Project?'].fillna('No', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-lexington",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "single-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check raw data calculation\n",
    "\n",
    "# df_SHOPP_raw_data[['AMT_ID','Section','Reservation Project?','Include 5-year POR?',\n",
    "#        'PA&ED Allocation', 'Project Cost in RTL Year of POR',  'PA&ED allocation Year', 'POR PA&ED Year',\n",
    "#        'Support Cost ($K)',\n",
    "#        'Capital Cost ($K)', 'HOV Degradation Project?'] ].to_csv('raw_data.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "offshore-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug only\n",
    "# df_SHOPP_raw_data[(df_SHOPP_raw_data['Include 5-year POR?'] == 'Yes')\n",
    "#                  & (df_SHOPP_raw_data['District'] == 1)\n",
    "#                  ].groupby(['District','RTL In Use']).agg(\n",
    "#     {'Project Cost in RTL Year of POR': 'sum',\n",
    "#     'PA&ED Allocation': 'sum',\n",
    "#     'AMT_ID': 'nunique',\n",
    "#     }\n",
    "# ).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-senegal",
   "metadata": {},
   "source": [
    "# Add columns to performance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "champion-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "#legacy problem, keep the performance of the unused sections, to compare with mara's spreadsheet.\n",
    "\n",
    "df_perf_raw_data_1 = pd.merge(df_perf_raw_data,\n",
    "                              df_SHOPP_raw_data[['AMT_ID', 'Section', 'Reservation Project?', 'Include 5-year POR?','RTL In Use','Support Capital Ratio',\n",
    "                  'Project Cost In Use',]], \n",
    "                how ='left', \n",
    "                left_on = ['AMT_ID', 'Section'],\n",
    "                right_on = ['AMT_ID', 'Section'], \n",
    "#                 suffixes=('', '_raw'),\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "general-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data_1 = pd.merge(df_perf_raw_data_1, df_finance_targets_uc[['District', 'Performance Objective', \n",
    "                                                                         'New Target','F2G Target','P2G Target',\n",
    "                                                                         'New Escalated UC ($K)', 'F2G Escalated UC ($K)', 'P2G Escalated UC ($K)']], \n",
    "                how ='left', \n",
    "                left_on = ['District','Performance Objective'],\n",
    "                right_on = ['District','Performance Objective'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "gothic-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data_1['Post-Fair'].fillna(0, inplace = True)\n",
    "\n",
    "df_perf_raw_data_1['F2G Achieved'] = df_perf_raw_data_1['Post-Fair'] - df_perf_raw_data_1['Assets in Fair Cond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "accessible-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data_1['Post-Poor'].fillna(0, inplace = True)\n",
    "\n",
    "df_perf_raw_data_1['P2G Achieved'] = df_perf_raw_data_1['Post-Poor'] - df_perf_raw_data_1['Assets in Poor Cond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "specific-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rename_performance ={\n",
    "    'New Assets Added':'New Achieved',\n",
    "}\n",
    "\n",
    "df_perf_raw_data_1 = df_perf_raw_data_1.rename(dict_rename_performance, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "compound-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_raw_data_1['Concatenate District+Objective'] = df_perf_raw_data_1['District'].astype(str) + df_perf_raw_data_1['Performance Objective']\n",
    "df_perf_raw_data_1['Include in Pivot table?'] =''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-juice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "signal-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_earned_value(df):\n",
    "    \n",
    "    EV = (\n",
    "        df['New Achieved'] * df['New Escalated UC ($K)'] \n",
    "        + df['Post-Fair'] + df['Assets in Fair Cond']* df['F2G Escalated UC ($K)']\n",
    "        + df['Post-Poor'] + df['Assets in Poor Cond']* df['P2G Escalated UC ($K)']\n",
    "         )\n",
    "    \n",
    "    return round(EV,2)\n",
    "\n",
    "df_perf_raw_data_1['Earned Value (EV) ($K)'] = df_perf_raw_data_1.apply(calc_earned_value, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "proper-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_effective_earned_value(df):\n",
    "    # I do not understand this function\n",
    "    if df['F2G Target'] == 0: \n",
    "        EEV = 0\n",
    "    else: \n",
    "        EEV = df['Post-Fair'] + df['Assets in Fair Cond'] * df['F2G Escalated UC ($K)']\n",
    "    \n",
    "    if df['P2G Escalated UC ($K)'] != 0 :\n",
    "        EEV += df['Post-Poor'] + df['Assets in Poor Cond'] * df['P2G Escalated UC ($K)']\n",
    "    \n",
    "    return round(EEV,2)\n",
    "\n",
    "df_perf_raw_data_1['Effective Earned Value (EEV) ($K)'] = df_perf_raw_data_1.apply(calc_effective_earned_value, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "illegal-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cooked-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the relavent performance data only\n",
    "\n",
    "df_perf_raw_data_filtered = df_perf_raw_data_1[\n",
    "    (df_perf_raw_data_1['Include 5-year POR?'] == 'Yes')\n",
    "    & (df_perf_raw_data_1['Reservation Project?'] == 'No')\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "disciplinary-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data_1[\n",
    "#     (df_perf_raw_data_1['Include 5-year POR?'] == 'Yes')]['Support Capital Ratio'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cutting-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "alternative-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #PPI Debug\n",
    "\n",
    "# df_perf_raw_data_filtered[(df_perf_raw_data_filtered['District'] == 1)\n",
    "#                  & (df_perf_raw_data_filtered['RTL In Use'] == '2026/27')\n",
    "#                   & (df_perf_raw_data_filtered['Performance Objective'] == 'Proactive Safety')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-watch",
   "metadata": {},
   "source": [
    "# create summary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "baking-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Districts =  list(range(1, 13))\n",
    "RTLs = ['2026/27', '2027/28', '2028/29','2029/30', '2030/31']\n",
    "\n",
    "df_5y_summary = pd.DataFrame(list(product(Districts, RTLs)), columns=['District', 'RTL In Use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "packed-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate total project cost for each district and RTL year\n",
    "temp = df_SHOPP_raw_data[(df_SHOPP_raw_data['Include 5-year POR?'] =='Yes')]\n",
    "temp1 = temp.groupby(['District','RTL In Use'])['Project Cost in RTL Year of POR'].agg(sum).reset_index()\n",
    "\n",
    "df_5y_summary = pd.merge(df_5y_summary, temp1, \n",
    "                             how = 'left', left_on = ['District','RTL In Use'], right_on=['District','RTL In Use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "searching-electron",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5y_summary['Project Cost in RTL Year of POR'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "collectible-vampire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the PAED allocation for each RTL year \n",
    "temp = df_SHOPP_raw_data[(df_SHOPP_raw_data['Include 5-year POR?'] =='Yes') ]\n",
    "\n",
    "df_PAED= temp.groupby(['District','POR PA&ED Year']).agg(\n",
    "    {\n",
    "    'PA&ED Allocation': 'sum',\n",
    "    }\n",
    " ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-attitude",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "narrative-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_5y_summary = pd.merge(df_5y_summary, df_PAED, \n",
    "                             how = 'left', left_on = ['District','RTL In Use'], right_on=['District','POR PA&ED Year'])\n",
    "df_5y_summary['PA&ED Allocation'].fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "df_5y_summary['Project Cost ($K)'] = df_5y_summary['Project Cost in RTL Year of POR'] +  df_5y_summary['PA&ED Allocation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "worldwide-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find funding target for each district and RTL year\n",
    "df_5y_summary = pd.merge(df_5y_summary, df_finance_targets[['District', '5-Y Funding Targets ($K)']], \n",
    "                             how = 'left', left_on = 'District', right_on='District')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "printable-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5y_summary['Annual Target Funding ($K)'] = df_5y_summary['5-Y Funding Targets ($K)']/5\n",
    "df_5y_summary['5% Upper Limit ($M)'] = df_5y_summary['5-Y Funding Targets ($K)']*0.25/1000\n",
    "df_5y_summary['5% Lower Limit ($M)'] = df_5y_summary['5-Y Funding Targets ($K)']*0.15/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-juice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "respiratory-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count number of non-reservation projects within 5 year POR, for each district and RTL year.\n",
    "\n",
    "temp1 = df_SHOPP_raw_data[\n",
    "    (df_SHOPP_raw_data['Reservation Project?'] =='No') \n",
    "    & (df_SHOPP_raw_data['Include 5-year POR?'] =='Yes')]\n",
    "\n",
    "temp2 = temp1.groupby(['District','RTL In Use'])['AMT_ID'].agg('count').reset_index(name = 'No of Projects')\n",
    "\n",
    "df_5y_summary = pd.merge(df_5y_summary, temp2, \n",
    "                             how = 'left', left_on = ['District','RTL In Use'], right_on=['District','RTL In Use'])\n",
    "\n",
    "df_5y_summary['No of Projects'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "under-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5y_summary['Balance ($K)'] = round(df_5y_summary['Annual Target Funding ($K)']-df_5y_summary['Project Cost ($K)'],0)\n",
    "\n",
    "df_5y_summary['Percent of 5-Year Target Funding'] = df_5y_summary['Project Cost ($K)'] / df_5y_summary['5-Y Funding Targets ($K)']\n",
    "\n",
    "df_5y_summary['Within 20% (+/-5%) Annual Target Funding?'] = df_5y_summary['Percent of 5-Year Target Funding'].apply(lambda x: 1 if (x < 0.15 or x > 0.25) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "promotional-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_5y_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-current",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-david",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "vocal-celebration",
   "metadata": {},
   "source": [
    "## calculate PPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "collected-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "Districts =  list(range(1, 13))\n",
    "RTLs = ['2026/27', '2027/28', '2028/29','2029/30', '2030/31']\n",
    "\n",
    "df_PPI = pd.DataFrame(list(product(Districts, RTLs)), columns=['District', 'RTL In Use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ranging-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum project cost for projects within 5y POR, for each district and RTL\n",
    "\n",
    "temp = df_SHOPP_raw_data[df_SHOPP_raw_data['Include 5-year POR?']=='Yes'].groupby(['District','RTL In Use'])['Project Cost in RTL Year of POR'].agg(sum).reset_index(name = 'Project Cost')\n",
    "\n",
    "df_PPI = pd.merge(df_PPI, temp, how = 'left', left_on = ['District','RTL In Use'], right_on = ['District','RTL In Use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "assumed-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum PA&ED Allocation cost for projects within 5y POR, for each district and RTL\n",
    "\n",
    "temp = df_SHOPP_raw_data[df_SHOPP_raw_data['Include 5-year POR?']=='Yes'].groupby(['District','POR PA&ED Year'])['PA&ED Allocation'].agg(sum).reset_index(name = 'Total PAED Allocation')\n",
    "\n",
    "df_PPI = pd.merge(df_PPI, temp, how = 'left', left_on = ['District','RTL In Use'], right_on = ['District','POR PA&ED Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "nervous-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PPI.fillna(0, inplace =True)\n",
    "\n",
    "df_PPI['Total Project Cost'] = df_PPI['Project Cost'] + df_PPI['Total PAED Allocation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-dining",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "gorgeous-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment performance objective target and unit cost for each district and RTL\n",
    "\n",
    "df_PPI_performace= pd.merge(df_PPI[['District','RTL In Use']],\n",
    "                            df_finance_targets_uc[[\n",
    "                                'District', 'Performance Objective',\n",
    "                                'New Target', 'F2G Target', 'P2G Target',\n",
    "                                'New Escalated UC ($K)',   'F2G Escalated UC ($K)', 'P2G Escalated UC ($K)',\n",
    "                            ]],\n",
    "                            how = 'left', left_on = ['District'], right_on = ['District'])\n",
    "# df_PPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-separate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "divine-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate achieved performance for each district, RTL and performance objective\n",
    "\n",
    "temp = df_perf_raw_data_filtered.groupby(['District','RTL In Use','Performance Objective'])[['New Achieved','F2G Achieved', 'P2G Achieved']].sum().reset_index()\n",
    "\n",
    "df_PPI_performace = pd.merge(df_PPI_performace, temp, how = 'left', left_on= ['District','RTL In Use','Performance Objective'], right_on= ['District','RTL In Use','Performance Objective'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "available-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PPI_performace['New Achieved'].fillna(0, inplace = True)\n",
    "df_PPI_performace['F2G Achieved'].fillna(0, inplace = True)\n",
    "df_PPI_performace['P2G Achieved'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "higher-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PPI_performace['New Achieved']=-abs(df_PPI_performace['New Achieved'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-career",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "knowing-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate cumulative achieved performance \n",
    "\n",
    "# temp = df_PPI_performace.groupby(['Performance Objective','District','RTL In Use']).sum().groupby(level=[0,1]).cumsum().reset_index()\n",
    "temp = df_PPI_performace.groupby(['Performance Objective','District','RTL In Use']).sum()[['New Achieved','F2G Achieved', 'P2G Achieved']].groupby(['Performance Objective','District']).cumsum().reset_index()\n",
    "\n",
    "temp1 = pd.merge(df_PPI_performace,\n",
    "                             temp[['Performance Objective','District','RTL In Use','New Achieved','F2G Achieved', 'P2G Achieved']],\n",
    "                             how = 'left', \n",
    "                             left_on= ['District','RTL In Use','Performance Objective'], \n",
    "                             right_on= ['District','RTL In Use','Performance Objective'],\n",
    "                            suffixes = ['', ' Cumulated'])\n",
    "\n",
    "df_PPI_performace = temp1.sort_values(['District','Performance Objective','RTL In Use'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "enormous-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate earned value for each district, RTL\n",
    "\n",
    "def calc_earned_value(escalated_uc, cumulated_achieved_performance, target_performance ):\n",
    "    return round(escalated_uc * min(abs(cumulated_achieved_performance), target_performance), 3)\n",
    "    \n",
    "# cumulative_earned_performance= unitcost*(1+escalationrate)^year*min(achieved_performance, target_performance)\n",
    "# current_RTL_earned_performance = difference in cumulative_earned_performance\n",
    "\n",
    "df_PPI_performace['New Earned Value'] = df_PPI_performace.apply(lambda x: calc_earned_value(x['New Escalated UC ($K)'], x['New Achieved Cumulated'],x['New Target']), axis = 1)\n",
    "df_PPI_performace['F2G Earned Value'] = df_PPI_performace.apply(lambda x: calc_earned_value(x['F2G Escalated UC ($K)'], x['F2G Achieved Cumulated'],x['F2G Target']), axis = 1)\n",
    "df_PPI_performace['P2G Earned Value'] = df_PPI_performace.apply(lambda x: calc_earned_value(x['P2G Escalated UC ($K)'], x['P2G Achieved Cumulated'],x['P2G Target']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "official-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug only\n",
    "\n",
    "# df_PPI_performace[df_PPI_performace['Performance Objective']== 'Proactive Safety'][['District', 'RTL In Use', 'Performance Objective','New Target',\n",
    "#        'F2G Target', 'P2G Target','New Achieved', 'F2G Achieved', 'P2G Achieved','New Achieved Cumulated', 'F2G Achieved Cumulated',\n",
    "#        'P2G Achieved Cumulated','New Escalated UC ($K)', 'F2G Escalated UC ($K)',\n",
    "#        'P2G Escalated UC ($K)','New Earned Value',\n",
    "#        'F2G Earned Value', 'P2G Earned Value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-dispatch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-great",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "decreased-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate cumulative earned value of all performance objectives for each RTL\n",
    "#sum all the cumulative earned value from NEW, F2G and P2G to total value\n",
    "\n",
    "temp = df_PPI_performace.groupby(\n",
    "    ['District','RTL In Use',]\n",
    ")[['New Earned Value','F2G Earned Value', 'P2G Earned Value']].sum().reset_index()\n",
    "\n",
    "temp['Cumulative Total Value'] = temp['New Earned Value'] + temp['F2G Earned Value'] + temp['P2G Earned Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "literary-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#augment a row ahead of 5 year cycle, to find the difference for each of the 5 year POR\n",
    "\n",
    "Districts =  list(range(1, 13))\n",
    "RTLs = ['2025/26']\n",
    "df_dummy = pd.DataFrame(list(product(Districts, RTLs)), columns=['District', 'RTL In Use'])\n",
    "\n",
    "temp1 = pd.merge(temp, df_dummy, how ='outer', left_on=['District', 'RTL In Use'], right_on=['District', 'RTL In Use'])\n",
    "\n",
    "temp1.fillna(0, inplace= True)\n",
    "\n",
    "temp1.sort_values(['District', 'RTL In Use'], inplace =  True)\n",
    "\n",
    "temp1['Total Value'] = temp1['Cumulative Total Value'].diff()\n",
    "\n",
    "df_PPI.drop(['Total Value'], axis='columns', inplace=True, errors='ignore')\n",
    "\n",
    "df_PPI = pd.merge(df_PPI, temp1[['District', 'RTL In Use','Total Value']], how ='left',  left_on=['District', 'RTL In Use'], right_on=['District', 'RTL In Use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "korean-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PPI['PPI'] = round(df_PPI['Total Value']/df_PPI['Total Project Cost']* 100,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "headed-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug only\n",
    "\n",
    "# df_PPI_performace.to_csv('./output/PPI_performance.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "verified-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug only\n",
    "\n",
    "# df_PPI_performace[(df_PPI_performace['District'] == 1)\n",
    "#                  & (df_PPI_performace['RTL In Use'] == '2026/27')\n",
    "# #                   & (df_PPI_performace['Performance Objective'] == 'Pavement Class II')\n",
    "# #                   & (df_PPI_performace['RTL In Use'] == '2027/28')\n",
    "#                  ][['District', 'RTL In Use', 'Performance Objective','New Target',\n",
    "#        'F2G Target', 'P2G Target','New Achieved', 'F2G Achieved', 'P2G Achieved','New Achieved Cumulated', 'F2G Achieved Cumulated',\n",
    "#        'P2G Achieved Cumulated','New Escalated UC ($K)', 'F2G Escalated UC ($K)',\n",
    "#        'P2G Escalated UC ($K)','New Earned Value',\n",
    "#        'F2G Earned Value', 'P2G Earned Value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-homework",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "respiratory-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5y_summary = pd.merge(df_5y_summary, df_PPI[['District','RTL In Use','PPI']],\n",
    "                             how = 'left', left_on = ['District','RTL In Use'], right_on=['District','RTL In Use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "mathematical-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5y_summary = df_5y_summary.sort_values(['RTL In Use', 'District'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "original-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearrange columns sequence\n",
    "\n",
    "cols = [\n",
    "'District', \n",
    "       '5-Y Funding Targets ($K)', 'Annual Target Funding ($K)',\n",
    "       '5% Upper Limit ($M)', '5% Lower Limit ($M)', \n",
    "    'RTL In Use', 'Project Cost ($K)','No of Projects',\n",
    "       'Balance ($K)', 'Percent of 5-Year Target Funding',\n",
    "       'Within 20% (+/-5%) Annual Target Funding?','PPI'\n",
    "]\n",
    "df_5y_summary = df_5y_summary[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "searching-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_5y_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-baghdad",
   "metadata": {},
   "source": [
    "# Caluclate LL summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "progressive-panel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty df with all target district and RTL\n",
    "\n",
    "Districts =  list(range(1, 13))\n",
    "RTLs = ['LL PA&ED']\n",
    "\n",
    "df_LL_summary = pd.DataFrame(list(product(Districts, RTLs)), columns=['District', 'RTL In Use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "attached-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate supprt and capital cost for long lead project\n",
    "temp = df_SHOPP_raw_data[(df_SHOPP_raw_data['Reservation Project?'] =='No')\n",
    "                  & (df_SHOPP_raw_data['Include 5-year POR?'] =='Yes')   \n",
    "                        ]\n",
    "\n",
    "temp1= temp.groupby(['District']).agg(\n",
    "    {\n",
    "    'Support Cost ($K)': 'sum',\n",
    "    'Capital Cost ($K)': 'sum',\n",
    "    }\n",
    " ).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "df_LL_summary = pd.merge(df_LL_summary, temp1, \n",
    "                             how = 'left', left_on = ['District'], right_on=['District'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "broke-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_LL_summary = pd.merge(df_LL_summary, df_PAED, \n",
    "                             how = 'left', left_on = ['District','RTL In Use'], right_on=['District','POR PA&ED Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "sorted-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LL_summary['PA&ED Allocation'].fillna(0, inplace = True)\n",
    "dict_rename = {\n",
    "    'PA&ED Allocation': 'Project Cost ($K)',\n",
    "                               }\n",
    "\n",
    "df_LL_summary.rename(dict_rename, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "loaded-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_LL_summary = pd.merge(df_LL_summary, df_finance_targets[['District', '5-Y Funding Targets ($K)']], \n",
    "                             how = 'left', left_on = 'District', right_on='District')\n",
    "\n",
    "df_LL_summary['Percent of 5-Year Target Funding'] = round(df_LL_summary['Project Cost ($K)'] / df_LL_summary['5-Y Funding Targets ($K)'],3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_LL_summary['Support Capital Ratio'] = df_LL_summary['Support Cost ($K)']/df_LL_summary['Capital Cost ($K)']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fifty-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count number of LL PAED projects\n",
    "\n",
    "temp = df_SHOPP_raw_data[(df_SHOPP_raw_data['Reservation Project?'] =='No')\n",
    "                  & (df_SHOPP_raw_data['Include 5-year POR?'] =='Yes')   \n",
    "                         & (df_SHOPP_raw_data['POR PA&ED Year'] =='LL PA&ED')\n",
    "                        ]\n",
    "\n",
    "temp1 = temp.groupby(['District'])['PA&ED Allocation'].agg(\n",
    "    'count').reset_index(name = 'No of Projects')\n",
    "\n",
    "df_LL_summary = pd.merge(df_LL_summary, temp1, \n",
    "                             how = 'left', left_on = 'District', right_on='District')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-samba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "scenic-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp = df_perf_raw_data_filtered[\n",
    "                   (df_perf_raw_data_filtered['Performance Objective'] =='Complete Streets Build New')\n",
    "                   &  (df_perf_raw_data_filtered['RTL In Use'].isin(['2026/27','2027/28']))\n",
    "                  ].groupby(['District']).agg({'P2G Achieved':'sum'}).reset_index()\n",
    "\n",
    "\n",
    "df_LL_summary =  pd.merge(df_LL_summary, \n",
    "                             temp, \n",
    "                            how = 'left', \n",
    "                            left_on = ['District'], \n",
    "                  right_on = ['District'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-stock",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "refined-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = df_finance_targets_uc[df_finance_targets_uc['Performance Objective'] == 'Complete Streets Build New'][['District', 'P2G Target']]\n",
    "\n",
    "df_LL_summary =  pd.merge(df_LL_summary, \n",
    "                             temp2, \n",
    "                            how = 'left', \n",
    "                            left_on = ['District'], \n",
    "                  right_on = ['District'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-element",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "sitting-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LL_summary['Complete Streets Build New Performance (Years 6 & 7) % of Target'] = round(-df_LL_summary['P2G Achieved']/df_LL_summary['P2G Target'],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "passing-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LL_summary['Complete Streets Build New Performance (Years 6 & 7) Greater Than 40% Annual Performance Target?'] = df_LL_summary['Complete Streets Build New Performance (Years 6 & 7) % of Target'].apply(lambda x: -1 if x > 0.4 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "hidden-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data_1[(df_perf_raw_data_1['Reservation Project?'] =='No')\n",
    "#                   & (df_perf_raw_data_1['Include 5-year POR?'] =='Yes')\n",
    "#                    &  (df_perf_raw_data_1['Performance Objective'] =='Complete Streets Build New')\n",
    "#                    &  (df_perf_raw_data_1['RTL In Use'].isin(['2026/27','2027/28',]))\n",
    "#                    & (df_perf_raw_data_1['District'] == 1)\n",
    "#                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "narrow-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_perf_raw_data_filtered[(df_perf_raw_data_filtered['Performance Objective'] =='Complete Streets Build New')\n",
    "#                          & (df_perf_raw_data_filtered['District'] == 1)\n",
    "#                           &  (df_perf_raw_data_filtered['RTL In Use'].isin(['2026/27','2027/28',]))\n",
    "#                          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-invalid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "spare-distributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LL_summary =  pd.merge(df_LL_summary, \n",
    "                             df_HOV_degradataion[['District','Finance Target ($K)']], \n",
    "                            how = 'left', \n",
    "                            left_on = ['District'], \n",
    "                  right_on = ['District'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "pleasant-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_col_rename = {\n",
    "    'Finance Target ($K)':'HOV Degradation Mitigation Projects (Years 6 & 7) HOV Degradation allocation ($K)'\n",
    "}\n",
    "df_LL_summary = df_LL_summary.rename(dict_col_rename, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "proud-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#calculate HOV degradation cost for each district\n",
    "\n",
    "temp = df_SHOPP_raw_data[(df_SHOPP_raw_data['Include 5-year POR?'] =='Yes') \n",
    "                  & (df_SHOPP_raw_data['HOV Degradation Project?'] =='Yes')].groupby(['District'])['Project Cost in RTL Year of POR'].sum().reset_index(name = 'HOV Degradation Mitigation Projects (Years 6 & 7) Project Cost ($K)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "civilian-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LL_summary = pd.merge(df_LL_summary, temp, how ='left', left_on = 'District', right_on = 'District')\n",
    "df_LL_summary['HOV Degradation Mitigation Projects (Years 6 & 7) Project Cost ($K)'].fillna(0, inplace=True)\n",
    "df_LL_summary['HOV Degradation Mitigation Projects (Years 6 & 7) Project Cost ($K)'] = round(df_LL_summary['HOV Degradation Mitigation Projects (Years 6 & 7) Project Cost ($K)'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-austria",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "incoming-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_HOV_degradation(df):\n",
    "    if round(df['HOV Degradation Mitigation Projects (Years 6 & 7) Project Cost ($K)'],0) >= round(df['HOV Degradation Mitigation Projects (Years 6 & 7) HOV Degradation allocation ($K)'],0):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "df_LL_summary['HOV Degradation Mitigation Projects (Years 6 & 7) Equal or Greater Than Minimal Cost?'] = df_LL_summary.apply(calc_HOV_degradation, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "extended-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LL_summary['Complete Streets Build New Performance (Years 6 & 7) % of Target'].fillna(0, inplace = True)\n",
    "df_LL_summary['No of Projects'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "facial-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cols = ['District', '5-Y Funding Targets ($K)', \n",
    "        'Support Capital Ratio', \n",
    "       'Complete Streets Build New Performance (Years 6 & 7) % of Target',\n",
    "       'Complete Streets Build New Performance (Years 6 & 7) Greater Than 40% Annual Performance Target?',\n",
    "       'HOV Degradation Mitigation Projects (Years 6 & 7) HOV Degradation allocation ($K)',\n",
    "       'HOV Degradation Mitigation Projects (Years 6 & 7) Project Cost ($K)',\n",
    "       'HOV Degradation Mitigation Projects (Years 6 & 7) Equal or Greater Than Minimal Cost?',\n",
    "       'RTL In Use',  'Project Cost ($K)','No of Projects',\n",
    "       'Percent of 5-Year Target Funding',\n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "central-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = df_LL_summary[out_cols]\n",
    "\n",
    "df_summary = df_summary.append(df_5y_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-worker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "suitable-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate achieved performance\n",
    "\n",
    "df_perf_ck = df_PPI_performace.groupby(['District','Performance Objective'])[['F2G Achieved', 'P2G Achieved',]].sum().reset_index()\n",
    "\n",
    "df_perf_ck = pd.merge(df_perf_ck, df_finance_targets_uc[['District', 'Performance Objective', 'Unit of Measure','F2G Target', 'P2G Target',]],\n",
    "                             how = 'left', left_on= ['District','Performance Objective'], right_on= ['District','Performance Objective'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "helpful-distinction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s151589\\Anaconda3\\envs\\dataprep\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "#modify the achieved performance and performance balance with different precision, use 0.1 only the safety columns, use 0 for all other columns\n",
    "\n",
    "df_perf_ck['Precision'] = 1\n",
    "\n",
    "df_perf_ck['Precision'].loc[(df_perf_ck['Performance Objective'].isin(['Proactive Safety','Reactive Safety']))] = 10\n",
    "\n",
    "df_perf_ck['F2G Achieved'] = round(df_perf_ck['F2G Achieved'] * df_perf_ck['Precision'], 0) / df_perf_ck['Precision']\n",
    "df_perf_ck['P2G Achieved'] = round(df_perf_ck['P2G Achieved'] * df_perf_ck['Precision'], 0) / df_perf_ck['Precision']\n",
    "\n",
    "\n",
    "df_perf_ck['F2G Balance'] = -(df_perf_ck['F2G Achieved'] + df_perf_ck['F2G Target'])\n",
    "df_perf_ck['P2G Balance'] = -(df_perf_ck['P2G Achieved'] + df_perf_ck['P2G Target'])\n",
    "\n",
    "\n",
    "df_perf_ck['Meeting F2G Performance?'] = df_perf_ck['F2G Balance'].apply(lambda x: -1 if x < 0 else 1)\n",
    "df_perf_ck['Meeting P2G Performance?'] = df_perf_ck['P2G Balance'].apply(lambda x: -1 if x < 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "local-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_ck = df_perf_ck.sort_values(['District', 'Performance Objective'])\n",
    "\n",
    "df_summary  = pd.concat([df_summary,df_perf_ck], join ='outer', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "solved-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary['Concatenate District +RTL'] = df_summary['District'].astype(str) + df_summary['RTL In Use']\n",
    "\n",
    "df_summary['Concatenate District +objective'] = df_summary['District'].astype(str) + df_summary['Performance Objective']\n",
    "\n",
    "df_summary['Date'] = TARGETDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-moldova",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "north-freeze",
   "metadata": {},
   "source": [
    "<a id='Export_FaceSheets'></a>\n",
    "\n",
    "# Export FactSheets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "subjective-proxy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_export_log = open(LOG_FILE, \"a\")  # append mode\n",
    "file_export_log.write(\"#####{} \\n\".format(TARGETDATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fallen-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cols = ['Date',\n",
    "    'District', '5-Y Funding Targets ($K)',\n",
    "    'Support Capital Ratio','Annual Target Funding ($K)', '5% Upper Limit ($M)','5% Lower Limit ($M)',\n",
    "    'Complete Streets Build New Performance (Years 6 & 7) % of Target',\n",
    "   'Complete Streets Build New Performance (Years 6 & 7) Greater Than 40% Annual Performance Target?',\n",
    "\n",
    "   'HOV Degradation Mitigation Projects (Years 6 & 7) HOV Degradation allocation ($K)',\n",
    "   'HOV Degradation Mitigation Projects (Years 6 & 7) Project Cost ($K)',\n",
    "   'HOV Degradation Mitigation Projects (Years 6 & 7) Equal or Greater Than Minimal Cost?',\n",
    "    \n",
    "    'RTL In Use', \n",
    "            \n",
    "    'Concatenate District +RTL',\n",
    "    'Project Cost ($K)', \n",
    "    'No of Projects',\n",
    "    'Balance ($K)',\n",
    "    'Percent of 5-Year Target Funding',\n",
    "    'Within 20% (+/-5%) Annual Target Funding?', \n",
    "    'PPI', \n",
    "    'Performance Objective',\n",
    "    'Concatenate District +objective',\n",
    "    'Unit of Measure',\n",
    "    'F2G Target', 'P2G Target',    \n",
    "    'F2G Achieved', 'P2G Achieved',  \n",
    "    'F2G Balance', 'P2G Balance', \n",
    "    'Meeting F2G Performance?','Meeting P2G Performance?'       \n",
    "\n",
    "]\n",
    "\n",
    "df_out = df_summary[out_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "according-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename df_out columns based on tableau convension \n",
    "\n",
    "rename_dict = {'RTL In Use': 'Fiscal Year', \n",
    "    'F2G Target':'Fair to Good SHSMP SHOPP Target',\n",
    "    'P2G Target':'Poor to Good SHSMP SHOPP Target',    \n",
    "    'F2G Achieved': 'Fair to Good Performance',\n",
    "    'P2G Achieved': 'Poor to Good Performance',  \n",
    "    'F2G Balance':'Fair to Good Performance Balance or Gap',\n",
    "    'P2G Balance':'Poor to Good Performance Balance or Gap', \n",
    "}\n",
    "\n",
    "df_out = df_out.rename(rename_dict, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-mining",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "skilled-powder",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 480it [00:00, 12654.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing factsheets.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "export_data(df_out, 'factsheets', PROJECTBOOKCHECK_HTTPSEVER_FOLDER, LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "metropolitan-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #publish tableau datasource for factsheets\n",
    "# filename = 'factsheets'\n",
    "\n",
    "# try: \n",
    "#     df_out.to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "#     shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename))\n",
    "#     file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "# except:\n",
    "#     file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "\n",
    "\n",
    "# hyper_name = 'factsheets.hyper'\n",
    "\n",
    "# try: \n",
    "#     publish_datasource(df_out, hyper_name)\n",
    "#     file_export_log.write(\"Succeeded: {} \\n\".format('{}'.format(hyper_name)))\n",
    "# except:\n",
    "#     file_export_log.write(\"Failed: {} \\n\".format('{}'.format(hyper_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "significant-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['Support Capital Ratio',\n",
    "       'Project Cost In Use', 'New Target', 'F2G Target', 'P2G Target',\n",
    "       'New Escalated UC ($K)', 'F2G Escalated UC ($K)',\n",
    "       'P2G Escalated UC ($K)', 'F2G Achieved', 'P2G Achieved',\n",
    "       'Earned Value (EV) ($K)', 'Effective Earned Value (EEV) ($K)',]:\n",
    "    df_perf_raw_data_1[c].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "incorporated-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_cols = ['District', 'AMT_ID','Section', 'Performance Objective', \n",
    "#             'F2G Achieved', 'P2G Achieved', \n",
    "#             'Concatenate District+Objective',\n",
    "#             'Section', \n",
    "#             'Reservation Project?', 'Include 5-year POR?',\n",
    "#             'Include in Pivot table?',\n",
    "#        'RTL In Use', 'Support Capital Ratio', 'Project Cost In Use',\n",
    "#         'New Escalated UC ($K)',   'F2G Escalated UC ($K)', 'P2G Escalated UC ($K)',\n",
    "#             'New Target', 'F2G Target', 'P2G Target',\n",
    "#             'Earned Value (EV) ($K)',\n",
    "#        'Effective Earned Value (EEV) ($K)']\n",
    "# df_out = df_perf_raw_data_1[out_cols]\n",
    "df_perf_raw_data_1['PerformanceChange Date After Review'].fillna('NA', inplace = True)\n",
    "df_perf_raw_data_1['Date'] = TARGETDATE\n",
    "\n",
    "df_out = df_perf_raw_data_1[\n",
    "    (df_perf_raw_data_1['Include 5-year POR?'] == 'Yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "increased-disaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 528it [00:00, 5279.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'Extract' does not exist in extract performance.hyper, creating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing table: 7689it [00:01, 5216.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing into AssetManagement at https://tableau.dot.ca.gov\n",
      "Publishing performance.hyper to Sandbox_ProjectBookCheck_Automation...\n"
     ]
    }
   ],
   "source": [
    "export_data(df_out, 'performance', PROJECTBOOKCHECK_HTTPSEVER_FOLDER, LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "intended-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #publish tableau datasource for factsheets\n",
    "# filename = 'performance'\n",
    "\n",
    "# try: \n",
    "#     df_out.to_csv('.\\output\\{}.csv'.format(filename), index= False)\n",
    "#     shutil.copy('.\\output\\{}.csv'.format(filename), '{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename))\n",
    "#     file_export_log.write(\"Succeeded: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "# except:\n",
    "#     print('error')\n",
    "#     file_export_log.write(\"Failed: {} \\n\".format('{}\\{}.csv'.format(PROJECTBOOKCHECK_HTTPSEVER_FOLDER, filename)))\n",
    "\n",
    "\n",
    "# hyper_name = 'performance.hyper'\n",
    "\n",
    "# try: \n",
    "#     publish_datasource(df_out, hyper_name)\n",
    "# #     print('success')\n",
    "#     file_export_log.write(\"Succeeded: {} \\n\".format('{}'.format(hyper_name)))\n",
    "# except:\n",
    "#     print('error')\n",
    "#     file_export_log.write(\"Failed: {} \\n\".format('{}'.format(hyper_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-wrestling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "resistant-isaac",
   "metadata": {},
   "source": [
    "\n",
    "<a id='FinalCleanUp'></a>\n",
    "## Final Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dedicated-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_export_log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "understanding-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#clean up tableau publishing log file\n",
    "\n",
    "import os\n",
    "import glob\n",
    "# get a recursive list of file paths that matches pattern\n",
    "fileList = glob.glob('./*.log')\n",
    "# Iterate over the list of filepaths & remove each file.\n",
    "for filePath in fileList:\n",
    "    try:\n",
    "        os.remove(filePath)\n",
    "    except OSError:\n",
    "        print(\"Error while deleting file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "durable-sponsorship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed : 20.66102433204651 seconds\n"
     ]
    }
   ],
   "source": [
    "end_time =  time.time()\n",
    "elapsed = end_time - start_time\n",
    "print('time elapsed : {} seconds'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-consultancy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
